SAGA on FutureGrid
==================

Activity:
---------

  The Simple API for Grid Applications (SAGA) is an OGF standard
  (http://www.ogf.org), and defines a high level, application driven
  API for developing first principle distributed applications, and for
  distributed application frameworks and tools. Our SAGA project (see
  http://www.saga-project.org/) provides SAGA API implementations in
  C++ and Python, which interface to a variety of middleware backends,
  as well as higher level application frameworks, such as
  Master-Worker, MapReduce, AllPairs, BigJobs.  For all those
  components, we use FutureGrid and the different software
  environments available on FG for extensive portability and
  interoperability testing, but also for scale-up and scale-out
  experiments. These activities allow to harden the SAGA components
  described above, and support CS and Science experiments based on
  SAGA.



Achievement:
------------
 
  FG has provided a persistent, production-grade experimental
  infrastructure with the ability to perform controlled experiments,
  without violating production policies and disrupting production
  infrastructure priorities.Â  These attributes coupled with excellent
  technical support -- the bedrock upon which all these capabilities
  depend, have resulted in the following specific advances in the
  short period of under a year:

  [[With all due respect, the FG support is friendly, understanding,
  supportive, but not quick.  We understand the reasons for that, as
  far as we are privy of them, but I personally would be hard-pressed
  to call the support excellent, despite being very appreciative of
  it]]


1. Use of FG for Standards based development and interoperability
   tests:

  We have in particular been able to prepare SAGA for future
  deployments on XSEDE, by testing the SAGA-BES adaptor in a variety
  of configurations, against Unicore and Genesis-II backends, with
  UserPass and Certificate based authentication, with POSIX and HPC
  application types, with and without file staging support.  While
  those tests are still ongoing, it allows us to be confident toward
  the expected XSEDE middleware evolution.

  Further, we are continuously using FG based job submission endpoints
  for GIN driven interoperation tests with a variety of other
  production Grid infrastructures, including DEISA, PRACE, Teragrid
  and EGI (see http://forge.gridforum.org/sf/projects/gin/ and
  http://www.saga-project.org/interop-demos/ .

  In order to simplify the deployment and to improve end user support
  for SAGA, we have been using FG hosts to develop, test and harden
  our deployment procedures, by mimicking the CSA approach we
  currently use on TeraGrid and XSEDE.  At the same time, that
  deployment testing makes SAGA and SAGA based components available
  and maintained on all FG endpoints.


2. Use of FG for Analysing & Comparing Programming Models and Run-time
   tools for Computation and Data-Intensive Science.

  - Development of tools and frameworks:

    - P* experiments

      'P*' is a conceptual model of pilot based abstractions, in
      particular for pilot jobs.  Our work on pstar includes
      comparison between different PilotJob frameworks (BigJob, Condor
      GlideIn, Diane, Swift), and between different coordination
      models within those frameworks.  We used FG for a number of
      those experiments, as it allowed to compare a range of
      characteristics in a controlled environment.


    - next gen dynamic distributed app (Ole)
    - Next Gen of Dyn exascale apps (Ashley, Jha)
    - Grid/Cloud interop (AndreL) [finished]

  - data intensive apps
    - MapReduce (AndreL, Pradeep)
    - Grid/Cloud NGS analysis exp. (Sharath)


  - hybrid cloud-Grid scientific applications and tools (autonomic
    schedulers) [with Manish Parashar, finished]

    Policy-based (objective driven) Autonomic Scheduler provide a
    system-level approach to hybrid grid-cloud usage.  FG has been
    used for the development and extension of such Autonomic
    Scheduleing and application requirements.  We have integrated the
    distributed and heterogeneous resources of FG as a pool of
    resources which can be allocated by the policy-based Autonomic
    Scheduler (Comet). The Autonomic Scheduler  dynamically determines
    and allocates instances to meet specific objectives, such as
    lowest time-to-completion, lowest cost etc. We also used FG
    supplement objective driven pilot jobs on TeraGrid (ranger).


  - investigate run time fluctuations of application kernels

    We attempt to explore and characterize run-time fluctuations for a
    given application kernel representative of both a large number of
    MPI/parallel workloads and workflows.  Fluctuation appears to be
    independent of the system load and a consequence of the complex
    interaction of the MPI library specifics and virtualization layer,
    as well as operating environment.  Thus we have been investigating
    fluctuations in application performance, due to the cloud
    operational environment.  An explicit aim is to correlate these
    fluctuations to details of the infrastructure.  As it is difficult
    to discern or reverse engineer the specific infrastructure details
    on EC2 or other commercial infrastructure, FG has provided us a
    controlled and well understood environment at infrastructure
    scales that are not possible at the individual PI/resource level.



4. Saga has also produced the following papers:



FuturePlans:
------------

  We will be continuing to use FG as a resource for SAGA development.
  Amongst others, we intent: to move the testing infrastructure to
  other SAGA based components, like our PilotJob and PilotData
  frameworks; to widen the set of middlewares used for testing (with
  again having XSEDE and other PGIs in mind); to enhancing the scope
  and scale of our scalability testing; to test and harden our
  deployment and packaging procedures.

