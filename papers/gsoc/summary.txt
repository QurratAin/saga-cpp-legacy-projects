Implementation
--------------
Steal content from the developer manual?

Experiments
-----------
We validate the scalability of the enhanced SAGA-MapReduce framework
in heterogeneous infrastructures by performing the ''canonical'' word count
task with varying degrees of freedom: the amount of data processed per task and
the number of workers used.
We do measurements for each combination of data and compute configuration, such
as local data and local computation, local data and distributed computation,
distributed data and local computation and distributed data and distributed
computation.
For local data we use NFS, while for experiments involving distributed data we
use HDFS.
For distributing computation we use SAGA's SSH adaptor to launch worker
tasks on machines designated as workers.

More specifically, we perform the following set of experiments:
1) Doubling chunk size from 16MB to 256MB while processing 4GB of data by 8
workers.
2) Varying the number of workers from 2 to 10 in increments of 2 while
keeping the amount of processed data constant at 4GB.
