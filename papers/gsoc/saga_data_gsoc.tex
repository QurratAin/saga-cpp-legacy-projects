\documentclass[a4paper,11pt]{article}
%\documentclass[a4paper,12]{article}
\pagestyle{empty}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{epstopdf}
\usepackage{color}
\usepackage[left=1.0in,top=1.0in,right=1.0in,bottom=2.5in]{geometry}
\setlength{\textwidth}{6.27in}
\setlength\topmargin{0.0in}
\setlength\headheight{0.5in}
%\setlength{\topmargin}{0.25in}
%\setlength\headheight{0.25in}

\usepackage{fancyhdr,lastpage}
\pagestyle{fancy}
\chead{I need to be titled~\thepage~of \pageref{LastPage}}
\fancyhead[L]{}
\fancyhead[R]{}
\cfoot{Page \thepage~of \pageref{LastPage}}

\newif\ifdraft
\drafttrue

\ifdraft
\newcommand{\fixme}[1]{ { \bf{ ***FIXME: #1 }} }
\newcommand{\jhanote}[1]{ {\textcolor{red} { ***Jha: #1 }}}
\else
\newcommand{\jhanote}[1]{}
\newcommand{\fixme}[1]{}
\fi

\begin{document}

%%%%% TITLE %%%%%
\begin{center}
\textbf {\large \bf I need to be titled }
%\doublespacing
\vspace{14pt}

%%%%% AUTHORS %%%%%
\textbf {\normalsize \hspace{0.6 in} Miklos Erdelyi$^3$, Saurabh Sehgal$^1$, Andre Merzky$^1$,  \newline Katerina Stamou$^2$, Shantenu Jha$^1*$ }

\vspace{12pt}

%%%%% AFFILIATIONS %%%%%
\normalsize { \hspace{0.6 in} $^1$Center for Computation and Technology, \newline Louisiana State University, Baton Rouge, LA 70803, USA}

\normalsize {\hspace{0.6 in} $^2$Mechanical Engineering Department, \newline Louisiana State University, Baton Rouge, LA 70803, USA}

\normalsize { \hspace{0.6 in} $^3$Department of Computer Science, \newline University of Pannonia, Veszprem, Hungary}

\vspace{0.2in}
{\footnotesize {\hspace{0.0 in} $^*$Corresponding Author sjha@cct.lsu.edu}}


\vspace{12pt}
\end{center}

%%%%% MAIN TEXT %%%%%

\vspace{12pt}

There are numerous scientific applications that utilize data and resources distributed over vast heterogeneous infrastructures and networks with varying speeds and characteristics. However, despite the drastic differences in hardware capabilities of such distributed systems, applications usually tend to utilize a single infrastructure for all of their computational and data processing needs. Since most distributed frameworks are designed with specific assumptions and infrastructures in mind, dependence on a single technology in a heterogeneous environment is not always an optimal choice to gain maximum runtime performance. For example, the Sector/Sphere data cloud is exclusively designed to support data-intensive computing on high speed networks, while other distributed filesystems like GFS/Hadoop \fixme{HDFS instead of Hadoop?} assume limited bandwidth among infrastructure nodes [1]. Thus, for applications to efficiently utilize heterogeneous environments, abstractions must be developed for the efficient utilization of and orchestration across such distinct distributed infrastructure.  SAGA or "Simple API for Grid Applications" is a high level API that provides a simple, standard and uniform interface to the most commonly required distributed functionality [2]. SAGA can be used to encode grid applications, tool-kits to manage distributed applications as well as implement abstractions that support commonly occurring programming, access and usage patterns. Popular programming abstractions such as Map-Reduce and All-Pairs have been successfully implemented with SAGA to showcase its utilization as a flexible framework to scale-out data-intensive computations on different flavours of grids and clouds, and attain a high level of interoperability at the application level. Thanks to the ease of developing SAGA "Adaptors", developers can provide SAGA the interfaces to interact with widely different infrastructures simultaneously throughout the execution of a single application.

This paper reports on progress on three-fronts: First, we take the existing SAGA Map-Reduce implementation, and enhance it to increase performance and ease of use for application programmers through adding features such as serialization and compression of intermediate data, ability to define a combiner function to reduce network traffic and data-locality optimization at task assignment.
Secondly, we develop a SAGA adaptor for the Sector/Sphere compute and data cloud. The adaptor translates the high level SAGA job submission and file manipulation APIs into Sector/Sphere operations. This allows SAGA applications to leverage the functionality provided by the Sector/Sphere cloud for processing large data sets on infrastructures with high speed networks.  The third is the creation of components that facilitate flexibility in data placement relative to the computational resource -- that is either data can be transferred intelligently to match computational workloads or computational workloads can be placed to match (prevent) data requirements. More generically, it is worth mentioning that these approaches can be extend to support certain kinds of {\it affinities}.

{\it Enhancing SAGA-based Map-Reduce Performance:} To orchestrate the functioning of the various different frameworks, we use the master-worker programming pattern, on which the SAGA Map-Reduce implementation is also based. This pattern allows the workers to execute on the different infrastructures (including Sector/Sphere) while communicating their progress and results through an advert database to the master~\cite{saga_data_intensive}. The performance enhancements to the existing SAGA Map-Reduce implementation come partly from reduced network bandwidth usage and partly from more efficient processing when reading or writing serialized data by the workers. Network traffic is primarily reduced by applying data-locality optimization: the master tries to assign chunks of the input to workers such that the data to be processed will reside near or on the worker node itself, thus avoiding the need for transferring data blocks by the distributed filesystem implementation. Information for this decision is obtained by the master through SAGA's "Replica" interface. The amount of network usage is further reduced when the user specifies a combiner function which is then used for aggregating key/values locally on the worker. The processing of input and output key/value pairs is enhanced by minimizing expensive memory I/O operations.

{\it Sector/Sphere Adaptors: }Sphere represents a programming paradigm that is different from MapReduce. \fixme{Sauabh: Add a bit more about Sphere and maybe even a sentence about the Sphere/Sector adaptor}.  Along with the enhancements to the SAGA Map-Reduce implementation combined with the development of the Sector/Sphere adaptor, we describe in this paper, our approach to introduce intelligence in relative data-compute placement whilst demonstrating and utilizing the interoperability features inherent in the design of SAGA. Specifically, we use the Sector/Sphere adaptor in conjunction with others (KFS, HDFS, Amazon EC2) naturally give us the opportunity to experiment with various distinct frameworks running on infrastructures best suited for their purposes.

{\it Validation Using Montage: } We test initial prototypes of these developments and their performance advantage using the well known Montage application.  Montage requires the execution of DAG;
% We introduce a SAGA application, digedag [Ref?], a part of the Montage project, already well under development.
Digedag is a SAGA-based workflow planner and execution package, that provides APIs for translating abstract workflows in the form of DAGs into "concrete" DAGs, which are then executed on the underlying infrastructure.
% We use digedag as an example application running on a heterogeneous environment composed of various distributed frameworks and a large data distribution.
% Once a DAG has been translated into its concrete form,
We describe our approach to most efficiently execute it by taking into consideration the data-locality, as well as the access patterns of the execution steps required to complete the work flow. This analysis is done through developing performance models of transferring data between frameworks, as well as the distribution of the computing resources in the environment. Based on this analysis, the data is placed efficiently, and a subset of nodes and frameworks maybe chosen to perform the necessary computations. The shuffled data is also cached for future computations.



%%%%% REFERENCES %%%%%

\begin{thebibliography}{99}
\bibitem{sector}
\newblock Y. Gu, R.L. Grossman, "Sector and Sphere: The Design and Implementation of a high performance data cloud".

\bibitem{saga_ccgrid09}
\newblock C. Miceli, M. Miceli, S. Jha, H. Kaiser, A. Merzky, "Programming Abstractions for Data Intensive Computing on Clouds and Grids"

\bibitem{saga_data_intensive}
\newblock ??

\bibitem{montage}
\newblock Montage ??

\bibitem{digedag}
\newblock Digedag ??

\end{thebibliography}

\vspace{12pt}

%%%%% FIGURES %%%%%

%================================================================
%  Add new figure (Figure 1) here
%================================================================
%\begin{figure}
%\centering
%\includegraphics[width=5.0in]{Image1.eps}
%\caption{CFD/MD Coupled Simulation on Channel Flow - Now Yet Included}
%\end{figure}
%================================================================

\begin{figure}
\centering
%\includegraphics  [scale=0.33, angle=270]{Image2}
\caption{Will I be a figure? \jhanote{}}
\end{figure}

\begin{figure}
\centering
%\includegraphics [scale=0.33, angle=270]{Image3}
\caption{Will I be a figure? \jhanote{}}
\end{figure}

\noindent

\end{document}
