\documentclass[conference,final]{IEEEtran}

\usepackage{latex8}
\usepackage{times}

\usepackage[utf8]{inputenc}
\usepackage{graphicx}
\usepackage{url}
\usepackage{float}
\usepackage{times}    
\usepackage{multirow}    
\usepackage{listings}   
\usepackage{times}     
\usepackage{paralist}    
\usepackage{wrapfig}    
\usepackage[small,it]{caption}
\usepackage{multirow}
\usepackage{ifpdf}


\usepackage{listings}
\usepackage{keyval}  
\usepackage{color}
\definecolor{listinggray}{gray}{0.95}
\definecolor{darkgray}{gray}{0.7}
\definecolor{commentgreen}{rgb}{0, 0.4, 0}
\definecolor{darkblue}{rgb}{0, 0, 0.4}
\definecolor{middleblue}{rgb}{0, 0, 0.7}
\definecolor{darkred}{rgb}{0.4, 0, 0}
\definecolor{brown}{rgb}{0.5, 0.5, 0}

\lstdefinestyle{myListing}{
  frame=single,   
  backgroundcolor=\color{listinggray},  
  %float=t,
  language=C,       
  basicstyle=\ttfamily \footnotesize,
  breakautoindent=true,
  breaklines=true
  tabsize=2,
  captionpos=b,  
  aboveskip=0em,
  belowskip=-2em,
  %numbers=left, 
  %numberstyle=\tiny
}      

\lstdefinestyle{myPythonListing}{
  frame=single,   
  backgroundcolor=\color{listinggray},  
  %float=t,
  language=Python,       
  basicstyle=\ttfamily \footnotesize,
  breakautoindent=true,
  breaklines=true
  tabsize=2,
  captionpos=b,  
  %numbers=left, 
  %numberstyle=\tiny
}

\newcommand{\up}{\vspace*{-1em}}
\newcommand{\upp}{\vspace*{-0.5em}}
\newcommand{\numrep}{16 }
\newcommand{\samplenum}{4 }
\newcommand{\tmax}{$T_{max}$ }
\newcommand{\tc}{$T_{C}$ }

\title{SAGA-based BigJob: A pervasive, general purpose Pilot-Job Abstraction for Distributed Systems}

\author{
Andr\'e Luckow$^{1}$, Lukasz Lacinski$^{1}$,   Shantenu Jha$^{1,2,3,*}$,\\
  \small{\emph{$^{1}$Center for Computation \& Technology, Louisiana State University, USA}}\\
  \small{\emph{$^{2}$Department of Computer Science, Louisiana State University, USA}}\\
  \small{\emph{$^{3}$e-Science Institute, Edinburgh, UK}}\\
  \small{\emph{$^{*}$Contact Author: \texttt{sjha@cct.lsu.edu}}}\\
}

%\date{}

\def\acknowledgementname{Acknowledgements}
\newenvironment{acknowledgement}%
{\section*{\acknowledgementname}%
\parindent=0pt%
}

\newif\ifdraft
% \drafttrue
\ifdraft
\newcommand{\llnote}[1]{ {\textcolor{green} { ***JK: #1 }}}
\newcommand{\alnote}[1]{ {\textcolor{blue} { ***AL: #1 }}}
\newcommand{\jhanote}[1]{ {\textcolor{red} { ***SJ: #1 }}}
\else
\newcommand{\llnote}[1]{}
\newcommand{\alnote}[1]{}
\newcommand{\jhanote}[1]{}
\fi

\begin{document} 

\maketitle    

% \up\up\up\up

\begin{abstract}
  The uptake of distributed infrastructure by scientific applications
  has been limited by the availability of extensible, pervasive and
  simple to use abstractions. Effective abstractions are required at
  multiple levels -- development, deployment and execution stages of
  scientific applications. The Pilot-Job abstraction has been shown to
  be an effective abstraction to address many requirements of
  scientific applciations. However there are multiple Pilot-Job
  abstractions which are often tied to a specific infrastructure.  In
  this paper, we introduce a SAGA-based Pilot-Job which supports a
  wide range of application types and is usable over a broad range of
  infrastructure, i.e. is both general-purpose and pervasive.
  Emerging distributed infrastructure such as Clouds provide different
  resource provisioning models from classical Grids. This introduces
  new opportunities for distributed applications and the support of
  dynamical execution models. In this paper, we discuss how the
  SAGA-based Pilot-Job has been used for different application types
  and supports concurrent usage across multiple heterogeneous
  distributed infrastructure.
\end{abstract}

% \up \up

\section*{Structure/Outline}

Section 1. Introduction -- talk about (i) Distributed Systems, need
for abstractions (development, deployment and execution) and
programming systems. (ii) Talk about Pilot-Jobs as one of the most
succesful ``execution abstraction''. (iii) Talk about limitations of
current approaches. (iv) In a nutshell what this paper aims to achieve
and then conclude with an outline.

\bigskip

Section 2. SAGA-based Pilot Job.  SAGA in brief. Place canonical SAGA
picture. Talk about why using SAGA for PilotJob is different
(integrated and consistent API). Talk about SAGA Job-Model; talk about
extensions to the SAGA Job Model for BigJob.  Architecture and Control
Flow for BigJob. Discuss how SAGA BigJob works well with Condor Glide-in.

\bigskip 

Section 3. Introduce Clouds -- SAGA for Clouds and parallel jobs for
Clouds. Explain the role of a Pilot Job for Clouds. What does it mean?
How is it different from Pilot Jobs for Grids/Clusters?  Talk about
Parallel jobs and Clouds and how we manage them.

\bigskip 

Section 4. Usage Modes and Analysis: Already laid out.

\bigskip 
Section 5. Conclusion

\Section{Introduction}
% \up



Several classes of applications are well suited for distributed
environments. Probably the best known and most powerful examples are
those that involve an ensemble of decoupled tasks, such as simple
parameter sweep applications~\cite{1239909}.

\emph{Pilot jobs} is a concept initially pioneered by Condor Glide-In, which
has been used by many communities to increase the predictability
and time-to-solution of such applications. A pilot job allows the execution 
of jobs which the necessity to queue each individual sub-job. The pilot job itself
is a regular Grid job, which is started through a Grid resource manager, such as
the Globus GRAM.

The Simple API for Grid Applications (SAGA) is a high-level, easy-to-use API for 
accessing distributed resources. Unlike other common pilot job systems SAGA BigJob 
(i) natively supports MPI job and (ii) works on a variety of back-end systems, 
generally reflecting the advantage of using a SAGA-based approach.

Discuss PilotJob:
- How Traditionally Used (mostly deployment time)
- How traditionally bound to a single platform and system

Recently, the usage of virtualization and the usage of on-demand virtual machines
become increasingly popular. These so-called infrastructure-as-a-service clouds have
different advantages compared to traditional Grid systems: users are provided
with a greater flexibility and have the ability to customize their virtual machine
environment. At the same time virtual machines are well isolated from each other. More and
more the need to integrate traditional Grids and Clouds arises.

%from autonomic HPC Grid/Cloud paper
Developing and running applications in such a hybrid and dynamic computational 
infrastructure presents new and significant challenges. These include the need for programming 
systems that can express the hybrid usage modes and associated runtime trade-offs and adaptations, 
as well as coordination and management infrastructures that can implement them in an efficient 
and scalable manner. Key issues include decomposing applications, components and workflows, 
determining and provisioning the appropriate mix of Grid/Cloud resources, and dynamically scheduling 
them across the hybrid execution environment while satisfying/balancing multiple, possibly changing 
objectives for performance, resilience, budgets and so on.


\Section{Related Work}

Lately, the pilot job concept has been extensively research.

Condor Glide-In~\cite{citeulike:291860}

Falkon~\cite{1362680}


Nimbus~\cite{10.1109/MIC.2009.94} provides a special integration with
classical batch cluster systems. By running cluster in a hybrid mode
this setup can support both native jobs by running those in the Xen's
domain 0 as well as VMs. In the pilot usage mode, the cloud user is
able to control the entire setup and configuration and startup a
virtual cluster.


CERN Atlas Pilot Job~\cite{1555338}

\Section{BigJob -- The SAGA-based Pilot Job}

Introduce BigJob:
 - Describe it, and how it differs from other PilotJobs

 - Outline new usage modes that BigJob fundamentally supports:
    -- As the basis for scale-out across
    -- As the basis for a framework for runtime optimization
    -- More thought?

BigJob:
 - Architecture and control flow details
 - Performance Numbers

\SubSection{Overview}

The following figure gives an overview of the SAGA BigJob architecture.

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.45\textwidth]{figures/bigjob}
    \caption{BigJob Architecture: The core of the framework, the BigJob-Manager,
     orchestrates a set of BigJob-Agents and sub-jobs using the SAGA job and file APIs. 
     The BigJob-Agent is responsible for managing and monitoring sub-jobs on a 
     single machine.}
    \label{fig:figures_bigjob}
\end{figure}


\subsection{BigJob and Condor Glide-in}

\jhanote{I'm currently unsure of where to add -- here or in the next
  section, how bigjob works with Condor Glide-in. Suggestions?}

\subsection{BigJob for Utilizing Cloud Resources}

% espite a standardized interface, big difference on how to obtain meta-data (internal ip etc.)

At the execution level, Clouds differ from Clusters/Grids in at least
a couple of different ways. In cloud environment, user-level jobs are
not typically exposed to a scheduling system; a user-level job
consists of requesting the instantiation of a Virtual Machine (VM).
Virtual machines are either assigned to the user or not (this is an
important attribute that provides the illusion of infinite resources).
The assignment of job to a VM must be done by the user (or a
middleware layer as BigJob).  In contrast, user-level jobs on grids
and clusters are exposed to a scheduling system and are assigned to
execute at a later stage.  Also a description of a grid/cluster job
typically contains an explicit description of workload; in contrast
for clouds a user level job typically contains the container
(description of the resource requested) but does not necessarily
contain the workload. In other other words, the physical resources are
not provisioned to the workload but are provisioned to the container.
This model is quite similar to resource reservations where you obtain
a "container" of resources to which you can later bind jobs
to. Interestingly, at this level of formulation, pilot-jobs attempt to
provide a similar model of resource provisiong as clouds natively
provide.

BigJob provides the user an uniform abstraction to grids and clouds
independent of any particular cloud or grid provider that can be
instantiated dynamically
(Figure~\ref{fig:figures_distributed_pilot_job}).

\begin{figure*}[htbp]
    \centering
        \includegraphics[width=0.7\textwidth]{figures/distributed_pilot_job.pdf}
    \caption{An overview of the SAGA-based Pilot Job}
    \label{fig:figures_distributed_pilot_job}
\end{figure*}

Prior to using the SAGA cloud pilot job, the user is required to
prepare the virtual machine image for each cloud that is going to
used. The image should contain the application and possibly the
application data. Once the image is setup, the user can initialize
\texttt{bigjob\_cloud} object referencing the respective cloud
environment (including the used image).

During the initialization of a cloud based BigJob, the implementation
launches the requested number of the specified virtual machine type.
No agent required

While these IaaS clouds share similar Amazon EC2 style interface, they
tend to expose different semantics and behaviors. Commonly, there a
strong difference in the machine types supported, the management of
metadata and customization possibilities, the image setup procedure,
support for shared file systems, network setup etc. Further
standardization in this area is required.


description of images and instance types different

OCCI

\SubSection{Performance}

Startup Times

Dispatch times

In the following section we show that the SAGA BigJob abstraction is
suitable for running pilot jobs on different kinds of distributed
infrastructures.

The main overhead when using BigJob results from the queueing time in grids respectively the virtual 
machine creation time in cloud environments. Figure~\ref{fig:performance_setup_time} shows the setup
times observed in our experiments. 
\begin{figure}[htbp]
    \centering
        \includegraphics[width=0.45\textwidth]{performance/setup_time.pdf}
    \caption{\textbf{BigJob Setup Times:} In grids the setup time greatly depends upon the 
    queuing time at the local resource manager. However, in our experiments also clouds showed
    a high fluctuation in the queueing time.}
    \label{fig:performance_setup_time}
\end{figure}


\section{Usage Modes and Analysis}

The aim of this section is not to perform detailed systematic
performance measures and analysis, but to illustrate the various usage
modes the SAGA-based BigJob can support and how they are supported. We
posit that the performance overheads of BigJob are small relative to
the duration of the tasks that are typically performed, i.e., order of
seconds compared to tens of minutes and hours.  Needless to say, if
millions of jobs each of short duration were being attempted then the
overheads would be significant.

We discuss two scenarios that are representative of how applications
would typically use multiple distributed infrastructure. We focus our
attention on replica-based MD simulations and define a workload as
\numrep replicas of the HCV model~\cite{}, each replica running for
500 timesteps.  The first scenario involves running all \numrep over
different infrastructure configurations and determining the \tc for
each scenario. We repeat \tc for each configuration \samplenum times.

The second scenario, introduces an upper-bound on the acceptable \tc
(defined as \tmax) -- which is the maximum permissible time to
solution.

Each scenario has several possible specific sub-scenarios, of which we
discuss a few in each.

\subsection{List and explain the resources used in Experiments}

\subsection{Test Application: Scientific Problem Under Study}

\subsubsection*{Resource I: TeraGrid/LONI Cluster (QB)}

\subsubsection*{Resource II: Condor-Pool of LONI Clusters}

\jhanote{This one will require most description -- how the pool is set
up, what features are used etc}

\subsubsection*{Resource III: Cloud Environments}


\subsection{Scenario I: \tc for Workload for Different Resource Configurations}

\subsubsection{\tc for single Resource Usage}

In the first example, a given workload -- a NAMD simulation consisting of xxx atoms --
was run for 500 timesteps at different infrastructures.

\begin{figure}[htbp]
    \centering
        \includegraphics[width=0.45\textwidth]{performance/namd_run.pdf}
    \caption{\textbf{NAMD Runtimes on Different Resource Types: } The graph shows that 
             native HPC resource generally outperform cloud resources in particular when
             running applications across multiple nodes. However, the new 
             high memory eight core EC2 instance type was able to }
    \label{fig:performance_namd_run}
\end{figure}




\subsubsection{\tc for Collective Resource Utilization}

Workload of 8 replica runs
Subsequent run - each replica will take the entire BigJob
4 VMs/8 cores as increments for Nimbus
8 cores on Poseidon
32 core per bigjobs

\begin{itemize}
\item Resource I and III:
\item Resource II and III:
\item Resource I, II and III:
\end{itemize}


If resources in the Grid environment are instantly available it is usually not reasonable to start
additional cloud resources. However, clouds provide a very predictable startup times. Thus,
it is possible to  Nevertheless,
the performance can be highly variable.

\subsection{Scenario II: Investigation of the Distribution of Workload for Maximum Allowed
  Time to Solution} 

Given that Clouds provide the illusion of infinite capacity, or at
least queue wait-times are non-existent, it is likely that often most
sub-jobs will end up on the Cloud infrastructure.  Thus, in Scenario
II, the resource assignment algorithm we use is as follows: We submit
tasks to non-cloud resource first, and if the jobs have not finished
when time equal to $T_{X}$ (defined as: \tmax - 2 average \tc on all
clouds) has elapsed, than we move the workload to utilize clouds.  The
underlying basis is that clouds have an explicit cost associated with
them and if jobs can be completed on the the TG and Condor pool while
preserving the performance constraints, we opt for such a
solution. However, if queue loads prevent the performance requirements
being met, we move the jobs to a cloud-resource, which we have shown
has less fluctuation in \tc of the workload.

Start on Poseidon
Wait for 15 minutes

Based on current trends: will we finish or not.

Wallclock 1000 sec
Poseidon BigJob becomes available after 100 sec
1 replica finishes after 150 sec

After 1/4 check whether some resources should be started:
- 1 BigJob on Nimbus with 4 VM
- increase VMs linearly if jobs done don't catch
- if we caught up, we backup

BigJob startup is a dynamic decision -- We can dynamically bigjobs to a queue









\Section{Conclusion}
various abstractions for IaaS currently
various standardization efforts: OCCI, Cloud Consortium, ISO

We plan to extend this work in two important directions. The first is
the use of a more sophisticated coordination mechanism -- that
supports asynchronous task coordination (e.g., Comet). In this paper,
we have focussed on replica simulations, but not on replica-exchange
simulations -- which involve coordination between the different tasks
and intelligence in their placements.  It will be very interesting to
note the performance gains that accrue as a result of such
asynchronous coordination on production infrastructure for the
replica-exchange problems. Also, having established the basic
infrastructure to submit tasks to and manage multiple, heterogenous
resources using a simple, single interface, an important second
extension of this work is to use more sophisticated task-placement
decisions or resource utilization decision making.

\bibliographystyle{IEEEtran}
\bibliography{saga,literatur}
\end{document}
