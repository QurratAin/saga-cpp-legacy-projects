\documentclass[]{article}

% Use utf-8 encoding for foreign characters
\usepackage[utf8]{inputenc}

% Setup for fullpage use
\usepackage{fullpage}

% Uncomment some of the following if you use the features
%
% Running Headers and footers
%\usepackage{fancyhdr}

% Multipart figures
%\usepackage{subfigure}

% More symbols
%\usepackage{amsmath}
%\usepackage{amssymb}
%\usepackage{latexsym}

% Surround parts of graphics with box
\usepackage{boxedminipage}

% Package for including code in the document
\usepackage{listings}

% If you want to generate a toc for each chapter (use with book)
\usepackage{minitoc}

% This is now the recommended way for checking for PDFLaTeX:
\usepackage{ifpdf}

%\newif\ifpdf
%\ifx\pdfoutput\undefined
%\pdffalse % we are not running PDFLaTeX
%\else
%\pdfoutput=1 % we are running PDFLaTeX
%\pdftrue
%\fi

\ifpdf
\usepackage[pdftex]{graphicx}
\else
\usepackage{graphicx}
\fi

\usepackage{color}
\definecolor{listinggray}{gray}{0.95}
\definecolor{darkgray}{gray}{0.7}
\definecolor{commentgreen}{rgb}{0, 0.4, 0}
\definecolor{darkblue}{rgb}{0, 0, 0.4}
\definecolor{middleblue}{rgb}{0, 0, 0.7}
\definecolor{darkred}{rgb}{0.4, 0, 0}
\definecolor{brown}{rgb}{0.5, 0.5, 0}

\newif\ifdraft
\drafttrue
\ifdraft
\newcommand{\jhanote}[1]{ {\textcolor{red} { ***shantenu: #1 }}}
\newcommand{\alnote}[1]{ {\textcolor{blue} { ***andre: #1 }}}
\newcommand{\smnote}[1]{ {\textcolor{green} { ***sharath: #1 }}}
\else
\newcommand{\alnote}[1]{}
\newcommand{\athotanote}[1]{}
\newcommand{\smnote}[1]{}
\fi




\title{BigJob, ManyJob, Pilot-Store, ... -- Abstractions for dynamic ...}
\author{  }

\date{2011-04-02}





\begin{document}

\ifpdf
\DeclareGraphicsExtensions{.pdf, .jpg, .tif}
\else
\DeclareGraphicsExtensions{.eps, .jpg}
\fi

\maketitle


\section{Pilot-Jobs}

The uptake of distributed infrastructures by scientific applications has been
limited by the availability of extensible, pervasive and simple-to-use
abstractions which are required at multiple levels â€“ development, deployment
and execution stages of scientific applications. The Pilot-Job abstraction has
been shown to be an effective abstraction to address many requirements of
scientific applications. Specifically, Pilot-Jobs support the decoupling of
workload submission from resource assignment; this results in a flexible
execution model, which in turn enables the distributed scale-out of
applications on multiple and possibly heterogeneous resources. Most Pilot-Job
implementations however, are tied to a specific infrastructure. In this paper,
we describe the design and implementation of a SAGA-based Pilot-Job, which
supports a wide range of application types, and is usable over a broad range
of infrastructures, i.e., it is general-purpose and extensible, and as we will
argue is also interoperable with Clouds.

\noindent
\textbf{Characteristics:}
\begin{itemize}
	\item Task binding: early vs. late binding
	\item \textbf{Resource Types:}
	\begin{itemize}
		\item Cluster support, i.e. Number of resources per BigJob
		\item Number of concurrent sub-jobs per BigJob agent
	\end{itemize}
	\item \textbf{Coordination:} 
	\begin{itemize}
		\item Sub-Job pull vs. push applies to control and data flow (different objects that are pushed/pulled)
		\item Central vs. decentral decision making
		\item Should we support a pull-based BJ (e.g. Diane)? 
	\end{itemize}	
	\item \textbf{Communication:}
	\begin{itemize}
		\item remote procedure style communication, e.g. CORBA
		\item messaging
		\item shared tuple space: BigJob e.g. uses the Advert service to share data between the manager and the agent (such as task information)
	\end{itemize} 
	\item \textbf{Dynamic Resources:}
		\begin{itemize}
			\item Push/Pull model for growing/shrinking resources
			\item How is this decision made?
		\end{itemize}
	\item \textbf{Data management:} Managing input and output files can be critical in particular with the current increase of data volumes. Pilot-Jobs can support different kinds of data management, e.\,g.\ file stage-in and out. Also, it can provide integration with other kinds of data systems.
	\item \textbf{Fault tolerance:} Large, distributed Grids are highly dynamic and inherently prone to failures and thus unreliable. To deal with failures, systems can deploy strategies, such as automatic resubmission etc.
	\item Resource abstraction: SAGA vs. GANGA
	\item End-user abstraction: BigJob API
	\item Task scheduling and prioritization
	\item Supported middleware types and infrastructures
	
	\item Security
\end{itemize}


\begin{table}[t]
\begin{tabular}{|l|p{2.5cm}|p{2cm}|p{2cm}|p{2cm}|p{2cm}|}
	\hline
	&\textbf{Task Binding} &\textbf{Cluster Support} &\textbf{Coordina\-tion} & \textbf{Communica\-tion} &\textbf{Dynamic Resources}\\
	\hline
	\textbf{BigJob} & &&&&\\
	\hline
	SAGA BigJob & &&&&\\
	\hline
	\hspace{4mm} Globus/PBS adaptor  &late binding (at sub-job submission)  
									 &yes &push/pull \alnote{no local decision making at agent: push and pull in control and data} &SAGA Advert &no\\  
	\hline
	\hspace{4mm} Cloud adaptor (EC2) &late binding (at sub-job submission)  
									 &no &push/pull&SAGA Advert &no\\ 
	\hline
 	BigJob-Cloud &late binding (at sub-job submission) &yes &Push 
				 &local python-based queue &no\\ 
	\hline
	BigJob-Azure &late binding (at sub-job submission)
	             &no &push/pull &Azure Storage &no\\ 
	\hline
    BigJob-Diane &late binding \alnote{not sure whether at submission time or after} &yes &pull &CORBA &yes\\ 
	\hline	
	\textbf{Dynamic BigJob} & &&&&\\
	\hline
    ManyJob &late binding (after job submission) &yes &push/pull &SAGA Advert service&no\\
	\hline
 	ManyJob-Cloud &late binding (after job submission) &no &push/pull &SAGA Job (SSH) &no\\
	\hline 
	ManyJob-Affinity &late binding (after job submission)
	\smnote{Andre: I think
here binding occurs before job submission?} \alnote{I think not: affinity are just a constraint that is put on a subjob. However, there can be e.g. multiple bigjob in a manyjob that satisfy a constraint} &yes &push/pull &SAGA Advert service &no\\
	\hline
\end{tabular}
\caption{Characteristics of Pilot-Job Implementations According 
		to Defined Vectors}
\end{table}		
\alnote{Sharath: I removed some of the details from the table e.g. how the 
manyjobs binds sub-jobs to bigjobs - we must discuss this in text.}
		
\vspace{10 mm}

\textbf{Backends}
\begin{itemize}
    \item SAGA/Grid: Globus, PBS, Local, 
    \item EC2-style Clouds (FutureGrid, EC2, Eucalyptus)
    \item Azure
    \item Condor
    \item Diane
\end{itemize}


\textbf{BigJob vs. Diane}

\begin{tabular}{|l|l|l|}
\hline
 &BigJob &Diane\\
\hline
MPI &yes &yes\\
\hline
Advanced Scheduling &no &yes\\
\hline
Dynamic VOs &no &yes\\
\hline
API for Agent Submission &yes &no\\
\hline
\end{tabular}





\textbf{Extensions}
\begin{itemize}
    \item Dynamic VOs: adding new BigJobs to a ManyJob at runtime
    \item new backends
\end{itemize}


\textbf{Difference between Bigjob and Bigjob Cloud:} 

\begin{itemize}
	\item ManyJob is required to manage the set of VMs. The BigJob-Cloud can manage a set of VMs without the need of ManyJob.
	\item Bigjob uses advert server for communication between BigJob-agent and BigJob whereas BigJob-Cloud does not use an advert server.
	\item Bigjob-cloud does not require SAGA-AWS adaptors as opposed to requirement in original Bigjob. 
\end{itemize}	




\textbf{SAGA-ManyJob}:
It uses SAGA BigJob approach to start multiple BigJobs agents 
whether on a single resource or on multiple resources. And 
these agents are responsible for pulling the tasks from advert 
service and run the possible subjobs concurrently or in generations.



\textbf{SAGA-ManyJob-Affinity}:
This implementation is similar to SAGA-ManyJob except that we define affinity for each resource and also define affinity for the tasks. Therefor binding between tasks and resource occur while submitting the jobs.

This approach is well suited when utilizing wide variety of infrastructure/resources where parameters for the application will change according to the file paths/environment variables etc.. for each resource



\section{Pilot Data / Store}
\noindent
Scenarios:
\begin{itemize}
	\item Acquire data sources (advanced reservation, place holder)
	\item Virtual destination: dynamically mapping of data to pilot stores
	\item Runtime environment for $\alpha$ based data
\end{itemize}
	
\noindent	
Dynamic data:
\begin{itemize}
	\item Data to be generated (temporal)
	\item Data that is in place (spatial)
	\item Data that is changing (temporal)
	\item Data characteristics, properties
\end{itemize}	

\noindent
Analogies with Pilot-Job:
\begin{itemize}
	\item Assign pilot job to resource: $f^{1}(PJ_i) \rightarrow R_i$
	\item Assign task to pilot-job: $f^{2}(T_i) \rightarrow PJ_i$ 

	\item $g^{1} (D_i) \rightarrow PS_i$
	\item $g^{2} (PS_i) \rightarrow R_i$
\end{itemize}

\subsection{BitDew}

Random Notes
\begin{itemize}
	\item Focus on Desktop Grid
	\item Java-based implementation (ie difficult to interface with Python-based PS/SAGA)
	\item highly distributed: stable and volatile nodes
	\item pull model, i.e. a node pulls for new data
\end{itemize}


Mapping to BitDew:
\begin{itemize}
	\item Pilot Store in its current implementation covers Bitdew Data Catalog and Repository
	\item For data management and placement the Active Data API and the Bitdew data scheduler could be used
	\item Transfer Management is done via SAGA File API	
\end{itemize}

How to evolve pilot data/store?
\begin{itemize}
	\item Active management of data (e.g. replication, automatic affinity management) requires an active component:
	\begin{itemize}
		\item Manager/Agent model as in BigJob?
		\item Who runs active components? Started as part of batch job or separate install/start?
	\end{itemize}
\end{itemize}

questions:
\begin{itemize}
    \item How should
    we store data in order to effectively cope with non-uniform demand for
    data? 
    \item How many copies of popular data objects do we need? 
    \item Where should we store them for effective load balancing?
\end{itemize}

\section{Pilot-Job and Pilot-Store as Runtime Environment for MR}
...
Scenarios:
\begin{itemize}
	\item 1 BJ 16 core 1 machine
	\item 2 BJ 8 cores - 1 machines
	\item 2 BJ 8 cores - 2 machines
\end{itemize}

other parameters:
\begin{itemize}
	\item placement of data
	\item cloud
\end{itemize}

\section{BFast Scenario for Dynamic Data}

\textbf{Types of Input Files:}
\begin{itemize}
	\item static data: 
	\begin{itemize}
		\item reference genome
		\item index files
	\end{itemize}
	\item dynamic data: short-read files (ad-hoc generated depending on runtime)
\end{itemize}

\noindent
\textbf{Dynamic Scenarios:}
\begin{itemize}
	\item moving generated short-read data to available resources
	
	\item support processing of n experiments 

	\item re-partition of tasks to a larger number of available cores (dynamic data that needs to re-generated as a consequence that there are new compute elements available)

\end{itemize}

\bibliographystyle{plain}
\bibliography{}
\end{document}
