\documentclass[conference,final]{IEEEtran}

\usepackage{graphicx}
\usepackage{epsfig}
\usepackage{subfigure}
\usepackage[hypertex]{hyperref}
\usepackage{subfigure}  
\usepackage{color}
% \usepackage{draftcopy}

\usepackage[small,it]{caption}

\usepackage{multirow}
\usepackage{ifpdf}

\long\def\comment#1{{ \bf \textcolor{magenta}{\bf #1}}}
\long\def\ccomment#1{{ \bf \textcolor{blue}{\bf #1 (SJ)}}}
\newcommand{\F}[1]{\B{\textcolor{red}{FIXME: #1}}}
\newcommand{\C}{\comment}
\newcommand{\CC}{\ccomment}
\newcommand{\fix}[1]{\textcolor{red}{\bf #1}}
\newcommand{\tc}{$T_c$}

\newif\ifdraft
\drafttrue

\ifdraft
\newcommand{\fixme}[1]{ { \bf{ ***FIXME: #1 }} }
\newcommand{\jhanote}[1]{ {\textcolor{red} { ***Jha: #1 }}}
\newcommand{\yyenote}[1]{ {\textcolor{blue} { ***yye00: #1 }}}
\else
\newcommand{\jhanote}[1]{}
\newcommand{\yyenote}[1]{}
\newcommand{\fixme}[1]{}
\fi

\newcommand{\jitter}[1]{{$\sigma(\alpha)$}}

\newif\ifpdf
\ifx\pdfoutput\undefined
  \pdffalse
\else
  \ifnum\pdfoutput=1
    \pdftrue
  \else
    \pdffalse
  \fi
\fi

\ifpdf
\DeclareGraphicsExtensions{.pdf, .jpg}
\else
\DeclareGraphicsExtensions{.eps}
\fi

\begin{document}

\title{\large Developing Autonomic Distributed Scientific
  Applications: A Case Study From History Matching Using Enemble
  Kalman-Filters}
  
\author{\authorblockN{Yaakoub El Khamra\authorrefmark{3}\authorrefmark{1}, Shantenu Jha\authorrefmark{1}\authorrefmark{2}, Andre Luckow\authorrefmark{1}},
   \authorblockA{\authorrefmark{1}
    Center for Computation and Technology, Louisiana State University,
    Baton Rouge, 70803} \authorblockA{\authorrefmark{2} Department of
    Computer Science, Louisiana State University, Baton Rouge, 70803}
    \authorblockA{\authorrefmark{3} Texas Advanced Computing Center, 
    University of Texas, Austin, 78758}
}
\maketitle
 \begin{abstract}
   The development of simple, effective distributed applications
   remains challenging.  Therefore, not surprisingly, it is difficult
   to implement advanced application characteristics -- such as
   autonomic behaviour. However, there exist a large class of
   applications which could benefit immensely with support for
   autonomic properties.  For example, many applications have
   irregular execution characteristics and highly variable resource
   requirements which are very difficult to predict in advance, but
   can be addressed using autonomic approaches.  Autonomics can help
   meet this promise. This paper discusses the design and development
   of a prototype framework using SAGA -- aptly called Lazarus, that
   can support many of the requirements of Autonomic applications that
   desire to use Computational Grids.  The development of such
   applications is difficult, but so is the effective deployment of
   such applications on Grids.  For example, as a consequence of
   irregular execution characteristics dynamic resource requirements
   are difficult to predict a priori thus rendering static resource
   mapping techniques such as workflows ineffective.  We provide here
   an initial description of the features and the architecture of the
   Lazarus framework, integrate it with an Ensemble Kalman Filter
   application, and demonstrate the advantages -- performance and
   lower development cost of the Lazarus framework.  As proof of
   concept we deploy Lazarus on several different machines on the
   TeraGrid, and show the effective utilization of several
   heterogeneous resources and distinct performance enhancements.
 \end{abstract}
 \begin{keywords}
   eScience Application, Middleware Inter-operation, Distributed
   Infrastructure Deployment, Distributed Application Programming,
   Cactus, Performance, SAGA, Programming Abstractions, Batch Queue
   Prediction BQP
 \end{keywords}

\section*{Notes}

To deal with the increasing complexity of large-scale computing
systems, computers and applications must learn to manage themselves in
accordance with high-level guidance from humans -- a vision that has
been referred to as autonomic computing.  Grids have the following
properties: (i) faulty, error-prone, (ii) dynamic resouces, and (iii)
heterogenous. But not all characterisitcs -- autonomic or otherwise,
have to be coded agianst.  Abstractions, such as frameworks to
facilitate resuse.  Application-level information that can than be
translated, for example, a policy or a strategy.. Present SAGA as a
programming system to develop Autonomic Application.  Provides
generarlised, extensible mechanisms for:
\begin{itemize}
\item  Resource Selection
\item Placement
\item  Fault Tolerance -- what are we going to say? Manual implementation
\item Ability to plug-into decision support and Information Services
  systems
\item in general a framework can releive the pressure/onus off the
  application developer for a wide range of application
\end{itemize}

And we apply this to an application that is a "prototypical"
application

\begin{itemize} 
\item Dynamic requirement
\item Highly-irregular and  difficult to plan/predict
\begin{itemize} 
  \item number of jobs
  \item distribution of the size of jobs
  \item time to completion between stages
\end{itemize} 
\item checkpoint and self-migrating 
\item Need for performance 
\end{itemize} 

In this paper we discuss:
\begin{itemize} 
\item Details of: Application Requirement $\rightarrow$ Resource Properties 
$\rightarrow$ Resource Selection
\item Performance Measures:
  \begin{itemize}
\item Define a workload and the time to complete 
\item Define a time and the number of jobs completed (throughput)
\item Scalability (number of systems utilised)
\end{itemize} 
\end{itemize} 



\section{Introduction}

\jhanote{Reference Manish's earlier work on accord and reservoir simulations}
\yyenote{So I added a small sentence there, do you want more?}

By definition Grids are characterised as dynamic and heterogeneous
environments.  They are dynamic due to time-dependent resources loads,
availability and access patterns; the aggregation of specialised
resources in different administrative domains is one source of the
heterogeneity.  Most tools to address the dynamical nature of the
grids assume a fixed underlying resource requirement.  There exist
several well known examples of distributed applications which in turn
have multiple 'embarrassingly' distributed jobs (or sub-applications)
that are either typically uncoupled or the coupling is between the
master and client application.  Things get significantly more
complicated when there is horizontal coupling between the distributed
jobs, say for example, a global exchange or synchronization point.
Most applications and support-tools for distributed applications
assume that the individual ``jobs'' during the course of their run
life-time will display a well-defined, static execution
characteristics.  However there are class of applications for which
the individual job run time characteristics are inherently difficult
to predict and plan for.  In addition to the class of applications we
investigate here -- Kalman filters~\cite{DataAssim, KalmanPaper},
there are ``first principles'' Grid applications such as
GridSAT~\cite{gridsat03} and applications which based upon resource
aware ``learning'' algorithms~\cite{ majority_voting}, for which it is
both difficult to estimate precisely the resource requirements while
explicitly needing to marshal the distributed resources . For these
applications the resource requirement is dynamic and unpredictable;
interestingly, the resource requirements and utilization might
possibly be dependent upon both the execution trajectory and
underlying infrastructure. Such applications are hard to develop and
deploy, but surprisingly, they have traditionally not received the
same level of infrastructural support for the development. It is
difficult to define a scheduling strategy that will be effective
throughout the execution of a complete applications; hence static
resource mapping is not an option.  It can be argued that the logic
for adapting to resource requirement changes from within the
application are best addressed at the application level.

\yyenote{Feel free to move this, this is what I want to say about
  Manish} \jhanote{this is perfect. thanks. its both technically
  correct and strategically good} This certainly is not the first time
autonomic frameworks have been used to launch and manage reservoir
simulations. Bangerth et al \cite{Manish} used an autonomic framework
to manage reservoir simulations for well-placement optimization. At
the moment, our work is focused on history matching and reservoir
characterization, however the next logical step is to adapt Lazarus to
run well/perforation placement studies. This might lead to a
convergence of SAGA and Accord~\cite{accord} in terms of common
functionality through different approach.

\jhanote{needs to be shortened} A key impediment to accelerated
development of Grid applications and consequently the uptake of Grids
is the scarcity of high-level application programming abstractions
that bridge the gap between existing grid middle-ware and
application-level needs.  Application developers are daunted by the
complexity of the vast array of low-level Grid and distributed
computing software APIs that currently exist; APIs have traditionally
been developed using a bottom-up approach that exposes the broadest
possible functionality.  Coding using these bottom-up APIs requires
extremely verbose code to implement even the simplest of
application-level capabilities.  Many Grid computing
projects~\cite{gat, cog, realitygrid} recognized the need for
higher-level programming abstractions to simplify the use of
distributed computing for application developers.  The Simple API for
Grid Applications (SAGA) attempts to consolidate community effort and
make ends meet by employing a top-down approach to distributed
computing software infrastructure.  SAGA is the first comprehensive
attempt to provide a programmatic approach for the development of
applications so as to utilize distributed environments, either by
design or by virtue of deployment.  In addition to simplifying the
programming environment for application developers, SAGA insulates
applications from technological, version changes and other low-level
implementation details that regularly occur in the lower layers of the
software stack.

HPC Grid projects such as TeraGrid and DEISA have definitely provided
a massive increase in the computing power available for scientific
applications, but this is due to the individual parts, and nothing to
do with the sum of the parts, i.e., not because applications are able
to use distributed resources in a coupled or coordinated manner. The
ability of applications to scale-out -- a critical requirement for
distributed applications, has not been adequately developed or
supported. It has had limited success in engendering novel
applications or usage modes.


\jhanote{Refresh aim! This is GMAC @ ICAC!}  The aim of this paper is
to provide a rare example of a novel approach of developing
(programming) an application that can utilize the individual resources
of the TeraGrid in a coupled and coordination fashion, and not just a
single piece of big-iron.  We have captured the primary run-time
characteristics of an interesting and common class of applications and
implemented a solution to effectively manage this run-time complexity
at the {\it application level}.  Our solution is perfectly acceptable
as a proof-of-concept, and modulo deployment and resource availability
issues, our approach will scale to problem sizes encountered in the
many science and engineering problems with hard-to-predict run-time
characteristics.

% Grid Computing -- and its hollow (? -- at least so far) promise of
% providing unlimited computational capacity. Well the unlimited was
% always impractical -- but any attempts to scale-out have been almost
% ignored -- but the need has not. Thus applications  have had to resort
% to application-level solutions .... now introduce SAGA, abstractions,
% and all that jazz..

% Admittedly, the e size of our input problem that we use is small, and
% thus makes it unlikely to solve a problem of any real {\it scientific
%   impact} %to the petroleum and energy industry,
% however, 

% tools and support infrastructure to support and plan for resource
% variability have been developed.

% {\it mention the need for programmatic approach versus a grid
%   meta scheduler such as grid way or GR MS. mention that workflows are
%   good for static workloads. this in a way is a autonomic dynamic
%   application..}

% Grid way and other meta schedulers are designed to be able to account
% for dynamic resource characteristics -- fluctuations in availability,
% performance, load or proximity.


% {\it mention that these techniques are useful for first principles applications}
% {\it will need to reference AppLeS: application level scheduling
%   paper~\cite{apples03}}
%Mention what AppLeS does \& doesn't and why this work is different

% Applications that are designed for dynamic and heterogeneous
% environments require the ability to manage varying levels of
% heterogeneity and dynamical resources. 


\noindent The highlights of this paper are:

\noindent {\it Utilize the advantages of proper programming
  abstractions, by integrating SAGA and Cactus and demonstrate the
  usefulness for Grid application development:}
Cactus provides the support and features required to implement
adaptivity e.g., checkpoint, restart and migrate thorns. SAGA provides
the ability to implement these features in a specific distributed
environment, for example, move files from location A to location B,
start a job on resource X from resource Y.  Thus the two programming
abstractions that Cactus and SAGA provide are natural complements of
each other.  As alluded to, we do so by interfacing SAGA with Cactus
and thus are able to draw on the many advantages of using SAGA
function calls from within a Cactus application.  The result is an
application that uses these two important application-level frameworks
and abstractions to create a truly distributed application.  SAGA
provides the capability for the the distributed aspects. SAGA provides
a high-level programming interface to Grid functionality, and thus
presents arguably, for the first time ever, the ability to develop
complete and sophisticated applications using simple Grid function
calls.  This paper demonstrates the utility of SAGA for creating
applications that can perform across dynamic and heterogeneous
infrastructure.  Importantly, although we focus on a prototype of a
specific application -- Kalman filtering -- thanks to the architecture
and abstractions used, similar functionality can be trivially
incorporated in more sophisticated and complex applications.

\noindent {\it The development of an application that is adaptive in
  multiple ways:}
A working definition of adaptive applications can be given as
following: an application that can respond to a change in the run-time
environment and manage internally (ie without external user or control
intervention) the associated change of state and control-flow arising
from the change(s) in the run-time environment.  For some
applications, adaptivity as defined here would be an {\it interesting}
feature to have, ie., arguably of academic interest. As we will show,
for applications that have irregular run-time characteristics,
adaptivity is a {\it critical} feature, ie., a necessity.  For
example, once a model of application (as a job) has been mapped to a
resource, it is likely that the same model will have to be mapped to
another resource before the model reaches the desired convergence.
Thus for such applications , it is difficult to statically
(re-)schedule or manually control the execution of the jobs through
the application life-time.

Adaptivity may arise due to the number of processors required by the
many jobs being a variable, as well as the fact that the number of
stages (ie involving global synchronization and subsequent
distribution) is unknown {\it a priori}. There comes a point when
providing the mechanism (logic and control) to the applications
themselves to respond to these changes becomes more efficient and
reliable than leaving it to a scheduler (or a meta-scheduler for that
matter). We believe that this prototype application is well beyond the
transition point and is a classic example of an adaptive application.

The ability of a Cactus application to migrate to a more appropriate
resources based upon network characteristics was demonstrated in
Ref~\cite{escience07}.  We extend the sophistication of adaptivity to
include: migration to better resource, based upon both compute and
network characteristics, and choosing optimal resources to spawn to
based upon local queue characteristics (as well as compute and network
performance). The correct abstractions and programming approach
enables the simple codification of an application that can determine
best resource to migrate to based upon all of the above.


\noindent {\it Effective Deployment of a non-trivial coupled resources
  on the TeraGrid:} 

% Our application is able to use multiple TeraGrid resources.  Based
% upon presentations by TeraGrid Directors (Catlett and Skow), the
% distribution of applications usage modes on the TeraGrid indicate
% approximately 10 (ie less than 1\% of all applications) actually use
% the resources in any sense of coupled fashion (either as MPICH-G2
% jobs, or explicitly marshalling more than 1 resource during the
% course of a simulation~\footnote{It is important to note that this
%   number has essentially remained frozen for several years,
%   indicating the lack of new applications and usage modes. A
%   significant fraction uses Gateways (portals) and a large number of
%   applications use workflow tools}. Our application is a high-end
% scientific application which uses SAGA to provide the ability to
% couple resources -- either at the application level (via common
% namespace, logical files etc) or at the infrastructure level (ie
% middleware distribution specific adaptors enable the same
% functionality across different distributions).

The outline of the paper is as follows: In the next section we outline
the scientific motivation and then describe the details of the
components of the application that we have developed to use SAGA and
Cactus.  \jhanote{to finish..}

\section{Application: Description and Motivation} 

\subsection{Motivation: Ensemble Kalman Filters}

The specific application that we investigate -- a prototype
implementation of a ensemble Kalman filter using SAGA and Cactus -- is
a particularly interesting case of 'irregular, hard-to-predict run
time characteristics'.  The model needs to run to completion which is
defined as convergence to within a certain value.  The run time of
each model was unpredictable and uncorrelated with the run-time of
models on running on the same number of processors -- a truly
independent variable.  As at every stage, each model must converge to
within a specified value before the next stage can begin, hence
dynamically load-balancing so as to ensure that all models complete as
close to each other as possible is the desired aim.  The number of
stages that will be required is not determined a priori. In the
general case the number of jobs required varies between stages.
Figure 1 shows a schematic of the irregular and hard to predict run
time characteristics of the simulations.

\jhanote{Place Appropriately...}

Even for relatively small input problem sizes at each stage, up to
several hundred models are generated which require from one to sixteen
processors to solve efficiently; the distribution of the number of
jobs and the run time-to-completion for a given processor count varies
by up to an order of magnitude.  Such hard to predict run-time
characteristics render static, data-flow independent scheduling
techniques difficult to use.  We demonstrate how the use of
appropriate programming abstractions like SAGA and Cactus enable the
effective development of applications with non-trivial requirements,
e.g., run-time resource selection based upon the application specific
characteristics.


% Modern reservoir simulators are in essence computer programs that are
% used to model fluid flow in porous media. Reservoir flow modeling
% exists in the context of of the reservoir management function, a
% process that optimizes the interaction between data and decision
% making during the life cycle of a field.  One of the more popular
% popular models is the model that is used to solve for the
%Ensemble Parallel Kalman filters can be used for solving
%multi-component, multi-phase flow of fluids~\cite{AzizSettari, },
%atmospheric modelling~\cite{yaakoub_reference_add} and a whole other
%range of scientific and engineering
%problems~\cite{yaakoubreferenceadd}.  Typical input to such
%simulations of multi-phase flow in porous geometry consists of the
%initial conditions of both fluids (saturation, temperature, pressure,
%density etc.) as well environmental conditions (porosity,
%permeability, depth etc.)

%To ensure the fidelity of the such simulations for real models, data
%from simulations is validated against experimental data. This process
%is referred to as history matching. In this process, a large number of
%simulations with different parameters or initial data, are run and
%their results fitted against the experimental data. When simulation
%results vary from experimental data, the input parameters are modified
%to bring the model closer to the real experimental data. This process
%is repeated until a consistency criteria is observerd. The fitting
%method can be anything from a genetic algorithm, an ensemble Kalman
%filter or a simulated annealing process.  Each has its merits and
%drawbacks.  One of the best methods to perform such convergence
%criteria is the ensemble Kalman~\cite{needreferencehere} filter
%method, and it requires a hard synchronization point where it gathers
%all the data from all the various models and modifies model parameters
%to get better history matching in the iterations to follow.

% Typical reservoir simulations can vary in size from 100 grid points to
% tens of millions of grid points, and a decent model space can contain
% upwards of hundreds of models each with possibly varying size,
% physical model (i.e equations to solve) and more importantly different
% rock and fluid properties.  

Ensemble Kalman filters (EnKF) are widely used in science and
engineering~\cite{DataAssim, KalmanPaper}. EnKF are recursive filters
that can be used to handle large, noisy data; the data can be the
results and parameters of ensembles of models that are sent through
the Kalman filter to obtain the true state of the data. The variation
in model parameters often has a direct and sizable influence on the
complexity of solving the underlying equations, thus varying the
required runtime of different models (thus the availability of the
results).  Varying parameters sometimes also lead to varying systems
of equations and entirely new scenarios. This obviously increases the
computational size requirements as well as memory requirements.  For
example as a consequence of the variation in size the underlying
matrix might become too large or even effectively doubling the number
of the system of equations, which could more than doubles the memory
required to solve the system of equations.
%Variation in non-linear terms in non-linear
%partial differential equations might also change the method used
%to solve the system of equations, which would vary the runtime as well
%as memory cost.

Hence a mechanism to assign models to available resources based on
their expected time to completion and resource requirement is useful.
Such a mechanism would estimate the time a model will spend in the
queue of a resource, the time it needs to run, and the time required
to migrate the data it requires/produces back and forth, and based on
that attempt to minimize the time required to perform each history
matching iteration.  In fact, with changing resource simulation
requirements (as is the case with models that find themselves lagging
behind the rest of the model pack), a mechanism which can take
advantage of of faster, cheaper or more powerful machines is even more
advantageous ~\cite{escience07}.

\begin{figure}
\begin{center}
\includegraphics*[scale=0.36,]{./figures/3StageKalmanFilter}
\end{center}
\caption{Schematic illustrating the irregular execution or
  hard-to-predict run-time characteristics of a prototype
  implementation of an ensemble kalman filter. The end-to-end
  application consists of several stages; in general at each stage the
  number of models generated varies. In the specific case studied in
  this paper, the size and granularity of the models varied within a
  stage. Consequently for any given stage the resource requirements
  varied from 8 processors to 64 processors.  The run time of each
  model was unpredictable and uncorrelated with the run-time of models
  on running on the same number of processors -- a truly independent
  variable. At every stage, each model must converge to within a
  specified value before the next stage can begin, hence dynamically
  load-balancing so as to ensure that all models complete as close to
  each other as possible is the desired aim.}
\label{fig:irregular_execution}
\end{figure}

\subsection{Application Outline}

The aim of our model application is to show the potential and ease of
use of a SAGA-enabled Cactus framework application. Our application
consists of a exemplary distributed simulation that uses the added
SAGA functionality to dynamically determine its ideal migration target
based on ad-hoc and statistical network characteristics and to migrate
itself in a heterogeneous Grid environment.  Although this a model
application it can be easily adapted to more complex scientific
applications.  Furthermore, our model application can be used as an
autonomous benchmarking agent for Grid resources. In this section we
briefly describe SAGA and the Cactus framework and discuss our
motivation to use SAGA to incorporate high-level Grid functionality
into Cactus.

\subsubsection{SAGA}

The Simple API for Grid Applications (SAGA) is an API standardization
effort within the Open Grid Forum (OGF)~\cite{ogf_web} an
international standards development body concerned primarily with
standards for distributed computing.  SAGA provides a simple,
POSIX-style API to the most common Grid functions at a sufficiently
high-level of abstraction so as to be able to be independent of the
diverse and dynamic Grid environments. The SAGA specification defines
interfaces for the most common Grid-programming functions grouped as a
set of functional packages.

\begin{itemize}
\item File package - provides methods for accessing local and remote
  filesystems, browsing directories, moving, copying, and deleting
  files, setting access permissions, as well as zero-copy reading and
  writing
\item Replica package - provides methods for replica management such
  as browsing logical filesystems, moving, copying, deleting logical
  entries, adding and removing physical files from a logical file
  entry, and search logical files based on attribute sets.
\item Job package - provides methods for describing, submitting,
  monitoring, and controlling local and remote jobs. Many parts of
  this package were derived from the largely adopted
  DRMAA~\cite{drmaa_url} specification.
\item Stream package - provides methods for authenticated local and
  remote socket connections with hooks to support authorization and
  encryption schemes.
\item RPC package - is an implementation of the GGF GridRPC
  API~\cite{gridrpc_url} definition and provides methods for unified
  remote procedure calls.
\end{itemize}

The two critical aspects of SAGA are its {\it simplicity} of use and
the fact that it is well on the road to becoming a community {\it
  standard}.  It is important to note, that these two properties are
provide the added value of using SAGA for Grid application
development.  Simplicity arises from being able to limit the scope to
only the most common and important grid-functionality required by
applications.  There a major advantages arising from its simplicity
and imminent standardization.  Standardization represents the fact
that the interface is derived from a wide-range of applications using
a collaborative approach and the output of which is endorsed by the
broader community.

The SAGA C++ reference implementation~\cite{saga_web} was incorporated
into the Cactus Code Framework in Ref~\cite{escience07} to provide the
needed Grid programming functionality.  We believe this was an
important step in merging two programming abstractions to achieve an
effect that is greater that sum of the parts. 

% The SAGA C++ reference implementation is being developed in close
% conjunction with the OGF standard.  Advert-service package which will
% most-likely be incorporated into a future version of the OGF standard.
% The SAGA C++ reference implementation comprise a complete set of local
% adaptors, an SQlite3 and PostgreSQL advert-service adaptor, and Globus
% pre-WS adaptors for file (GridFTP) and job (GRAM2) packages. We will
% go onto show how the application uses these features.

% \subsubsection{The Cactus Code~\cite{cactus_web}}
% Cactus~\cite{X0} is a framework for high performance scientific
% computing designed for scientists and engineers to develop and run
% codes for solving complex problems.  Developing code for high
% performance parallel machines has many challenges including
% scalability, efficiency (for computation, communication and
% input/output), portability and flexibility. Frameworks such as Cactus
% allow scientists and engineers to develop modules which can then be
% used together with modules written by other researchers to solve
% complex computational problems. The framework provides tools ranging
% from basic computational building blocks to complete toolkits that can
% be used to solve complex problems in astrophysics, computational fluid
% dynamics or other disciplines.  Tools developed in the Cactus Code
% framework run on a wide range of architectures including desktop PC's,
% supercomputers and computational Grids. Cactus and its associated
% toolkits are publicly available for download from the Cactus Code
% website.

% From an architectural standpoint, the Cactus Code framework consists
% of a central part (the ``flesh") and code modules (``thorns").  The
% flesh serves as a module manager, scheduling the routines of the
% thorns and passing data between thorns.  Thorns perform tasks ranging
% from setting up the computational grid, decomposing the computational
% grid for parallel processing, providing boundary and initial
% conditions.


%, communication of data from one processor to another,
%solving partial differential equations to input and output and
%visualization streaming. There are code modules that provide
%simulation control tools, such as the HTTPD thorn that sets up a web
%server for the simulation and allows researchers to control a
%simulation or view sample output from a web interface.  Thorns can
%also provide custom developed scientific or engineering applications,
%such as computational fluid dynamics or gravitational physics.
%
%Features of Cactus which make it particularly suited to take advantage
%of a Grid environment include its portability, architecture
%independent checkpoint and restart capabilities, steering interface,
%and a well designed interface in the flesh for providing information
%about grid variables, scheduling, parameters and so on.

%Cactus has been a driving application for many Grid computing
% projects.  An early experiment in 2000 called the Cactus
% Worm~\cite{X1} showed how any Cactus application could be autonomously
% migrated around the resources of the eGrid in Europe simply by adding
% a new thorn which used the Globus MDS, GRAM and GridFTP AP Is to access
% Grid capabilities. A later collaboration with the GRADS project added
% dynamic capabilities for resource selection and contract
% negotiation~\cite{X2}.  These experiences led to the EU GridLab
% project which experimented with Cactus migration as a driving
% scenario~\cite{X3}.

% Cactus was also used for early experiments in metacomputing, showing
% how incorporating adaptive techniques into the Cactus driver layer,
% such as dynamic load balancing, configuration of ghostzones, and use
% of data compression could lead to acceptable scaling for large MPI
% applications across multiple supercomputers. This work was awarded the
% Gordon Bell prize in 2001~\cite{Cactus_GordonBell}.

% \subsubsection{Why SAGA and Cactus?} 

% Because of the modular structure of Cactus, any functionality provided
% by a specific thorn is immediately available to any of the other
% thorns in the configuration. For this reason we implemented a set of
% new Cactus thorns providing an extensible set of functions allowing
% the collection of netperf~\cite{netperf_web} based network performance
% metrics. Additionally, the extensible nature of this set of thorns
% permits additional metrics for any Cactus based application in the
% future.  To integrate SAGA functionality into Cactus, a SAGA thorn was
% developed that provides the basic SAGA installation information
% (header files, libraries etc.)  to the thorns that require SAGA
% capabilities.  SAGA provides different packages with a consistent and
% uniform flavor, thus implementing thorns that have different
% functionality (performance measurement and migrate thorns) using
% different SAGA packages is preferable. Last but not least, using SAGA
% and Cactus enables applications to specify and customize the network
% performance characteristics that it needs; as we shall see later, the
% ability to do so is a very useful feature.

\jhanote{Place the following appropriately...}

\noindent {\it Automated Resource Selection at Runtime:} The Batch
Queue Predictor (BQP)~\cite{bqp, bqp_url}, is traditionally used for
determining the status of the queue resources available and static
resource mapping. What is enticing about BQP is that it provides
information that is of importance to the class of applications that we
are interested in, namely, the ability to predict with given
probability which resource and when a job (with a specified number of
processors and estimated run-time) is most likely to finish.  This is
typically harder to predict correctly than which resource a job with
specified characteristics is most likely to run first.  {\it The
  application uses BQP internally within an application to make
  resource selection decisions dynamically (at run-time, as opposed to
  static queries) and automatically (the logic of how to process BQP
  information is embedded in the application).}

\yyenote{Need a section about many/big-job, we use it and better talk
  about it} \jhanote{Yes, I agree -- we need a brief
  description. However we will need to be brief as space is limited
  and we can reference earlier work}

\jhanote{SJ to take from ICCS paper and add here..}

\yyenote{I am adding sections about Lazarus and its fault tolerance}

\jhanote{add stuff on bigjob}

\subsection{Lazarus}

\jhanote{Need to say, what the requirements are, establish very
  quickly why autonomics is the solution to the specific problem and
  then talk about the solution -- first the primitive (ie scripts)
  then the Lazarus (using BigJob and BQP).}
\yyenote{Addressed, please have a look}  
To reliably launch hundreds of reservoir simulations and collect the data
they produce repeatedly across different machines,
we needed a fast, easy to use abstraction, this lead to the use
of BigJob abstraction ~\cite{ICCS_paper, saga_royalsoc}.
After losing many jobs to various errors
such as running out of allocated diskspace, hardware failure
and file-copy failure, we quickly came to the conclusion that autonomy
and self healing are important features that we needed to incorporate 
in Lazarus to ensure all large scale history matching runs
complete successfully. With fault tolerance, we no longer wasted
thousands of SUs running simulations with missing/corrupt ensemble members.
On the other hand, the autonomy incorporated in Lazarus, while basic,
ensures that we optimize the job sizes to have a higher chance of getting
through the queue without delay and that simulations
that ran into issues or simply failed to run, are resurrected.

For the current implementation, we started off using simple, portable
python scripts -- based upon SAGA, that handles job-launching and data
migration. This makes Lazarus a modular,
scalable and extensible framework for autonomic applications based upon
the SAGA programming system.  Lazarus uses the bigjob
abstraction to launch simulations,
the SAGA file adaptor python bindings to move files from one machine
to another and BQP data from a small python wrapper around the BQP command line tool
to retrieve the optimal location and number of bigjobs required to satisfy the
computation power required.

Lazarus's healing ability depends on
user-defined tests on the data to make sure it
is not corrupt, missing, or otherwise defective. If a simulation is
found to be defective it is resubmitted to be run again. This self
resurrection ability overcomes some of the catastrophic errors
encountered when running large numbers of jobs such exceeding wall
clock time, running out of diskspace (resubmit on a different machine)
and of course node failure.

\subsubsection{Autonomy}
The Lazarus framework contains several aspects of autonomy: it has
self-configuration (deployment on resources), self optimization (using
BQP data), self monitoring (checking its own output) and of course
self healing (resubmission of faulty simulations). These aspects have
been implemented with varying level of intelligence: the self
optimization for example is a basic algorithm that uses BQP data to
assign big-jobs to resources, but does not take into consideration
bandwidth requirement and the cost of copying files across
machines. The self-healing on another hand can typically resurrect
jobs that fail due to node failure as opposed to software
failure. Many autonomic features of Lazarus will find their way into
the FAUST framework, where they will be improved to incorporate
sophisticated inherent intelligence.  

It is also worth mentioning the due to the correct programming
abstractions, we did not have to develop most of the tuning
mechanisms, but were able to write suitable interfaces to these
mechanisms.

\subsubsection{Fault Tolerance}
Lazarus has built in self-healing capabilities. These capabilities
rely on a tool-check/calibration test and output file checks. After
all simulations have finished and their output files are copied over,
Lazarus proceeds to perform a tool-check on a sane file. The purpose
of the tool-check is to make sure the tools that will be used in
checking the output files from the simulations are available and
behave according to expectations. Once the tools are verified, they
are used to check the output of all the simulations. If a simulation
is found to have missing, incomplete or otherwise faulty output, it is
flagged for resubmission.  After all output is checked, the faulty
simulations are resubmitted and upon termination, all output is
checked again. Upon success, Lazarus proceeds to the next stage.

\subsubsection{BQP}
Batch Queue Predictor ~\cite{bqp} is a tool that is available on a
number of TeraGrid resources that allows users to make bound
predictions of how much time a job of a giving size and duration will
spend in the queue.  This prediction is given with a degree of
confidence (probability) that the job will start before a certain
deadline (i.e. the time in the queue) and quantile. Quantile value is
in effect repeatability, that jobs of similar sizes and durations will
have the same wait time. This information is vital when
submitting jobs to various machines as the longer a job sits in the
queue, the longer the delay for the entire stage.  For our application
we use the BQP command line tools, that are called through a python wrapper
from the Lazarus script.


% \jhanote{Refine: } \yyenote{Fixed}
In a given resource list, the python wrapper around the BQP executable
finds the resource and queue where if submitted, a BigJob of a
given size and expected run time, will have a good chance (or high
confidence) of getting through the queue and start running the
earliest. Confidence is in essence the probability that the job will
run, and to obtain a confidence of 1.0, an unpractically high queue time is
required. In our applications, not knowing the granularity of the
available BQP data, we opted to use a confidence of 0.75
and a quantile of 0.75. The choices are logical but require, as planned,
a more detailed statistical analysis for effectiveness.

\jhanote{sensitivity analysis!! Can't just put
  0.75 out there!}  \yyenote{fixed, alternatively we can fix it by removing
  the mention of 0.75}
 
% This applied to the BQP thorn, we do not want this here anymore
%The information from the BQP thorn is retrieved
%for all simulations that need to be run, particularly the time in
%queue. The time in queue is added to the time required to run the
%simulator (which is a function of the number of nodes and resource
%used and is retrieved from regular application benchmarks) and the
%time required to transfer data (that is obtained from the PerfMatrix
%thorn).  That time would be the estimated time to completion a given
%models in a given history matching stage.

%To better predict ensemble behavior we have collected (using the same
%BQP Thorn but in a different configuration) detailed BQP data for four
%major teragrid machines. The collected data \yaakoub{Need to put in
%  tables and histograms} indicates that there are machines where
%confidence factors vary significantly over a given run-time. While the
%collected data requires detailed statistical and stochastic analysis,
%some useful information can be infered by observation. For example,
%the confidence of running a job of size XXX lasting YYY seconds varies
%by ZZZ with a deadline that varies from WWW to VVVV.  \yaakoub{Need to
%  pick a good example of a large variation, so far cobalt seems good,
%  lonestar perhaps....}  Suden jumps in the confidence factor or
%expected deadline given a minimum confidence factor can indicate a
%favorable or unfavorable machine/queue/job-size/job-duration
%combination. Further analysis is required, particularly considering
%that the application that is run as a job is a parallel-scalable
%application and can be resized to run on more nodes for a smaller
%time.

%\yaakoub{Shantenu this is what you meant by preventative/predictive}
%\jhanote{Yes, this conveys the flavour. I will go through the
%data and stick up an example or two of the ``preventive'' example}

% \subsection{Talk about additional 'irregular execution' applications}
% Having determined which M resources to use, the way forward could be
% using a Grid co-allocator such as HARC~\cite{harc_url}; that is,
% having identified the best M resources from a network performance
% perspective, we leave the co-scheduling of these M resources to HARC
% which is an implementation of Paxos (two-phase) Commit Algorithm. We
% will report on the interfacing of HARC with SAGA in the future.


\section{Application Implementation, Control Flow and Deployment}

\yyenote{This entire section is bad, we probably should move its bits
  about but as it stands it is meaningless} \jhanote{lets chat}

\jhanote{Place in a suitable place...}  Lazarus is distinct to other
well established and successful approaches such as Accord for
autonomic computing, in that it is not a component-based programming
system but it is a framework already composed of multiple
components. Importantly the programming system that is used is SAGA --
both for the application and the Lazarus framework.

\begin{figure}
\begin{center}
%\includegraphics[scale=0.34]{./figures/ApplicationArchitecture}
%\includegraphics[scale=0.34]{./figures/kalmanfilterlayer.png}
\includegraphics[scale=0.3]{./figures/Lazarus_01.jpeg}
\end{center}
\caption{\jhanote{Need to increase resolution!}  Lazarus -- An
  Autonomic framework}

\label{fig:application_architecture}
\end{figure}



%\subsection {Application Architecture} 

\subsection{Simulation Thorn}

This thorn implements the simulation routines for the various models.
Our models are mostly non-linear partial differential equations that
are discretized using finite difference methods and solved with a
Krylov subspace solver using PETSc. ~\cite{PETSc}. For a prototype
implementation we chose a multiphase, multicomponent fluid flow
through porous media simulator and implemented it in the Simulation
thorn in Cactus.
% Is an implementation of the IMPES: implicit pressure explicit saturation 
% method designed to solve two phase flow through porous media problems.
% This thorn requires the thorn {\tt IDBlackOil} to perform the quiescent
% initialization to ensure a balance between gravity and capillary forces 

% The equations we solve are the water and oil mass conservation
% equations with Darcy's law using the IMPES formulation as outlined by
% Aziz and Settari ~\cite{AzizSettari}.  We use a finite difference
% discretization for the implicit pressure equation which we then solve
% by an iterative solver (PETSc) ~\cite{PETSc}.

% \subsection{ResourceMap Thorn}
% The ResourceMap thorn maps the various models to available resources.
% Each reservoir model has its own parameters that influence the size of
% the model and the wall time it will need to finish. Estimates of the
% required wall time and memory footprint of the simulation are obtained
% from benchmarks that mimic the actual models. A simple estimate is
% constructed based on the number of iterations the model will run for
% and other parameters such as the size of the domain, the IO frequency
% etc...  The ResourceMap thorn needs to pass this information to BQP to
% obtain the "confidence" factor for its predictions.  \jhanote{In the
%   previous line, we need a set of clarifying remarks about how this is
%   derived. Does this help?}.  The ResourceMap thorn queries the BQP
% thorn for the best machine and queue combination that will start the
% model earliest at a high enough confidence (i.e above a specified
% threshold). This is done by iterating over a list of machines and
% their queues, with a constant expected run time and node count and an
% increasing ''deadline``, and retrieving the confidence factor of
% running before the ''deadline`` from the BQP thorn. If the confidence
% is greater than the threshold, the job is submitted. If after
% iterating over all machines and queues, we do not get a confidence
% factor higher than the specified threshold, the ResourceMap thorn
% submits the job to the machine/queue combination that had the highest
% confidence factor.

% \subsection{Submit Thorn} 
% The Submit thorn, as its name suggests, submits a job described by the
% ResourceMap thorn to a given resource. A parameter file for the
% reservoir simulator and submission script are created at the resource
% using SAGA. A SAGA job is then launched that performs the actual
% submission (e.g qsub job\_1701.pbs).

% \jhanote{Are we using PerfMatrix?}
% The PerfMatrix thorn takes care of the intrinsic network performance
% measurement and persistent storage of the results. Currently, the
% implementation uses netperf~\cite{netperf_web} to measure
% unidirectional end-to-end throughput. Netperf is implemented as a
% simple client-server model consisting of two executables:
% \begin{itemize}
% \item{netserver: the measurement endpoint waiting for incoming connections}
% \item{netperf: the initiator of a measurement connecting to a netserver endpoint}
% \end{itemize}

% The PerfMatrix algorithm uses a list of computational resources which
% are potential migration targets for the application. After starting
% up, the initial application spawns itself onto all available hosts.
% \footnote{This approach is different from the original non-centralized
%   spawning scheme shown in Fig.~\ref{fig:controlflow} The reason for
%   our implementation using centralized spawning is the Globus
%   Toolkit's (4.0.5) inability of full credential forwarding.} Once all
% jobs have been launched, the original spawning application first
% establishes netperf connections with all the spawned applications;
% this is followed by the spawned applications establishing netperf
% connections amongst each other, following the scheme shown in
% Fig.~\ref{fig:controlflow}.  The job spawning, control, and I/O
% redirection is done entirely using SAGA's job management package.
% Once a netperf process returns a throughput result, the PerfMatrix
% thorn uses the SAGA advert-service package to announce the result to a
% central PostgreSQL database which is also used as a centralized
% logging facility. After all netperf processes have finished and
% published their results, the database contains a host-to-host
% throughput performance matrix along with a timestamp which is
% available to other thorns as well as other applications.

\yyenote{Why do we have the advert DB section here?}
\jhanote{removed advert DB section. OK?}
% \subsubsection{Advert-service database} SAGA's advert-service package
% describes a key-value based hierarchical attribute interface for
% storing arbitrary application level information. The currently
% available adaptor is capable to map these structures to an relational
% SQL schema and store them in local (SQLite) and remote (PostgreSQL)
% RDBMS. SAGA's advert-service offers a convenient way to simplify the
% difficult task of centralized data collection and logging within
% distributed applications. The location of all the reservoir
% simulations, the start and finish time as well as the paths to the
% output files are all stored in the advert-service. The advert-service
% also contains the data collected from BQP and from NetPerf.

\subsection{Control Flow}

\begin{figure}
\begin{center}
\includegraphics[scale=0.29]{./figures/BreakdownDiagram.png}
\caption{Block diagrams outlining the basic structure of lazarus.
Left: from a user perspective, Lazarus launches ensembles with
Cactus simulation thorns and Cactus EnKF thorns. From a development
viewpoint (right) Lazarus is a small collection of python scripts built
on top of the BigJob abstration, the SAGA file-adaptor, a small
BQP python wrapper and fault tolerance scripts. Both BigJob
and File Adaptor are built on top of the SAGA Python bindings, BQP
is built on top of the BQP C interface and the fault tolerance uses
hdf5 tools to verify simulation data.
\jhanote{arrows need to be
    explained.. sorry but still difficult to understnad what this is
    all about}}
\end{center}

\label{fig:application_architecture}
\end{figure}


\begin{figure}
\begin{center}
 %  \includegraphics[scale=0.5]{./figures/SequenceDiagram}
\includegraphics[scale=0.18]{./figures/Lazarus_Workflow_Alternate.png}
\end{center}
\caption{\jhanote{I would put a simpler diagram here} A high-level
  overview of the control flow for the SAGA-Cactus based ensemble
  Kalman filter application. Models are generated and these are mapped
  to appropriate resources. This is done based upon the number of grid
  points in the model (which in turn determines the number of
  processors and memory) and the projected run-time (which is based
  upon estimated number of iterations). \jhanote{caption needs
    adjustment}}
\label{fig:controlflow}
\end{figure}

The application starts by getting BQP data for a list of candidate
machines, assigns simulations to machines and submits the jobs to the
respective machine scheduler. Once all the simulations are submitted,
the history matching application (in our case a Kalman filter) is
submitted to run. The Kalman filter application is run on the
machine that will run 50\% or more of the entire simulations or the
machine that has the highest bandwidth amongst the machines used for
the simulations.  Once the simulations start, they notify the advert
service of their starting time and location; upon successful
completion, they also notify the advert service of the path of the
files they output.  Meanwhile the history matching application is
notified of the completion of the simulations and modifies the models
used in the reservoir simulation. The modified models are then
submitted again as a second stage and the entire processes is
repeated.

% \subsection{Interfacing with Google Maps}

% The application level information about the collected BQP and Netperf
% data is stored in a central location using the SAGA advert service
% facilities. The stored information is usable not only by the
% application itself, but is accessible from separate tools allowing to
% monitor the application progress. To make this information readily
% available to the user we developed a Google Maps~\cite{google_maps}
% based user interface presenting the live BQP data for each of the
% resources as shown on the map (Figure \ref{fig:gmaps_bqp} shows a
% screen shot of this web interface displaying BQP data for the {\tt
%   datastar} machine at SDSC). We will add support for displaying the
% Netperf based network performance information for each of the network
% interconnects as shown on the map as well, as well as extend to show
% the physical distribution of sites where jobs are running and the
% number of jobs at a site.

% Our Google Maps application architecturally consists of two parts.
% The client (browser based) side is implemented using Java scripts,
% which is the standard way of using the Google Maps API. The server
% side (generating the html as requested by the client) is implemented
% as a Python based CGI application. We use the SAGA Python API bindings
% to access the BQP data stored in the advert service and to generate
% the html to display at client side. Whenever the user clicks on one of
% the markers or lines in the map we request the corresponding
% information from the server by invoking a server side Python CGI
% script. The returned html is displayed in the Google Maps info window
% pointing to the marker or line the user clicked on.

% \begin{figure}
% \begin{center}
% \includegraphics*[scale=0.34, trim=15mm 33mm 15mm 33mm]{./figures/gmaps_bqp}
% \end{center}
% \caption{Google maps application showing the live BQP data retrieved
%   from the central advert service using the SAGA Python bindings
%   (\url{http://fortytwo.cct.lsu.edu/teragrid/teragrid.html}).}
% \label{fig:gmaps_bqp}
% \end{figure}

%\section{Infrastructure Used \& Deployment Details}
\jhanote{this needs major rewrite. Yaakoub to work on this.}
\yyenote{Fixed. Why do we have this section again? It really ought to be removed, we dont use the features that were here}

For our runs we chose three large Teragrid machines: Ranger, QueenBee
and Abe. Those machines were chosen because of their large size, extensive software
stack and of course the fact that BQP has data on all three machines. The 
deployment of applications across these three heterogeneous machines
belonging to different organizations can be a difficult
task. Different versions and availability of libraries and compilers
makes every single machine a unique environment. Although it is
technically possible to stage-in all required applications and
libraries and even to compile the application sources on the fly using
SAGA, we decided to deploy pre-build binaries on all machines since
this exercise is not part of this work's focus.


\yyenote{Made this into its own section}

\section{Failure Modes}

\jhanote{Which failure modes are relevant here? Remove those that are
  not}\yyenote{Fixed}

As expected we ran into various problems when deploying this
framework, many were errors that are irrecoverable and resulted in a
cold restart from scratch. Those can be outlined as follows:

Hardware failure:
\begin{itemize}
\item{Lost a compute node from the pool}
\item{Lost a network connection to a machine, BQP or the advert service}
\item{Could not write to /scratch because it was taken down for maintenance}
\end{itemize}
From all of these modes of failure, we found that we reliably recover
from node failure and failure to write data to disk, but not network failure. The
status of any given job is reported in a one-way poll for current state. This
has obvious limitations so we will also be using the "heart-beat" monitor in FAUST
once it is available.

Software environment failures:
\begin{itemize}
\item{Missing or wrong shared libraries}
\item{Wrong or inadequate environment variables}
\item{Run out of quota on disk, wrote too many files to the same directory}
\item{Run out of SU's in the allocation}
\item{No internet connection to the compute nodes (no BQP, no advert service)}
\item{MPI error that causes a simulation to stall (this happened because of a faulty installation and was corrected)}
\end{itemize}
In software environment failures, typically jobs terminate with errors or 
are killed, before the simulations results are written to disk. Unsurprisingly we ran
into all of these failures while developing Lazarus, and were able
to recover from all of them except for the network connectivity in the compute
nodes, as this would register the job's state as "unknown". This would be solved
with the aforementioned heart-beat monitoring system in FAUST.

Actual simulation failures:
\begin{itemize}
\item{Missing parameter files or executable}
\item{Wrong parameter files, or erroneous setup of parameter files}
\item{Divergence in the solver, causing NaN shuffling and leading to exceeding the requested wall clock time}
\item{Under-estimation of the required wall clock time}
\item{Hitting /scratch or /home too often (because of checkpointing), leading to very low access speeds and exceeding the requested wall clock time}
\end{itemize}
Some of the simulation failures are relatively easy to guard against,
namely the wrong parameter file or missing executable. The other errors
however are harder to detect and rectify.

\subsection{Needs to be Moved}
One of the recent improvements in deployment is the use of the python
bindings to the SAGA-based bigjob abstraction \yyenote{I think the
  name here should change as this is not really FAUST yet but loosely
  labelled FAUST}. \jhanote{Yes, I agree. Dunnit} 
Using these scripts, a user-specified number of stages each containing
a user-defined number of models can be launched to the grid. As the
models of a given stage run to completion, a second set of
error-checking jobs are launched that ensure all the models ran to
completion before the Kalman gain calculation is performed. This
error-checking mechanism attempts to re-submit the failed jobs, and if
met with failure a second time, the stage is halted to allow for user
intervention. \yyenote{that is what I am implementing at the moment}

\jhanote{Mapping: Need discussion on the two-levels of decision
  making. I thought we had done this!}

\begin{itemize}
\item Mapping of physical-model requirements into compute-resource requirements
\item Mapping compute-resource requirements into available resources
\end{itemize}
\jhanote{The latter could be done via BigJob Abstraction or without
  (statically map to an available resource, with or without the aid of
  BQP).  The advantage of BigJob abstraction (and ultimately FAUST) is
  the flexibility it provides -- wanna call is late binding? or
  loose-coupling..  call it what you may.}

\jhanote{there is the following blurb from the ICCS paper whcih we
  should either incorporate or acknowledge} We have developed a
mechanism whereby EnKF can be solved using multiple-resources, using
application-level scheduling applied dynamically~\cite{saga_tg08}, ie
mapping the sub-tasks requirement to the resources available at the
instant the sub-tasks become available and ready to run, as opposed to
{\it a priori} static method of job submission.  For the problem size
studied, the sub-tasks required mostly less than 32 processors. For
this paper we used the earlier developed frameworks and deployed it on
a single large machine -- NCSA's Abe. A mechanism (multiple,
distributed versus single machine) that is more efficient for physical
models with sub-tasks that have typically low processor counts, will
not necessarily be the more efficient as the typical sub-task size
increases. Therefore it is crucial that any general-purpose solution
be usable on both single large machines to multiple machines.  We can
enhance throughput further by applying the Glide-In mechanisms
discussed in the earlier section, which facilitate dynamic tasks being
aggregated from similar sub-tasks. We will report on the results of
this and whether the framework can be used on high-end petascale
supercomputers in future work.


\section{Experiments: Results and Discussion}

In this section, we discuss the Experiments we performend, but first
we discuss the design of the experiments.

As alluded to Grids are dynamic and in principle provide an effective
infrastructure for applications with dynamic resource requirements, as
well as hard-to-predict resources. The underlying motivation for these
experiments is to first establish that the Lazarus framework enables
the effective utilization of Grid resources. The second, design
decision for experiments is to determin if autonomic behaviour -- in
this case, the ability to use system-level information to decide which
resources to use dynamically, as opposed to the manual
intervention/decision, can lead to performance gains.

\jhanote{Yaakoub, please put in a paragraph about the workload}
\yyenote{Done}
The workload is defined as reduced version of a typical history matching
run. We start with an ensemble of one hundred members and we need to perform
five analysis/Kalman-filter runs. Since this sample workload is representative of the size of a typical large history matching run and a reduced form of its duration,
any consistent reduction in the total time to completion will eventually
have a larger impact on larger runs with more stages.

We define the \tc as the time in seconds it takes to complete the
workload. There are several components to the \tc. First, is the time
that it takes to submit to the queuing system, file-transfer (in and
out). In a way this is overhead, and we label this as $t_{overhead}$.
The second component is the time that the submitted jobs wait in queue
for resources requested to become avialable. We label this as
$t_{wait}$; the final component is the time the runtime that
simulations actually take to complete, which we label as
$t_{run}$. Thus: \tc = $t_{overhead}$ + $t_{wait}$ + $t_{run}$.

In the first stage of experiments, we determine the \tc for a single
TG machine, but repeat the experiment for different TG machines and
repeat 4-5 times at different times of the week, so as to get
uncorrelated data.  This provides a measure of base-line performance.

We then, repeat experiments using more than one computational resource
on the TG. To be precise, we employ more than one computational
resource towards the solution of a single instance of the problem.
Given that are experiments are capable of utilizing three different TG
resources, using two-resources at a time, gives us three different
combinations. As the results from the single-resource configuration
show, the individual resources have somewhat different intrinsic
performance, which should be factored when taking into account the
combined peformance. As a logical extension, we perform an experiment
wherein we utilize all three different TG resources.  An important
result, that holds in general, but also for the specific instances
investigated here, is that on average, as the number of resources
increases the \tc to solution decreases. This is evidenced from the
fact \tc for (R,Q) is lower than \tc (R) or \tc (Q). The large error
bars ar due to the fluctuations in the waiting times; it is important
to point out that the $t_{run}$ decreases, but the overall number of
CPU hours utilized does not increase. This is a reconfirmation of
the use of higher-level abstractions for enhanced performance.

In the final experiment, we utilize a type of information service --
BQP (for queue prediction) and incorporate it into the Lazarus
framework and make use of it through autonomic behaviour.  As the
right most datapoint shows, the utilization of BQP to determine which
resources and which configuration are used leads to a drastic
reduction in \tc compared to the simple case where Lazarus framework
was used with autonomic behaviour. This is a very powerful
demonstration of the fact that autonomic behaviour -- however
elementary, can lead to signficantly improved performance.

\begin{itemize}
\item Define workload.
\item Determine  \tc when using 1 machine 
\item Determine \tc when using same machine over 5 day average i.e. repeat 5    times, at least 3 times
\item Determine \tc when scaling upto 2 machines, 3 machines 
\item point out fluctuation in work-load and response time
\item point out that the experiment was repeated 4 times for non-BQP
  cases and repeated 3 for the BQP case (with experiment ongoing on
  the 4th experiment).
\end{itemize}

\begin{figure}
\begin{center}
\includegraphics[scale=0.34]{./figures/ErrorBarPlot.png}
\end{center}
\caption{From Left to Right: (i) Ranger, (ii) Queen Bee,
  (iii)Ranger+QueenBee, (iv) Ranger+QB+Abe, (v) BQP-All
  Machines. \jhanote{ Need to refine... Need higher resoultion graph!!}}
\label{fig:application_architecture}
\end{figure}

\begin{table}
\begin{tabular}{|c|c|c|c|c|}
\hline Sample \# & Machine & Queue & Num. Cores & Duration (hrs) \\ 
\hline 1-3 & Ranger & development & 64 & 1:30 \\ 
\hline 1-3 & QueenBee & checkpt & 128 & 2:00 \\ 
\hline 1-3 & Abe & normal & 64 & 2:00 \\ 
\hline 4 & Ranger & development &  & - \\ 
\hline 4 & QueenBee & checkpt & - & - \\ 
\hline 4 & Abe & normal & - & - \\ 
\hline 
\end{tabular} 
\caption{A table with the results of the resources used and in
  the configuration of the resources -- as determined, by the
  number of cores, duration and queue. The decision on
  resource and resource configuration is aided by BQP -- which 
  makes a locally optimal decision. \jhanote{we need to repeat
    this experiment a few times; based upon the outcome we should either
    mention that BQP always gives us this configuration, or hopefully we
    can say that BQP selects differently}}
\end{table}

\section{Challenges and Discussion}

\jhanote{Yaakoub to do}
\yyenote{Doing, have a look}

\begin{itemize}
\item Talk about the fixed granularity of BQP and the problems that this
engenders
\item Talk about fault-tolerance
\item Talk about how different machines have different queing policies
  and how an autonomic system like Lazarus can ``probe'' the queing
  system to understand the non-public policy and adapt irrespective.
\end{itemize}


\jhanote{What are the fault-tolerance issues that are encountered?
  How do we solve them? How could they be solved by using SAGA-CPR
  (just sketch out changes that need to be undertaken)}

\jhanote{need to reference prior work done by Manish on autonomics and
  on oil resorvoir in particular. What makes our work different?  Can
  the two converge? SAGA-Accord?}
\yyenote{Yes and no, physics and problems we are solving are different, 
but yes we can converge. I would not say interchangable, because well 
optimization studies do not require a global sync like we have in the EnKF
Added stuff in the intro about Manish, hope he likes it}  

The advantages of constantly running jobs on machines is the development
of an intuition to the state of the machine through constant use. This is
quantified in confidence numbers from BQP. Interestingly enough, we could
discern a higher chance of running before deadlines during weekends than
weekdays, and how some machines favor larger jobs that have short durations
and how other machines favor the opposite.

A major issue in our use of the BQP is the confidence and quantile numbers.A detailed
analysis is required to better quantify what those numbers mean when submitting
many bigjobs across different machines, and how the choice of confidence and quantile
ultimately affect the total wall clock time to completion.

Since we collected data from BQP without knowing it's granularity, we tend to
oversample the data to avoid undersampling and obtaining a misrepresentative view.
This obviously leads to a small (order of minutes) computational cost but is an issue
that needs to be addressed.

Perhaps the biggest challenge we encountered, and most frustrating, was failure
that went undetected, and lead us to waste SUs, hours in the queue and of course
hours waiting for results that were corrupt. Many of these modes of failure
can be solved using a heart-beat from the actual simulation to a monitoring service
that allows the simulation to register its current state, current iteration, progress rate,
state of data, convergence data from the solver etc... This will be implemented
using the SAGA C++ API in Cactus as a heartbeat thorn, and the monitoring service
will be implemented as a functionality in FAUST.

\section{Future Work and Conclusion}

In this paper we have demonstrated the very first beginnings of the
SAGA-based framework (Lazarus) that can be utilized by a broad range
of different applications to utilize Grids for autonomic computing.
Lazarus is distinct to other well established and successful
approaches such as Accord for autonomic computing, in that it is not a
component-based programming system but it is a framework already
composed of multiple components. Importantly the programming system
that is used is SAGA -- both for the application and the Lazarus
framework.

for autonomic computing such as Accord, in that is not really 



Developing both applications and tools using SAGA is an effective
mechanism for ensuring inter-operability across different middleware
distributions -- even at the application level -- something that is
arguably missing in current Grid Interoperation
efforts~\cite{gin_paper} Many challenges remain, but the main are,
program environment heterogeneity -- development, deployment and run
time across resources.  With grids there is the additional
complications of cross-administrative or virtual organizations; as our
paper exclusively uses the TeraGrid, which can for all practical
purposes and intent be considered a single virtual organization, we
are not encumbered by any additional burden. These are serious
challenges for all applications even those that would like to utilize
more than one resource in a decoupled fashion (for example parameter
sweep).  However the seriousness of the heterogeneity problem is
highly aggravated when an application needs to utilize resources in a
coupled manner.

The widespread availability of SAGA (and SAGA adaptors) is an
important step towards the creation of distributed applications that
can be universally deployed (i.e.  independent of the details of the
resource's middleware and configuration detail).  Our experience
should serve as useful input to the community -- resource providers
and middleware developers - to support the development and deployment
of SAGA.  We hope to motivate  resource providers such as the TeraGrid
(as well as middleware developers) to support the SAGA programming
abstractions and thereby help engender applications, as well as
contribute to the development of SAGA , SAGA adaptors as well as
deploying these SAGA adaptors.

We will in the future compare the performance of the execution of such
applications using a meta-scheduler such as GridWay, which although
possibly quicker for some instances will not be as scalable and
extensible. Motivated by the scalability and general purpose solution
we have discussed in this paper, we will go on to generalise to other
applications that exhibit similar characteristics~\cite{nature99}.

\jhanote{Need to make connection, or announce the arrival of FAUST}



% We created a single set of Globus adaptors and deployed them on
% distinct Grids. Our application successfully utilized these
% adaptors, without any further customization, which goes to show that

%We also discussed how the deployment of this model application across
%two distinct Grids was trivial as it only required the deployment of
%of the appropriate SAGA adaptors.  



% There are many applications that need to use federated
% Grids~\cite{clade06, gin_paper}.  Utilizing SAGA to develop, or at
% least provide Grid-functionality is a useful strategy. Therefore, if
% the development and deployment of applications across federated grids
% is to be facilitated, SAGA adaptor activity -- development and
% deployment, needs to be self-sustaining and thus requires explicit
% support, from both the middleware developers and resource providers.

% The success of e-Science critically depends upon the availability of
% e-Infrastructure.  But the promise of e-Science will be hollow without
% delivery of the applications and application-enabling paradigms and
% technology that can effectively utilize this new infrastructure. We
% believe SAGA is an important first step in this direction.

\section{Acknowledgements}
SJ acknowledges UK EPSRC grant number GR/D0766171/1 for supporting
SAGA and the e-Science Institute, Edinburgh for the research theme,
``Distributed Programming Abstractions''.  SJ also acknowledges
financial support from NSF-Cybertools and NIH-INBRE Grants. This work
would not have been possible without the efforts and support of other
members of the SAGA team.  Additionally, we would like to acknowledge
help from the LONI support team and CyberInfrastructure Develompent
group. Y. El-Khamra would like to acknowledge Prof. Chris White,
Prof. Mayank Tyagi and Dr. Xin. The authors acknowledge the Texas
Advanced Computing Center (TACC) at The University of Texas at Austin,
The LONI institute and NCSA for providing HPC resources that have
contributed to the research results reported within this paper. This
work has been made possible thanks to the internal resources of the
Center for Computation \& Technology (CCT) at Louisiana State
University.  

\bibliographystyle{IEEEtran} 
\bibliography{saga_tg08}
\end{document}

