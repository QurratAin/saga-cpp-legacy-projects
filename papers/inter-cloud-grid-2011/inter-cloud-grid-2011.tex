\documentclass[10pt,conference,final,letterpaper,twoside,twocolumn,]{IEEEtran}

\usepackage{graphicx}
\usepackage{color}
\usepackage{url}
\usepackage{ifpdf}
\usepackage{hyperref}
\usepackage{xspace}

\setlength\parskip{-0.015em}
\setlength\parsep{-0.15em}

\newenvironment{shortlist}{
	\vspace*{-0.85em}
  \begin{itemize}
 \setlength{\itemsep}{-0.3em}
}{
  \end{itemize}
	\vspace*{-0.6em}
}

\usepackage{fancyhdr}
\setlength{\headheight}{16.0pt}
\pagestyle{fancy}
\headheight = 0pt
\headsep    = 25pt
\fancyhf{}
\fancyhead[OC]{\bf {\it \footnotesize{Jha et al: A Case for SAGA as an Access Layer for DCI}}}

\newif\ifdraft
\drafttrue
\ifdraft
 \newcommand{\amnote}[1]{  {\textcolor{magenta} {***AM: #1}}}
 \newcommand{\jhanote}[1]{ {\textcolor{red}     {***SJ: #1}}}
 \newcommand{\tmnote}[1]{  {\textcolor{blue}    {***TM: #1}}}
\else
 \newcommand{\amnote}[1]{}
 \newcommand{\jhanote}[1]{}
 \newcommand{\tmnote}[1]{}
\fi

\newcommand{\dn}{\vspace*{0.33em}}
\newcommand{\dnn}{\vspace*{0.66em}}
\newcommand{\dnnn}{\vspace*{1em}}
\newcommand{\uppp}{\vspace*{-1em}}
\newcommand{\upp}{\vspace*{-0.66em}}
\newcommand{\up}{\vspace*{-0.33em}}
\newcommand{\shift}{\hspace*{1.00em}}

\newcommand{\T}[1]{\texttt{#1}}
\newcommand{\I}[1]{\textit{#1}}
\newcommand{\B}[1]{\textbf{#1}}
\newcommand{\BI}[1]{\B{\I{#1}}}
\newcommand{\F}[1]{\B{[FIXME: #1]}}
\newcommand{\TODO}[1]{\textcolor{red}{\B{TODO: #1}}}

\begin{document}

\title{Towards Grid-Cloud Interoperabilty: A Case for SAGA as Access
  Layer for OCCI backed Cloud Infrastructures}

\author{Shantenu Jha$^{*1,2}$, Thijs Metsch$^{3}$, Andre Merzky$^{1}$\\
  \small{\emph{$^{1}$Center for Computation \& Technology, Louisiana State University, USA}}\\
  \small{\emph{$^{2}$Department of Computer Science, Louisiana State University, USA}}\\
  \small{\emph{$^{3}$Platform Computing, Germany}}\\
  \small{\emph{$^{*}$Contact Author \texttt{sjha@cct.lsu.edu}}}
  }

\maketitle

\section*{Abstract}

\section{Introduction}
\label{sec:intro}
 

 % Outline:
 % 
 % - Why Interoperability? [Cloud-Grid, Cloud-Cloud] discuss using
 %   Application exemplars
 %
 % - How? discuss ALI vs SLI, fast-track vs deep-track
 %
 % - What? We propose - using SAGA on OCCI -- which is ALI using SLI
 %   (protocols)
 %
 % - This document discusses how we will implement and architect our
 %   approach, the advantages inherent in our approach from an
 %   applicaiton point-of-view


 Distributed infrastructures have been used by many applications to
 advance understanding in their disciplines.  The requirements and
 characteristics of applications that motivate the usage of
 distributed infrastructures are very broad, and most often differ
 from regular, HPC and HTC type applications in several fundamental
 ways.  Distributed applications often need to be designed for more
 than simple peak-utilization, e.g., the number of coupled tasks that
 need to be completed within a time window.  Equally important,
 distributed applications have a much broader range of usage
 modes~\cite{dpa-paper}.

 In particular for grids as one possible DCI infrastructure for
 distributed applications, standards have been playing an important,
 and in fact leading, role by ensuring application and system level
 interoperability~\cite{gin,saga-gin}, so that the required usage
 modes are (a) supported by the range of production grids available,
 and (b) that distributed application are able to scale beyond the
 boundaries of any single production grid~\cite{grid_scale_out}.

 Clouds are increasingly used to complement and expand the set of
 infrastructures for distributes applications.  In parallel, efforts
 to expand application and system level interoperability from grids
 towards clouds are emerging.  This paper motivates the need for such
 interoperability, and discusses one (of many) possible approaches,
 with the significant distinction of focusing on standards.

 The remainder of the paper is structured as follows: \F{needs
 completion}


\section{Interoperability}
\label{sec:interop}

 \subsection*{Applications Requiring Grid-Cloud Interoperabilty}

 To motivate the discussion in this paper, we shortly describe two
 real-world use cases which have been driving grid and cloud
 interoperability efforts in the recent past.  One is a data-intensive
 application -- a genome analysis tool BFAST; the other is more
 compute intensive -- ensemble based MD simulations.
 
 \BI{BFAST}: Next-Generation gene Sequencing (NGS) machines produce
 significantly larger amounts of data compared to early sequencers.
 In addition to the challenge of data-management that arise from
 unprecedented volumes of data, there exist the important requirement
 of effectively analyzing the data.  In this paper, we use
 BFAST~\cite{bfast2009,bfast2009b} -- genome-wide mapping application,
 as a representative example of the typical analysis that is required
 on data from NGS machines.  BFAST is representative of a diverse set
 of applications aimed at genome-wide analysis.
 
 Such features include i) a requirement of input files containing
 sequence information of a reference genome or short reads from NGS
 platforms ii) a production of output files that is generally written
 with a format that is successively injected to another tool as input.
 These aspects, along with a huge variation in the data volume in
 input, output, or temporary files, often require that the execution
 environment should scale-up (range of parallel, multi-threading
 executions on a single resource), as well as scale-out (range of
 distinct resources and distribution).
 
 BFAST requires a reference genome sequence and NGS platform generated
 short reads initially and prepare input files with pre-defined
 formats.  Then, the program carries out indexing of the reference
 genome, finding Candidate Alignment Locations (CALs), local alignment
 of CALs, and post-processing of alignment results, which taken
 together produces the mapping of billions of short reads onto the
 target reference genome.  Among the steps, three steps (index, match,
 loalalign) demand most of computing times and computing requirements
 with the size of a reference genome as well as volumes of short
 reads.
 
 \BI{Ensemble-based MD simulations} are commonly used bio-molecular
 simulation approaches to enhance the sampling and convergence for
 biomolecular simulations.  Ensemble based approaches represent an
 important and promising attempt to overcome the general limitations
 of insufficient time-scales, as well as specific limitations of
 inadequate conformational sampling arising from kinetic trappings.
 The fact that one single long-running simulation can be substituted
 for an ensemble of simulations, make these ideal candidates for
 distributed environments.  This thus provides an important general
 motivation for researching ways to support scale-out and thus enhance
 sampling and to thereby increase ``effective'' time-scales studied.
 
 In Ref.~\cite{ccgrid10, cloudcom10}, we have implemented the
 computational and coordination pattern represented by RE on different
 Clouds -- IaaS (Eucalyptus and Nimbus-based) and PaaS (Azure), by
 extending the BigJob framework to utilize the native abstractions
 provided by these Clouds, e.g., such as worker roles on Azure --
 storage and affinity groups.
 
 \amnote{What is 'RE' in the previous paragraph?}


 \subsection*{Ways to Interoperability}
 
 There are two major approaches to allow applications, such as the
 ones described above, to interoperably use DCIs: system level
 interoperability (SLI) and application level interoperability (ALI).
 SLI is the (often standards based) approach to federate multiple DCIs
 on middleware and operational level, and to allow applications to use
 the combined set of resources as if it were a single DCI.  That
 implies the exchange of accounting, authorization, authentication,
 logging, brokering and resource management information, and others,
 on system level.  Very often, SLI is implemented as delegation from
 on DCI to the other.

 ALI on the other hand does not require any activity on infrastructure
 level at all, but instead relies on the ability of the application to
 utlilize multiple independent DCIs at the same time.  While ALI is
 usually easier to achieve, it is burdening the application layer
 with the task to abstract the differences between DCIs.  Further, ALI
 based systems are inherently less sophisticated and less complete
 than SLI based systems -- for example, data transfer across DCI
 boundaries will need to be routed via the application layer,
 accounting can't be managed on application layer at all, etc.


 \subsection*{Grid Interoperability and Standardization}

 The very idea of grid computing has been founded on the idea of
 interoperability -- otherwise the original grid vision of pervasive
 compute power from a wall plug would be impossible from the
 beginning~\cite{blueprint}.  We have all been learning the hard way
 though that 'the grid', as a *single* pervasive entity, does not
 exist, and likely is not achievable, nor desirable -- too different
 are the application requirements to computing (and data management,
 and communication) so that an all-sufficient grid infrastructure
 would be too complex to design, implement, and operate~\cite{ogsa-use-cases}.
 Instead, a wide variety of grid middleware systems and grid
 infrastructure deployments emerged, more or less specifically
 taylored to the needs of certain application and user requirements.
 However, at least in academia, standards have always been playing an
 important role for grid computing, as it was soon understood that
 interoperability between different grids was difficult to achieve
 without standardization, if at all~\cite{...}.

 There are however more boundary conditions to interoperable grid
 infrastructures than standardized interface definitions and
 protocols: operational concerns, and in particular security and
 accounting issues, have shown to be a major impediment to really
 usable grid SLI~\cite{gin-usecases}.  The efforts of OGF groups like
 HPC-BP, GIN and PGI are, to a large extent, revolving around those
 issues, trying to separate interoperability from
 interoperation~\cite{gin-papers, ogf-www}.

 While not being able to solve any system level interoperational
 issues, ALI approaches have shown to provide similar levels of rid
 interoperability with significantly less effort, and improved end
 user experience.  We have been showing that SAGA based ALI is one
 possible incarnation of application level grid interoperability, with
 the additional benefit of being standards based~\cite{saga-gin,
 mandelbrot-www}.



 \subsection*{Cloud Interoperability and Standardization}

 The need for cloud standards and interoperabilty can be appreciated
 from a technology as well as an application perspective. One example
 of a technology pull for standardization is provided by need for
 interoperability across {\it Specialized Clouds}, i.e., emerging
 customized clouds that support specific capabilities or services,
 analagous to HPC grids (TeraGrid) versus HTC grid (Open Science Grid)
 or Data Grids (EGEE).  The application push can be understood by the
 imperative to operate on massive amounts of data {\it in situ}, which
 in turn involves computation across heterogeneous distributed
 platforms as part of the same application.  For example, the Earth
 System Grid involves peta to exa-bytes of data, and one cannot move
 all data (given current transfer capabilities), nor compute at a
 centralized location.  In addition, there exist a wide range of
 applications that have decomposable but heterogeneous computational
 tasks. It is conceivable, that some of these tasks are better suited
 for traditional grids, or on a specific cloud over another, e.g.,
 applications in the LEAD project, some workloads might be better
 placed on a data cloud whilst some may optimally be located on
 regular clouds or even grids, due to different data-compute affinity
 requirements amongst the tasks. \amnote{the previous sentence need
 stringer wording, and support from real use cases / references.}

 It is worth mentioning that most \I{existing} efforts at cloud
 interoperability are at the service managment, cloud network or
 federation level, and thus SLI.  Only few standard based efforts
 exist on that level.  Notably, OCCI aims to provide remote management
 protocol and API specification for IaaS clouds.  It complements
 related standards of SNIA and DMTF, while competing with more
 proprietary approaches such as those from VMware or Amazon.  Even
 fewer efforts target grid-cloud interoperability on system level: the
 inherent technology devide is considered a significant impediment for
 grid-cloud SLI.  A notable exception is the DCIFed working group at
 OGF~\cite{dcifed-www}.
 
 % Even fewer interoperability efforts exist on cloud-ALI, and are based
 % on non-standardized APIs (such as Amazon's EC2-API).  We aim to
 % provide the first such application-level interoperability built on
 % the back on existing community standards and efforts.  
 


 \amnote{Thijs, please re-check the next paragraph - not sure if that
 is still valid}

 OCCI has been able to gather significant community and industry
 support and uptake, e.g., early uptake in community driven cloud
 stacks (OpenNebula, OpenStack, Eucalyptus etc).  OCCI is however, a
 REST-ful protocal rather than an interface definition, and will thus,
 at least initially, experience different, likely non-interoperable
 implementations.  OCCI will thus make cloud interoperability easier,
 but not simple {\it for the application developer or user}.  But by
 integrating SAGA with OCCI we can provide broad coverage for
 applications, i.e., SAGA as the application/client API to OCCI should
 be able to shield an application from the specific OCCI
 implementations as well as provide grid-cloud interoperability.


\section{SAGA: the Simple API for Grid Applications}
\label{sec:saga}

 SAGA has been presented and discussed in detail
 elsewhere~\cite{sagapub...}, and has been used for application level
 interoperability before~\cite{sagainterop...}.  This section shortly
 summarizes the relevant findings.

 SAGA is an acronym for "Simple API for Grid Applications". As the
 name suggests, a simple API which facilitates the development and
 execution of distributed applications on most types of distributed
 infrastructure.  Modern distributed computing environments are very
 complex infrastructures, and allowing applications to make use of
 these complex systems is not trivial.  By defining a simple API, one
 requires those complexities to be dealt with at levels other than
 application code and development.  Simplicity of the interface is the
 primary design principle and objective of SAGA.  The fact that SAGA
 is a (set of) OGF standard(s)~\cite{sagaspecs...} ensures the
 community-wide adoption and stability of the API.  Functional goals
 of SAGA are:

 \begin{enumerate}

  \item Provide a stable programming interface to distributed
  application programmers and tool developers
 
  \item Shield developer from heterogeneous and evolving
  infrastructures and middlewares

  \item By providing the building blocks to distributed and remote
  operations enable the expression of high-level abstractions and
  support of distributed application requirements

 \end{enumerate}

 The SAGA standardization effort is closely syncronized with other
 specification and community efforts, within and outside of OGF.  In
 particular, OGF groups ensure that SAGA semantics map well to lover
 level specifications, such as JSDL, BES, GridFTP, etc.   But also,
 and possibly more importantly, it is now widely and independenly
 acknowledged~\cite{XD,EGI,UMD,Naregi} that a uniform, simple and
 stable access layer is neccessary (but not sufficient) to improve end
 user experience on distributed computing infrastructures, and that
 SAGA can indeed play that role for a specific set of use cases.  As
 such, SAGA is now integral part of the GIN (Grid Interoperation Now)
 community effort, and also plays an active role in current efforts
 like OGF's PGI group and US's XD proposals.
  
 Although SAGA is foremost an API, the SAGA distributions support end
 users in a variety of ways.  In particular, the SAGA distributions
 also include command line tools implemented via the SAGA API, and
 higher level libraries for common distributed programming patterns,
 also basing on the SAGA API.


 \subsubsection*{The Price of Simplicty\cite{sagaprice}}

  There are three main costs associated with an ALI approach like SAGA,
  which tries to provide a simple, stable, concise and consistent
  layer on top of a very dynamic and exceedingly complex set of
  infrastructures.  First, there are performance penalties.  We show
  in~\cite{sagaperf} that those are, for almost all of our target use
  cases, acceptable, or at least manageable.  Second, almost all
  abstractions in IT are leaking once the underlying systems become
  too complex~\cite{leaky_abstractions}.  Despite trying very hard to
  pinpoint the SAGA API semantics, and to avoid abstraction leakage,
  we have to face this uphill battle.  Third, and even more
  importantly, there remains the fact that the SAGA layer itself, i.e.
  the SAGA implementation, is an very complex component.  Although
  that fact is well understood, and an intentional design artefact, it
  needs dealing with on several levels.  Amongst others, it is
  becoming increasingly clear that SAGA deployment needs to be dealt
  with at levels distinct from the SAGA end user, namely at the DCI
  provider level~\cite{UMD,XD,TG}.


 \subsubsection*{SAGA in the Clouds}

  Although the SAGA acronym contains the G-word, it is, first of all, an
  API for programming distributed applications.  As such, it is
  suitable for classical grid and non-grid DCIs, but just as well
  usable for cloud infrastructures~\cite{sagacloud...}.  In particular
  in respect to the 'leaky abstractions' mentioned above, one has to
  acknowledge that the dynamic resource provisioning aspects of clouds
  have certain implications for the semantic interpretation of the
  higher level SAGA API.  For example, resource life time assumptions
  which are valid on Grids have a very different meaning in clouds.
  While we have shown~\cite{sagacloud...} that SAGA can handle fairly
  simple scale-out scenarios onto clouds rather well, it will require
  some additional API semantics to more efficiently, and
  transparently, use cloud resources.  Interestingly, those cloud
  requirements are \I{very} similar to requirements SAGA has recently
  received from the grid application community.  For example,
  the SAGA based pilot-job implementation 'BigJob'~\cite{bigjob} is,
  at the moment, one of the dominant usage modes for TeraGrid and
  DEISA resources, for the SAGA community.  Application level resource
  allocation and reservation paradigms like pilot job and the cloud's
  dynamic resource provisioning paradigms have, on API level, many
  things in common, so that it seems sensible to expand
  SAGA\footnote{The SAGA API is, by design, extensible.  In fact,
  multiple SAGA extensions have already been defined, and are
  undergoing the same standardization process as SAGA itself.} by a
  relatively generic resource management API.  It must be noted that
  SAGA's notion of resource management has \I{almost nothing} to do
  with resource management on infrastructure level, but rather is an
  expression on how an application is discovering and allocating
  required resources.
  

 % AM: the extenci and use case parts should move to earlier

% \subsection{Standards promote Interoperability}
% 
%  \subsubsection*{ExTENCI}
% 
%  ExTENCI\footnote{\url{https://sites.google.com/site/extenci/}} is an
%  NSF funded 2 year project to promote interoperability between the
%  TeraGrid (and/or its successor -- XD) with the OSG (and its
%  successor).  The role of SAGA is provide a common job-submission
%  mechanism across TeraGrid and OSG, for both command-line access as
%  well as for Cactus based application via Gateway.  The different
%  application scenarios that are/will be supported are:
%  
%  \begin{itemize}
%  \item Ensemble of Cactus Simulations (NumRel, EnKF (Petroleum Eng))
%  \item Multiphysics Code (GR-MHD, CFD-MD)
%  \item Spawning Simulations (Realtime ‘outsourcing’ from
%    BlueWaters/Ranger to specialised architectures or less powerful
%    resources)
%  \end{itemize}



%  \section{Need a subsection title}
%  
%   Distributed Computing is more than just submitting isolated jobs.  It
%   is also about federating resources and application components
%   dynamically; about coordinated execution of heteregeneous and dynamic
%   workloads; it is about distributed data management etc. So while SAGA
%   is used for multiple reasons, there are three primary usage modes of
%   SAGA are the following: (i) Simplifying access layer, (ii) building
%   block for tools and distributed execution execution, and (iii) a
%   distributed scripting and programming capability.
%  
%  
%    \subsection{SAGA as a Standardized Programmatic and Access Layer:
%    Advantage to DCI Providers}
%  
%     \subsubsection*{Providing Distributed Scipting and Programming
%     Capbility}
%     % The SAGA API provides very concise and high level method calls
%     % which cover the vaste majority of distributed operations, as
%     % required by the target user community -- scientific application
%     % and tool developers.
%     The Structural Biology Grid (\url{http://SBGrid.org}) currently
%     implements sophisticated analysis and user-defined pipelines.
%     However, these are inherently localized and confined to specific
%     infrastructure.  Replacing ``local python'' calls with
%     ``distributed (SAGA) python'' calls would enable the seamless
%     utilization of DCI.  This provides a simple mode of extensibililty
%     of infrastructure, without any major refactoring of code. Further,
%     as the API specification and implementation is \I{standardized},
%     and thus stable, it allows for a 'write once, run anywhere'
%     approach, which is in general not available otherwise (or at least
%     not without \I{significantly} increase of application complexity).
%     The advantages of this to the end-user is obvious; the lowered
%     barrier-to-entry for novel users and communities will increase the
%     ease and uptake of DCI thus benefitting DCI
%     providers/organizations.  As part of the ExTENCI project, SAGA will
%     make major advances towards becoming a broadly usable programmatic
%     access layer to Condor/OSG.
%  
%  \subsection{Application Development Advantages}
%  
%  \subsubsection*{Application Prototyping and Tooling}
%  
%  The SAGA Python bindings have been proven to be immensely helpful for
%  application prototyping.  But also, they are very helpful when
%  interactively testing remote operations (in the interactive Python
%  interpreter / Python shell).  Finally, it is very easy to implement
%  small command line tools in Python, which are able to mimic and test
%  smaller portions of the overall application.  For example, it is
%  straight forward to implement a specific job control component of an
%  application in a stand alone Python script, and to later include the
%  same functionality in the application proper, with the confidence that
%  the semantics of the remote operations will be well
%  preserved.
%  
%  \subsubsection*{Application Development}
%  
%  %    According to the SAGA use case analysis\cite{saga-uc}, and to our
%  %    own experience in developing distributed applications, the set of
%  %    funtionality required for such applications is rather limited.
%  %    However, as that functionality is provided in very different ways,
%  %    by the various distributed middlewares available today, application
%  %    complexity has historically increased significantly for any single
%  %    remote operation used by the application.
%  
%  
%  % \subsubsection*{Application Deployment}
%  
%  % \subsubsection*{Runtime Configuration}



% The following three most common deployment modes were discussed:
% 
% \begin{itemize}
% 
% \item "Mode 1": SAGA is deployed on the end user's
%   computer. Non-intrusive to the Grid Middleware this is by far the
%   most popular deployment mode for SAGA today. At the same time,
%   however, it is completely beyond control, influence or support for
%   EGI.eu.
% 
% \item "Mode 2": SAGA is installed independently on VO infrastructure
%   and made available through the VO portal functionality. Likewise,
%   this mode of access is non-intrusive, but through collaboration and
%   strong binding through MoUs with EGI.eu somewhat more apt to
%   influence and coordination.
% 
% \item "Mode 3": SAGA is installed directly on the Grid infrastructure,
%   along with or part of, the Middleware. This installation mode would,
%   though highly intrusive, offer most potential to Grid end users as
%   it allows to write truly distributed (domain specific) applications
%   with relative ease.
% 
% \end{itemize}
% 
% \begin{figure}[t]
% \centering
% \begin{tabular}{ll}
% Use Case & Deployment Mode \\
% \hline
% Applications seeking Interoperability & I, II III \\
% Virtual Physiological Human & I, III\\
% FEDEX (Multi-Scale, Multi-Physics Simulations)  & I, III\\
% NeuGrid  & I, II, III\\
% BigJob based Applications (SAGA Pilot-Job)  &  III\\
% Science Gateways (eg Computational Biology)  & II, III \\
% EGI-Service Discovery  & I\\
% gLite/GANGA  & I \\
% RENKEI  & I\\
% \hline
% \end{tabular}
% \caption{An analysis of the SAGA Use Cases and the Deployment Modes
%   that they would benefit from \jhanote{I don't think all of these fit
%     here, as some of these are *not* cloud applications, or grid-cloud
%     applications}}
% \end{figure}

% \section{SAGA Future/Roadmap}
% 
%  The evolution of SAGA has two very independent components: the
%  evolution of the SAGA specification as OGF standard, and the
%  evolution of the various SAGA implementations.
% 
%  The SAGA Core API specification is very close to become a full OGF
%  recommendation (it arrived in literally the last stage of the
%  respective OGF process).  As the specification is very modular, it
%  allows for additional functional packages to be specified
%  individually.  Several such extension packages have already been
%  specified (advert, messages, service discovery, resource management),
%  and are in various stages of the standardization process - we expect
%  those packages to mature and eventually become published
%  specifications within a year (some of them are already published,
%  others are very close to that).  We don't expect any of the published
%  specifications to evolve anytime soon -- so far there seems to be no
%  need of new versions of the API, despite the increasing set of
%  implementations, users, and use cases.
% 
%  On the implementation side of things we expect a limited amount of
%  evolution on the actual API level (the standard is stable after all).
%  Most of the current development efforts are spent on adaptor level, and
%  in fact the quality and usability of SAGA stands and falls with the
%  quality of the middleware bindings, i.e. of the adaptors.  We thus
%  expect that those will continue to demand the majority of our
%  resources.  Ideally, adaptor development, and even more adaptor
%  maintainance and support, will eventually be provided by the respective
%  middleware providers, but for the time being that is not the case.  At
%  the moment it is very hard to estimate timeframe and required effort
%  for an eventual support for the future EMI and/or PGI services -- that
%  depends on many factors, such as the structure of the upcoming
%  specifications (close to BES or not, close to JSDL or not, etc), on the
%  implementation progress for these services, and on their acceptance in
%  the wider community.
% 
%  SAGA-C++ has seen significant progress on documentation and end user
%  support (deployment support, ticket management, mailing list activity
%  etc).  Those improvements are mostly caused by the increasing SAGA
%  user community, which both requires, but also supports that progress.
% 
%  Additional domains that the SAGA project will see activity moving it
%  from a research project to production-grade infrastructure, is in the
%  area of data-intensive computing and cloud-based infrastructure. In
%  the near future we will have a {\it package} for data management
%  (beyond files) and have bindings to OCCI -- which would extend the
%  functionality and capabilties provided to OCCI implmentations.

\section{OCCI: the Open Cloud Computing Interface}
\label{sec:occi}

 The Open Cloud Computing Interface consist of a set of open
 community-driven specifications provided under Umbrella of the Open
 Grid Forum. OCCI is a RESTful \tmnote{REF} Protocol and API for all
 kinds of Management tasks based on a Resource Orientated Architecture
 (ROA) \tmnote{REF}. OCCI was originally initiated to create a remote
 management API for IaaS model based Services, allowing for the
 development of interoperable tools for common tasks including
 deployment, autonomic scaling and monitoring of Virtual Machines
 (IaaS). It has since evolved into a flexible Protocol and API with a
 strong focus on integration, portability, interoperability and
 innovation while still offering a high degree of extensibility. The
 current release of the Open Cloud Computing Interface is intented to
 also cater to many other models in addition to IaaS, including e.g. 
 PaaS and SaaS. \tmnote{REF occi-wg.org here}

 The OCCI specifications fall into three categories, which are the
 OCCI Core specification, OCCI Renderings and OCCI Extensions.  Three
 OCCI documents exist and are being implemented by various
 implementations:
 
 \begin{itemize}

  \item The \I{OCCI Core} specification consists of a single document
  defining the OCCI Core \I{Model}. That model can be interacted with
  via \I{renderings}, and expanded via \I{extensions}.

  \item The \I{OCCI HTTP Restful Rendering} specification describes
  one particular rendering of the OCCI Core Model. Other renderings
  are feasable and could interact with the same instance of the OCCI
  Core Model.  The HTTP Restful Rendering describes an HTTP based
  RESTful API to interface with services which implement the OCCI Core
  Model.
 
  \item The \I{OCCI Infrastructure} specification is an extension of
  the OCCI Core Model which contains the definition required to apply
  the OCCI model to the IaaS domain. Other documents could describe
  other ways and means of extending the Core Model, for other elements
  of the IaaS domain, or for the PaaS and SaaS domains.

 \end{itemize}

 Future releases of OCCI may include additional rendering and
 extension specifications. Since OCCI is an RESTful Protocol or
 API\amnote{now, which is it?? ;-)}, it can build upon all the
 features defined by HTTP. This includes mechanisms for authentication
 and authorization, cache-mechanisms, content-type definitions and
 discovery capabilities.

 Another guiding principle in OCCI is to make use of existing
 standards and specifications where appropriate.  For example, OGF's
 OCCI working group and the Storage Networking Industry Association's
 (SNIA)\footnote{\url{http://www.snia.org/}} Cloud Data Management
 Interface (CDMI) \footnote{CMDI can be used to create, retrieve,
 update and delete data elements in a Cloud offering.} working groups
 have collaboratively ensured that both specifications are
 interoperable with each other. 
 % CDMI, just like OCCI, can be used to discover service capabilites.  
 % Meta-Data can be assigned to the data elements using CDMI.
 References to data elements, which result from CDMI service
 interactions, can directly be used when interacting with an OCCI
 compatible service.

 Similarly, OGF's OCCI working group and the Distributed Management
 Task Force's (DMTF)\footnote{\url{http://www.dmtf.org/}} Open
 Virtualization Format (OVF), see \cite{CDG+2009}, can be easily
 integrated through the use of the OCCI resource type Link. Where a
 provider wishes to supply an OVF representation of a client's
 resource instance(s), they can do so by associating the instance(s)
 with a mirror representation, with the serialisation/rendering format
 being OVF.

 The OCCI working group is also closely working together with other
 groups inside of the Open Grid Forum. The Distributed Computing
 Infrastucture Federation (DCI-fed) working group focuses on the
 creation of models and APIs for setting up distributed federated
 computing environments. The OCCI working group further plans to use
 Standards like the Distributed Resource Management Application API
 (DRMAA) for common Job operations on Clusters, via the OCCI protocol.

 All those efforts will, upon adoption, simplify service-level cloud
 interoperability efforts.  The landscape of cloud based DCIs is,
 however, evolving very fast and dynamically, and it remains to be
 seen what OCCI extensiont will be required to cater to emerging
 federation use cases.


\section{Grid-Cloud interoperatbilty}
\label{sec:gcinterop}

 The next paragraphs describe how a Cloud and Grid interoperability
 could look like. To demo these interoperability use-cases OCCI and
 SAGA interoperability use cases are described.

 \subsection{Using OCCI for IaaS based resource provisioning} Since
 SAGA features a rich set of adapters to talk to Grid Middlewares the
 first use-case describes a way to autmatically provision such grid
 middlewares on demand. SAGA could use OCCI to request initial or
 addtional Grid Resources.

This would be a request on a IaaS based level where SAGA could request
Compute Resource with a Grid Middlware installed to be started. While
Using formats like OVF or by providing addiotional Attributes in the
request towards OCCI, SAGA could customize the request and for example
state that it needs a Virtual Machine with certain attributes,
Platform LSF installed with \T{version $>=$ 7.0.5} and a OGSA-BES interface
deployed. The SAGA adapters can then be used to provision Jobs using
OGSA-BES.

This first use case demoes a dynamic scalling or dynamic provisioning
scenario. But it can also be used for Cloud-Bursting/Hybrid-Cloud
approaches.

\subsection{Using SAGA and OCCI to create a PaaS Offering}
SAGA offers a rich set of calls in it's API. Since OCCI ist mostly a
Protocol which can be used to create an API (by using Extensions) SAGA
can be used to enrich the OCCI functionalities and create a PaaS
offering.

Programmers would develop their applications using the SAGA API. When
finished they would provision their applications in an OCCI defined
manner. All the resource provisioning as well as concrete
implementations are then transparently hidden from the end-user.

This could be an HPC in the Cloud offering.

\subsection{SAGA access PaaS OCCI based offering}
Finally since SAGA's adapters can submit jobs there is a third way to
demo interoperability. A SAGA adapter could be implemented which
submits Jobs to Cluster using the OCCI Protocol. It might be that a
Service Provider offers such a Job Submission service over OCCI which
can be easily intergated with OCCI. The SAGA-OCCI Adapter could make
extensive usage of the automatic discovery and billig mechanisms while
using OCCI.

\section{Lessons learned}
\label{sec:lessons}

\ldots

\section{Architecture}
\label{sec:arch}

\subsection{3-Level Architecture Diagram}




\bibliographystyle{plain}
\bibliography{inter-cloud-grid-2011,ecmls11}

\end{document}

