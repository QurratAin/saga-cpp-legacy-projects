I. Overview/Opening saying what we think is/are the unique
contribution(s) of the paper.

Given that more than two Billion dollars of science every year depends
upon Pilot-Jobs, the lack of a theoretical framework to analyze,
compare and contrast Pilot-Jobs-- even if incomplete or approximately,
is a serious issue.
 
The primary contribution of this paper is the formulation of an
abstract model (P*) of Pilot-Jobs and the demonstration that, (i) P* is 
minimally complete but extensible along multiple dimensions,
e.g., supports the common treatment of dynamic compute jobs and dynamic data,
(ii) the realisation of the P* model that supports and promotes
interoperability of different PJ implementations and across different
infrastructure, (iii) validation of P* model and its implementation
(TROY) by demonstrating the use of across different PJ implementations
(with otherwise very different compute-job semantics)

To the best of our knowledge, (iii) has not been demonstrated; this is
consistent with known barriers to interoperability, Thus, we believe
(i), (ii) and (iii) are all unique contributions of this work.


II. Acknowledge short comings, and address how we will fix them. Does
not have been specific but could be high-level.  Important to point
out how in-spite of shortcomings main contributions as in I are not
undermined, i.e., shortcomings can be/will be fixed. (ie.  urge
shepherding). [SJ/AL]

- motivation for P* model: We will improve the motivation for section II.

- respectfully claim that TROY overhead have been addressed

- only covers Pilot-Jobs => future work: pilot-data, scheduling,
  etc. Application to data has never been done before

- no related work: we have references (<30% self-refs); section 4 is a
discussion of related work [factual inaccuracy]

- experiments Pilot-Data => future work

III. Address Specific comments, and either dispute or
acknowledge. Either way focus on how we will improve the individual
sections.

In turn, each section in III has two tracks: (i) why we agree/disagree
with specific comments, (ii) How we will improve individual sections,
either taking into account the referee remarks or of our own volition
(again making the case for shepherding).

Section 1: SJ
Section 2: AL

- provide a better motivation for P* model: 

(i) It is important to understand 
properties and characteristics (SJ: properties and characteristics of what? PJs?)
in order to map application requirements, available infrastructure and PJ framework. 
(map to what?)

(ii) Provide a simple API for the core functionality, hide the complexity and semantic heterogeneity 
of different PJ implementations.

- Describe the benefits of interoperability using a real-life
scenario, e.g. XSEDE - EGI interoperability.

- highlight the sub-set of functionality of PJ frameworks that is exposed via 
TROY and give an example of what kind of functionality is hidden (different, 
complex resource specifications, specific initialization and termination
commands,...).

Section 3: MS 

SJ: Would it help to highlight the difference between the API and the "engine"
aspects of TROY. P* and TROY-API provides conceptual uniformity; the
engine provides interoperability.

Improve descriptions of TROY and PJ framework relationship and on how
TROY implements the P* characteristics.

TROY is an implementation of the P*-model, and therefore also "minimal
but complete" by design.  Reviewer C questions the incentive to
"implement everything over TROY" related to performance.  As TROY
builds on top of other systems, in the single backend scenario, one
should not expect a performance increase. We show that the performance
overhead is negligble though.  [SJ: "we show" or "we have shown" ?]

The real advantage in using TROY is the 
concurrent execution of jobs on multiple pilot-job implementation
backends. We would like to explicitly mention that this also enables
the concurrent execution of jobs on (totally) different
infrastructures.  

TROY will not "implement the characteristics" of the
various Pilot-Jobs, it rather exposes these characteristics in a
unified way, without the need to change an application when switching
infrastructure.

We take the comments from the reviewers as a sign that we need to
explain these benefits more clearly.

Section 4: OW
No explicit reviewer comments regarding secion 4 - PJ Frameworks. 

Some general remarks:
  I think the word IMPLEMENTATION is used far to often throughout this 
  paper (45 times to be exact). Everything is an implementation of 
  an implementation of a model of an abstraction... or something like that ;-)

  grep -v '^%' pstar-ipdps2011.tex  | grep "implementation" | wc -l  
  40
  grep -v '^%' pstar-ipdps2011.tex  | grep "Implementation" | wc -l
  5

  E.g., "BigJob: A SAGA-based Pilot-Job Implementation for TROY".
  Why not call it "A SAGA-based Pilot-Job for TROY"? 

SJ: So the rebuttal point is what? We will address confusing and over-use
of implementation in different contexts.? 

Section 5: AL (with MS and AM)
- extended evaluation of TROY overhead and break down to sub-components 
(startup time, coordination, ...)

- present experiments of PD

Section 6: AL
- present use cases (coupling data-compute, discovery, in-situ access, 
streaming) of PD (see D3MA)
- present API of PD
- present experiments of PD

Section 7: SJ

