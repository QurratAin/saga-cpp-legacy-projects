\documentclass[]{paper}
\usepackage{}

% type user-defined commands here

\begin{document}

\title{FutureGrid 2012 Project Challenge:\\ Using SAGA to build Scalable Dynamic Distributed Applications}
%\title{FutureGrid 2012 Student Project Challenge} 
\author{Pradeep Kumar Mantha 
  \and Sivakarthik Natesan 
  \and Melissa Romanus 
  \and Sai Saripalli 
  \and Ashley Zebrowski
  \and \large{Faculty Advisor: Shantenu Jha}
}
\date{May 15th, 2012}
\maketitle

\begin{abstract}
\end{abstract}

\section{Introduction}

% The development of scalable and applications presents a formidable research challenge.  

There are multiple challenges in the effective design and implementations of scalable distributed applications and infrastructure: the spectrum of challenges range from managing the heterogeneity inherent in distributed systems on the one hand to the lack of well established programming models to support distributed applications. In addition there do not exist well defined set of base capabilities or unifying abstractions needed to reason about how, when and where to distribute applications. Against this backdrop, the range of distributed cyberinfrastructure (DCI) available to researchers is continually evolving.  Thus, the process of designing and deploying large-scale DCI, as well as developing applications that can effectively utilize them, presents a critical and challenging agenda for domain researchers and CI developers alike.

FutureGrid provides students and researchers with new possibilities to engage in science relating to the state-of-the-art in cloud and grid computing.  As members of the Research in Distributed Cyberinfrastructure and Applications (RADICAL) group, we have taken full advantage of the opportunities that FutureGrid provides.

We have been using SAGA on FutureGrid to address the wide spectrum of challenges: from scalable runtime systems for distributed data-intensive applications (Pilot-MapReduce) to novel dynamic execution modes for traditional HPC applications (Cactus-Spawner) as well as enhanced sampling algorithms (Replica-Exchange).  In addition to flexible and scalable applications, we have used FutureGrid to enhance and extend the capabilities of SAGA.  In this submission we outline how are some of the ways we are using SAGA on FutureGrid resources to push the envelope and pursue exciting new discoveries.

\jhanote{Each section should have the following: Scientific Motivation/objective? How was FutureGrid used? Scientific Results on Futuregrid? Ideally show how this work contributed to Interoperabiltiy and scalability}

\section{Pilot MapReduce}

\jhanote{this needs massive reduction and focus!}

Scientists in many science disciplines, where enormous amounts of data is generated , e. g. in the areas of fusion energy, bioinformatics, climate and astronomy, utilize distributed cyber-infrastructure to conduct experiments and improve their understanding about the scientific applications. Domain scientists face various challenges associated with processing of data at extreme scales on distributed cyberinfrastructures like FutureGrid. Therefore, an efficient processing of large distributed datasets is required, whilst ideally not introducing fundamentally new programming models or methods. For example, extending MapReduce - a proven effective programming model for processing large datasets, to work more effectively on distributed data is desirable. Hadoop is an open-source implementation of MapReduce programming model but is designed for shared-nothing environments and its performance is affected on a distributed file system.  On DCI like FutureGrid, we were not able to run Hadoop on multiple clusters.
We posit that there is a need for an effective and efficient runtime environment and without refactoring MapReduce itself for processing the distributed data. MapReduce on distributed data requires effective distributed coordination of computation (map and reduce) and data, as well as distributed data management (in particular the transfer of intermediate data units). To address these requirements, we design and implement Pilot-MapReduce (PMR) - a flexible, infrastructure-independent runtime environment for MapReduce. PMR is based on Pilot abstractions for both compute (Pilot-Jobs) and data (Pilot-Data): it utilizes Pilot-Jobs to couple the map phase computation to the nearby source data, and Pilot-Data to move intermediate data using parallel data transfers to the reduce computation phase. We analyze the effectiveness of PMR over applications with different characteristics (e. g. different volumes of intermediate and output data). Our experimental evaluations show that the Pilot abstraction for data movement across multiple clusters is promising, and can lower the execution time span of the entire MapReduce execution. We also investigate the performance of PMR with distributed data using a Word Count and a genome sequencing application over different MapReduce configurations.  We find that PMR is a viable tool to support distributed NGS analytics by comparing and contrasting the PMR approach to similar capabilities of Seqal and Crossbow, two Next Generation Sequencing(NGS) Hadoop MapReduce based applications. Our experiments show that PMR provides the desired flexibility in the deployment and configuration of MapReduce runs to address specific application characteristics and achieve an optimal performance, both locally and over wide-area multiple clusters.

Experiments:
  Can we use PMR results... since this is a report???



\section{Replica Exchange}

Replica-Exchange (RE) methods represent a class of algorithms that involve a large number of loosely-coupled ensembles 
and are used to understand physical phenomena â€“ ranging from protein folding dynamics to binding affinity calculations. The SAGA-based Pilot Framework, BigJob, has been shown to support this class of applications on FutureGrid as well as XSEDE resources.

mr: What do you want to say about this? Abhinav's work?? I am concerned that this overlaps with the fcpc2012-all paper...



\section{Cactus Spawner - Ashley Zebrowski}
The Cactus Spawner project envisions application frameworks with simulations that
can be broken down to their constituent components and run across multiple
distributed systems.  A chief consideration is that of ``intelligent computing'',
of knowing when and where to run simulation components separately from the main
simulation.  Work is being done to enable this by modelling simulation components
and predicting the time to run locally vs. the time to transport them and execute
them remotely.  To model real-world problems, the Cactus framework is used, and
actual black hole simulations are executed and spawned from.  Contributions
to the field involve algorithms in modelling, spawning, and performance evaluation on
the I/O systems of FutureGrid hardware.

\section{Bliss Development - Ashley Zebrowski}
SSH adaptor, Eucalyptus adaptor enable cloud interoperability.  Working on 
Bliss itself lowers the barrier of entry to distributed computing for developers
of both Bliss-enabled software and Bliss plugins/extensions.

\section{Conclusion}
Here we will evaluate each application based on how they fit into the FutureGrid proposal
criteria.
\begin{enumerate}
\item Interoperability
\item Scalability
\item Contribution to Education
\item Research (innovation, quality of papers, new software, algorithms, insightful performance measurements, etc.)

\end{enumerate}
\begin{thebibliography}{9}
\end{thebibliography}

\end{document}
