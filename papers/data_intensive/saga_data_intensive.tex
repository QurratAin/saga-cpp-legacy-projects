%%%%%%%%%%%%%%%
% RSGUIDE.TEX %
%%%%%%%%%%%%%%%

% Guide to preparing TeX articles for Royal
% Society articles using RSPUBLIC.CLS
% Use this file as a test file

\documentclass{rspublic}  

\usepackage[utf8]{inputenc}
\usepackage{graphicx}
\usepackage{url}
\usepackage{float}
\usepackage{times}    
\usepackage{multirow}    
\usepackage{listings}   
\usepackage{times}     
\usepackage{paralist}    
\usepackage{wrapfig}    
\usepackage[small,it]{caption}
\usepackage{multirow}
\usepackage{ifpdf}    
\usepackage{subfig} 
                  


\title{Programming Abstractions for Data Intensive Computing}

\author{Michael Miceli$^{12}$,Shantenu Jha$^{12}$,Chris Miceli$^{12}$, 
  Hartmut Kaiser$^{1}$, Andre Merzky$^{1}$ \\
  \small{\emph{$^{1}$Center for Computation \& Technology, Louisiana
      State University, USA}}\\
  \small{\emph{$^{2}$Department of Computer Science, Louisiana State
      University, USA}}\\
  \small{\emph{$^{3}$e-Science Institute, Edinburgh, UK}}\\
}

\newif\ifdraft
%\drafttrue
\ifdraft
\newcommand{\kimnote}[1]{ {\textcolor{green} { ***JK: #1 }}}
\newcommand{\alnote}[1]{ {\textcolor{blue} { ***AL: #1 }}}
\newcommand{\amnote}[1]{ {\textcolor{magenta} { ***AM: #1 }}}
\newcommand{\jhanote}[1]{ {\textcolor{red} { ***SJ: #1 }}}
\else
\newcommand{\kimnote}[1]{}
\newcommand{\alnote}[1]{}
\newcommand{\amnote}[1]{}
\newcommand{\jhanote}[1]{}
\fi

\begin{document}

\maketitle

\begin{abstract}{SAGA, ..., search, sequencing.. data-intensive}
  SAGA~\cite{saga_gfd90} is a high level API that provides a simple,
  standard and uniform interface to the most commonly required
  distributed functionality.  SAGA can be used to encode grid
  applications~\cite{saga_escience07, saga_tg08}, tool-kits to manage
  distributed applications as well as implement abstractions that
  support commonly occurring programming, access and usage patterns.
  The focus of this paper is on the latter set, i.e.  the use of SAGA
  in implementing well known abstractions for data intensive
  computing.  In this paper, we will implement MapReduce and All-Pairs
  abstractions using SAGA and use them to solve commonly encountered
  genomic tasks.  We will show how multiple sequence alignment can be
  orchestrated using the SAGA-Allpair implementation, and genome
  searching can be implemented using Map-reduce.  In addition, the aim
  of this paper is to show (validate) that SAGA is a sufficiently
  complete and high-level interface so as to support these programming
  abstractions.  %Figure~\ref{fig:data_intensive_app_saga} illustrates
  the software architecture of the implementation, highlighting the
  different abstraction levels that allow the reuse of most of the
  system for both algorithms and for different genomic applications.
  We will highlight the sailent points of our implementations, and how
  we handle common considerations such as when to move the data to the
  machine or when to process it locally.  The implemention of these
  abstractions encapsulates details such as latency hiding,
  performance and other variables (such as cluster sizes, and queue
  sizes).  The user should be able to easily add a few function calls
  without worrying about many considerations required by most grid
  computing applications.  We will discuss other performance issues
  that arise when implementing abstractions specific for
  data-intensive computing.  A grid application's design should not
  focus on the bandwidth of the network, the dispatch latency, the
  number of machines available, and data reliability.  Even something
  as simple as process size can be a tough challenge to optimize.  If
  a job is too small, then network traffic becomes a bottleneck and
  the design is inefficient.  If a job is too large, it is difficult
  to tell when it is hanging or still computing.  Also, if another job
  with a higher priority takes a machine over, the application will be
  waiting on jobs longer.  The main point of this paper is to show how
  a flexible, extensible implementation of programming data-intensive
  abstractions using SAGA can shield the application developer many of
  these considerations.

\end{abstract}

\section{Introduction} {\bf Jha} 

\jhanote{Outline the work in this paper}

\jhanote{Motivation for why this work is important}

% \section{Data Intensive Computing} 

\subsection{Example 1: MapReduce}

MapReduce~\cite{mapreduce-paper} is a programming framework which
supports applications which operate on very large data sets on
clusters of computers.  MapReduce relies on a number of capabilities
of the underlying system, most related to file operations, but also
related to process/data colocation.  The Google file system, and other
global file systems, provide the relevant capabilities, such as atomic
file renames.  Implementations of MapReduce on these file systems can
focus on implementing the the dataflow pipeline, which is the
algorithmic core of the MapReduce framework.

We have recently implemented MapReduce in SAGA, targeting general
purpose Grid systems, where the system capabilities required by
MapReduce are usually not natively supported -- instead, a general
purpose grid provides a much larger set of lower level operations.
Some semantics, such as again the atomic file rename, is provided by
the SAGA API layer, others, such as data/compute colocation are not.
Our implementation is thus required to interleave the core logic with
explicit instructions on where processes are to be scheduled Note that
some of the required capabilities can be provided by higher level grid
services -- those are, however, often not standardized, and often not
available in general purpose Grids.

The advantage of this approach is obviously that our implementation is
no longer bound to run on a system providing the appropriate semantics
originally required by MapReduce, but is portable to other, more
generic systems as well.  The drawback of the approach is obvious as
well: our implementation is relatively more complex, as it needs to
add semantic system capabilities at some level or the other, and it is
inherently slower, as it is for these capabilities very difficult or
near impossible to obtain system level performance on application
level.  But many of these are due to the early-stages of the
implementation of SAGA, and not a fundamental limitation of the design
or concept.

%  when operating on specific parts of the data set~\cite{gsoc-saga}.


\subsubsection{Details}

MapReduce is a programming framework developed by Google for running
data-intensive processes over a large cluster of commodity machines.
The main idea is to provide an easy interface for users to run a
common type of jobs on grids without having the client worry about the
semantics of the grid, for example, dispatch latency, machine failure,
data distribution, and network bandwidth.  All of these are problems
that could make a naïve implementation on a grid slower than a serial
implementation.  When using a MapReduce implementation the programmer
interacts with only two functions: map and reduce.  The map function
will go through the datasets and create a map of data to some type of
output.  A map is a datatype in computer science that relates one
object to another, i.e. a name t o a phone number.  The reduce
function will go through all of the maps and combine them to produce
another output.  The de facto example is word count.  Say, you have a
large set of documents and you want to find how many of each word is
present in all the documents.  The map function would go through each
document and for every word produce a map from the document to a list
of 1’s.  An example for the word “cat” may look like this cat -> 1, 1,
1, 1, 1.  Then, the reduce function will add up the 1’s to produce a
final output, i.e. cat -> 5.  The programmer has to break the problem
he or she wants to solve into two sections.  At first this framework
may seem limiting, but there have been a large number of distinct
applications written using it, and its popularity has been steadily
increasing.  This shows that the framework is well suited for solving
data-intensive problems.


\subsection{Our Implementation:} 

There are a few implementations, most notably Google and Hadoop and
these are what our implementation is based on.  It is able to handle
most of the problems associated with grid applications.  We use the
idea of a master/slave type framework.  The programmer would compile
different slave applications for every different type of machine he or
she would expect to encounter in the grid.  The slave application is
where the map and reduce functions are.  Then the master will handle
submitting these jobs on other machines as well as keeping track of
the state of the machines -- idle, done, or failed.  This allows for
easy running of an application using large girds that have frequent
machine failures.  Our MapReduce also handles data distribution in the
same manner Google does, by creating partitions of data so the entire
data set will never be on one machine, thus limited network bandwidth
and data distribution.  These files could then recognized by a
distributed filesystems such as HaDoop FileSystem.  Although, our
current implementation is written to avoid excessive network
bandwidth, it doesn’t change depending on current network
availability.


\subsection{Example 2: All-Pairs}

\section*{Infrastructure}

\subsection*{Hadoop}

Provide 1 paragraph description of Hadoop

Discuss the C interface to Hadoop

\subsection*{BigTable, HBase}

Provide 1 paragraph description of Bigtable and its specific
implementation -- HBase

\subsection*{Interfacing SAGA to Hadoop and BigTable}

\section{Applications}

\subsection*{Alignment}

\subsection*{Search}

\section*{Experiments}

\subsection*{MapReduce using Advert Service}

\subsection*{MapReduce using HBase}

\subsection*{Native Implementation: MapReduce using HBase and Hadoop}

\subsection*{SAGA Based MapReduce}

Performance figures when using the Advert service -- on one machine,
on >1 machine, finding the bottleneck

\jhanote{These figures can then be used to justify some of the 
  development efforts proposed in OMIISAGA-2}

\section{Acknowledgments}

\bibliographystyle{plain}
\bibliography{saga_data_intensive}

\end{document}

