%% This BibTeX bibliography file was created using BibDesk.
%% http://bibdesk.sourceforge.net/


%% Created for Andre Luckow at 2011-04-22 19:15:15 +0200 


%% Saved with string encoding Unicode (UTF-8) 

@inproceedings{ecmls11-mr-autodock,
 author = {Luo, Yuan and Guo, Zhenhua and Sun, Yiming and Plale, Beth and Qiu, Judy and Li, Wilfred W.},
 title = {A hierarchical framework for cross-domain MapReduce execution},
 booktitle = {Proceedings of the second international workshop on Emerging computational methods for the life sciences},
 series = {ECMLS '11},
 year = {2011},
 isbn = {978-1-4503-0702-4},
 location = {San Jose, California, USA},
 pages = {15--22},
 numpages = {8},
 url = {http://doi.acm.org/10.1145/1996023.1996026},
 doi = {http://doi.acm.org/10.1145/1996023.1996026},
 acmid = {1996026},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {autodock, cloud, futuregrid, hierarchical mapreduce, multi-cluster},
}

@article{10.1109/MIC.2011.64,
author = {Ian Foster},
title = {Globus Online: Accelerating and Democratizing Science through Cloud-Based Services},
journal ={IEEE Internet Computing},
volume = {15},
issn = {1089-7801},
year = {2011},
pages = {70-73},
doi = {http://doi.ieeecomputersociety.org/10.1109/MIC.2011.64},
publisher = {IEEE Computer Society},
address = {Los Alamitos, CA, USA},
}

@misc{webhdfs,
title = {{WebHDFS REST API}},
key = {webhdfs},
howpublished={\url{http://hadoop.apache.org/common/docs/r1.0.0/webhdfs.html}},
year=2012
}

@inproceedings{pstar-2012,
	Author = {Andre Luckow and Mark Santcroos and Ole Weider and Andre Merzky and Sharath Maddineni and Shantenu Jha},
	Booktitle = {Proceedings of The International ACM Symposium on High-Performance Parallel and Distributed Computing},
	Date-Added = {2011-09-04 16:13:49 +0000},
	Date-Modified = {2011-09-04 16:14:42 +0000},
	Title = {P*: A Model of Pilot-Abstractions},
	Year = {2012}}


@article{Isard:2007:DDD:1272998.1273005,
	 author = {Isard, Michael and Budiu, Mihai and Yu, Yuan and Birrell, Andrew and Fetterly, Dennis},
	 title = {Dryad: distributed data-parallel programs from sequential building blocks},
	 journal = {SIGOPS Oper. Syst. Rev.},
	 issue_date = {June 2007},
	 volume = {41},
	 issue = {3},
	 month = {March},
	 year = {2007},
	 issn = {0163-5980},
	 pages = {59--72},
	 numpages = {14},
	 url = {http://doi.acm.org/10.1145/1272998.1273005},
	 doi = {http://doi.acm.org/10.1145/1272998.1273005},
	 acmid = {1273005},
	 publisher = {ACM},
	 address = {New York, NY, USA},
	 keywords = {cluster computing, concurrency, dataflow, distributed programming},
	} 
	[download]
	@inproceedings{Isard:2007:DDD:1272996.1273005,
	 author = {Isard, Michael and Budiu, Mihai and Yu, Yuan and Birrell, Andrew and Fetterly, Dennis},
	 title = {Dryad: distributed data-parallel programs from sequential building blocks},
	 booktitle = {Proceedings of the 2nd ACM SIGOPS/EuroSys European Conference on Computer Systems 2007},
	 series = {EuroSys '07},
	 year = {2007},
	 isbn = {978-1-59593-636-3},
	 location = {Lisbon, Portugal},
	 pages = {59--72},
	 numpages = {14},
	 url = {http://doi.acm.org/10.1145/1272996.1273005},
	 doi = {http://doi.acm.org/10.1145/1272996.1273005},
	 acmid = {1273005},
	 publisher = {ACM},
	 address = {New York, NY, USA},
	 keywords = {cluster computing, concurrency, dataflow, distributed programming},
	}

@article{1742-6596-78-1-012057,
	Abstract = {The Open Science Grid (OSG) provides a distributed facility where the Consortium members provide guaranteed and opportunistic access to shared computing and storage resources. OSG provides support for and evolution of the infrastructure through activities that cover operations, security, software, troubleshooting, addition of new capabilities, and support for existing and engagement with new communities. The OSG SciDAC-2 project provides specific activities to manage and evolve the distributed infrastructure and support it's use. The innovative aspects of the project are the maintenance and performance of a collaborative (shared & common) petascale national facility over tens of autonomous computing sites, for many hundreds of users, transferring terabytes of data a day, executing tens of thousands of jobs a day, and providing robust and usable resources for scientific groups of all types and sizes. More information can be found at the OSG web site: www.opensciencegrid.org.},
	Author = {Ruth Pordes {\it et al}},
	Journal = {Journal of Physics: Conference Series},
	Number = {1},
	Pages = {012057},
	Title = {The open science grid},
	Url = {http://stacks.iop.org/1742-6596/78/i=1/a=012057},
	Volume = {78},
	Year = {2007},
	Bdsk-Url-1 = {http://stacks.iop.org/1742-6596/78/i=1/a=012057}}


@article{1742-6596-78-1-012057-long,
	Abstract = {The Open Science Grid (OSG) provides a distributed facility where the Consortium members provide guaranteed and opportunistic access to shared computing and storage resources. OSG provides support for and evolution of the infrastructure through activities that cover operations, security, software, troubleshooting, addition of new capabilities, and support for existing and engagement with new communities. The OSG SciDAC-2 project provides specific activities to manage and evolve the distributed infrastructure and support it's use. The innovative aspects of the project are the maintenance and performance of a collaborative (shared & common) petascale national facility over tens of autonomous computing sites, for many hundreds of users, transferring terabytes of data a day, executing tens of thousands of jobs a day, and providing robust and usable resources for scientific groups of all types and sizes. More information can be found at the OSG web site: www.opensciencegrid.org.},
	Author = {Ruth Pordes and Don Petravick and Bill Kramer and Doug Olson and Miron Livny and Alain Roy and Paul Avery and Kent Blackburn and Torre Wenaus and Frank W{\"u}rthwein and Ian Foster and Rob Gardner and Mike Wilde and Alan Blatecky and John McGee and Rob Quick},
	Journal = {Journal of Physics: Conference Series},
	Number = {1},
	Pages = {012057},
	Title = {The open science grid},
	Url = {http://stacks.iop.org/1742-6596/78/i=1/a=012057},
	Volume = {78},
	Year = {2007},
	Bdsk-Url-1 = {http://stacks.iop.org/1742-6596/78/i=1/a=012057}}


@manual{OMG-CORBA303:2004,
	Key = {OMG},
	Keywords = {2004, corba, omg},
	Month = {M},
	Organization = {Object Management Group},
	Posted-At = {2006-10-04 15:54:44},
	Priority = {0},
	Title = {{Common Object Request Broker Architecture: Core Specification}},
	Year = {2004}}




@article{1742-6596-219-6-062049,
	Abstract = {DIRAC, the LHCb community Grid solution, has pioneered the use of pilot jobs in the Grid. Pilot Jobs provide a homogeneous interface to an heterogeneous set of computing resources. At the same time, Pilot Jobs allow to delay the scheduling decision to the last moment, thus taking into account the precise running conditions at the resource and last moment requests to the system. The DIRAC Workload Management System provides one single scheduling mechanism for jobs with very different profiles. To achieve an overall optimisation, it organizes pending jobs in task queues, both for individual users and production activities. Task queues are created with jobs having similar requirements. Following the VO policy a priority is assigned to each task queue. Pilot submission and subsequent job matching are based on these priorities following a statistical approach.},
	Author = {Adrian Casajus and Ricardo Graciani and Stuart Paterson and Andrei Tsaregorodtsev and the Lhcb Dirac Team},
	Journal = {Journal of Physics: Conference Series},
	Number = {6},
	Pages = {062049},
	Title = {DIRAC pilot framework and the DIRAC Workload Management System},
	Url = {http://stacks.iop.org/1742-6596/219/i=6/a=062049},
	Volume = {219},
	Year = {2010},
	Bdsk-Url-1 = {http://stacks.iop.org/1742-6596/219/i=6/a=062049}}

@inproceedings{dare-tg11-gateways,
author={Joohyun Kim and Sharath Maddineni and Shantenu Jha},
title={Building Gateways for Life-Science Applications using the Distributed Adaptive Runtime Environment (DARE) Framework},
year=2011,
booktitle={Proceedings of TeraGrid'11 Extreme Discovery}
}

@phdthesis{diane-thesis,
	Author = {Jakub Tomasz Moscicki},
	Date-Added = {2011-04-22 19:11:25 +0200},
	Date-Modified = {2011-04-22 19:15:12 +0200},
	School = {University of Amsterdam},
	Title = {Understanding and Mastering Dynamics in Computing Grids: Processing Moldable Tasks with User-Level Overlay},
	Year = {2011}}
	
@inproceedings{Doraimani:2008:FGS:1383422.1383429,
     author = {Doraimani, Shyamala and Iamnitchi, Adriana},
     title = {File grouping for scientific data management: lessons from experimenting with real traces},
     booktitle = {Proceedings of the 17th international symposium on High performance distributed computing},
     series = {HPDC '08},
     year = {2008},
     isbn = {978-1-59593-997-5},
     location = {Boston, MA, USA},
     pages = {153--164},
     numpages = {12},
     url = {http://doi.acm.org/10.1145/1383422.1383429},
     doi = {http://doi.acm.org/10.1145/1383422.1383429},
     acmid = {1383429},
     publisher = {ACM},
     address = {New York, NY, USA},
     keywords = {caching, data management, file grouping, job scheduling, science grids, trace analysis},
} 


@inproceedings{ramakrishnan2011,
 author = {Zacharia Fadika and Elif Dede and Madhusudhan Govindaraju 
 and Lavanya Ramakrishnan},
 title = {Benchmarking MapReduce Implementations for Application Usage Scenarios},
 booktitle = {submitted to The International Conference for High Performance  Computing, Networking, Storage, and Analysis},
 year={2011}
}

@inproceedings{weissman2011,
 author = {Michael Cardosa and Chenyu Wang and Anshuman Nangia and Abhishek Chandra and Jon Weissman},
 title = {Exploring MapReduce Efficiency with Highly-Distributed Data},
 year={2011}
}

@inproceedings{jha2011,
 author = {Shantenu Jha and J.D. Blower and Neil Chue-Hong and Simon Dobson and Daniel S. Katz and Omer Rana},
 title = {3DPAS: Distributed Dynamic Data-intensive Programming Abstractions and Systems},
 year={2011}
}

@inproceeding{gray2000,
author = {Jim Gray, Prashant Shenoy},
 title = {Rules of Thumb in Data Engineering},
 year={2000},
 howpublished={\url{http://research.microsoft.com/en-us/um/people/gray/papers/ms_tr_99_100_rules_of_thumb_in_data_engineering.pdf}}

}

@book{hey2009,
	Abstract = {Increasingly, scientific breakthroughs will be powered by advanced computing computingapabilities that help researchers manipulate and explore massive datasets.

The speed at which any given scientific discipline advances will depend on how well its researchers collaborate with one another, and with technologists, in areas of eScience such as databases, workflow management, visualization, and cloud computing technologies.

In The Fourth Paradigm: Data-Intensive Scientific Discovery, the collection of essays expands on the vision of pioneering computer scientist Jim Gray for a new, fourth paradigm of discovery based on data-intensive science and offers insights into how it can be fully realized.},
	Added-At = {2010-02-16T09:54:37.000+0100},
	Address = {Redmond, Washington},
	Biburl = {http://www.bibsonomy.org/bibtex/28b203c0313656b6ced70c14c86a4c42a/acka47},
	Date-Added = {2011-09-04 20:56:39 +0000},
	Date-Modified = {2011-09-04 20:57:08 +0000},
	Editor = {Tony Hey and Stewart Tansley and Kristin Tolle},
	Interhash = {296450016ca8a5f8ab16ae4d92d1fc15},
	Intrahash = {8b203c0313656b6ced70c14c86a4c42a},
	Keywords = {research scholarly_communication science},
	Publisher = {Microsoft Research},
	Timestamp = {2010-02-16T09:54:37.000+0100},
	Title = {The Fourth Paradigm: Data-Intensive Scientific Discovery},
	Url = {http://research.microsoft.com/en-us/collaboration/fourthparadigm/},
	Year = 2009,
	Bdsk-Url-1 = {http://research.microsoft.com/en-us/collaboration/fourthparadigm/}}

@INPROCEEDINGS{Moscicki:908910, 
author={Moscicki, J.T.}, 
booktitle={Nuclear Science Symposium Conference Record, 2003 IEEE}, title={DIANE - distributed analysis environment for GRID-enabled simulation and analysis of physics data}, 
year={2003}, 
volume={3}, 
number={}, 
pages={1617 - 1620}, 
abstract={ Distributed analysis environment (DIANE) is the result of R D in CERN IT Division focused on interfacing semi-interactive parallel applications with distributed GRID technology. DIANE provides a master-worker workflow management layer above low-level GRID services. DIANE is application and language-neutral. Component-container architecture and component adapters provide flexibility necessary to fulfill the diverse requirements of distributed applications. Physical transport layer assures interoperability with existing middleware frameworks based on Web services. Several distributed simulations based on Geant 4 were deployed and tested in real-life scenarios with DIANE.}, 
keywords={ CERN IT Division; GRID-enabled physics data simulation; Geant 4; Web services; component adapters; component-container architecture; distributed analysis environment; interoperability; master-worker workflow management layer; middleware frameworks; physical transport layer; physics data analysis; semi-interactive parallel applications; Internet; data analysis; grid computing; middleware; physics computing; workflow management software;}, 
doi={10.1109/NSSMIC.2003.1352187}, 
ISSN={1082-3654},}

@misc{bigjob_web,
	title="{SAGA BigJob}",
	key={SAGA BigJob},
	howpublished={\url{https://github.com/saga-project/BigJob/wiki}},
	year={2012}
}

@misc{pilot_api,
	author="{Pilot API}",
	key={Pilot},
	howpublished={\url{https://github.com/saga-project/BigJob/blob/master/pilot/api/}},
	year=2012
}

@article{condor-g,
	Author = {Frey, J. and Tannenbaum, T. and Livny, M. and Foster, I. and Tuecke, S.},
	Citeulike-Article-Id = {291860},
	Date-Added = {2008-02-28 10:08:47 -0600},
	Date-Modified = {2008-06-30 19:47:43 +0200},
	Doi = {10.1023/A:1015617019423},
	Journal = {Cluster Computing},
	Keywords = {grid, scheduling},
	Month = {July},
	Number = {3},
	Pages = {237--246},
	Priority = {2},
	Title = {{Condor-G: A Computation Management Agent for Multi-Institutional Grids}},
	Url = {http://dx.doi.org/10.1023/A:1015617019423},
	Volume = {5},
	Year = {2002},
	Bdsk-Url-1 = {http://dx.doi.org/10.1023/A:1015617019423},
	Bdsk-Url-2 = {http://dx.doi.org/10.1023/A:1015617019423}}

@inproceedings{1362680,
	Address = {New York, NY, USA},
	Author = {Ioan Raicu and Yong Zhao and Catalin Dumitrescu and Ian Foster and Mike Wilde},
	Booktitle = {SC '07: Proceedings of the 2007 ACM/IEEE conference on Supercomputing},
	Date-Added = {2008-08-09 21:04:33 +0200},
	Date-Modified = {2008-08-09 21:04:53 +0200},
	Doi = {http://doi.acm.org/10.1145/1362622.1362680},
	Isbn = {978-1-59593-764-3},
	Location = {Reno, Nevada},
	Pages = {1--12},
	Publisher = {ACM},
	Title = {{Falkon: A Fast and Light-Weight TasK ExecutiON Framework}},
	Year = {2007},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/1362622.1362680}}
	
	
@article{Wilde2011,
	title = "Swift: A language for distributed parallel scripting",
	journal = "Parallel Computing",
	volume = "37",
	number = "9",
	pages = "633--652",
	year = "2011",
	note = "Emerging Programming Paradigms for Large-Scale Scientific Computing",
	issn = "0167-8191",
	doi = "10.1016/j.parco.2011.05.005",
	url = "http://www.sciencedirect.com/science/article/pii/S0167819111000524",
	author = "Michael Wilde and Mihael Hategan and Justin M. Wozniak and Ben Clifford and Daniel S. Katz and Ian Foster",
	keywords = "Swift",
	keywords = "Parallel programming",
	keywords = "Scripting",
	keywords = "Dataflow",
	abstract = "Scientists, engineers, and statisticians must execute domain-specific application programs many times on large collections of file-based data. This activity requires complex orchestration and data management as data is passed to, from, and among application invocations. Distributed and parallel computing resources can accelerate such processing, but their use further increases programming complexity. The Swift parallel scripting language reduces these complexities by making file system structures accessible via language constructs and by allowing ordinary application programs to be composed into powerful parallel scripts that can efficiently utilize parallel and distributed resources. We present Swift’s implicitly parallel and deterministic programming model, which applies external applications to file collections using a functional style that abstracts and simplifies distributed parallel execution."
}

@misc{coasters,
title={Coasters},
key={coasters},
howpublished={\url{http://wiki.cogkit.org/wiki/Coasters}},
year=2009
}

@misc{topos,
title={ToPoS - A Token Pool Server for Pilot Jobs},
key={Topos},
howpublished={\url{https://grid.sara.nl/wiki/index.php/Using_the_Grid/ToPoS}},
year=2011
}

@INPROCEEDINGS{1652061, 
author={Walker, E. and Gardner, J.P. and Litvin, V. and Turner, E.L.}, 
booktitle={Challenges of Large Applications in Distributed Environments, 2006 IEEE}, title={Creating personal adaptive clusters for managing scientific jobs in a distributed computing environment}, 
year={2006}, 
month={0-0 }, 
volume={}, 
number={}, 
pages={95-103}, 
keywords={Condor;NSF TeraGrid;Sun Grid Engine cluster;cooperative system;distributed computing environment;personal adaptive cluster;resource management;scientific job management;grid computing;resource allocation;workstation clusters;}, 
doi={10.1109/CLADE.2006.1652061}, 
ISSN={},}

@article{10.1109/HPC.2000.846563,
author = {Rajkumar Buyya and David Abramson and Jonathan Giddy},
title = {Nimrod/G: An Architecture for a Resource Management and Scheduling System in a Global Computational Grid},
journal ={International Conference on High-Performance Computing in the Asia-Pacific Region},
volume = {1},
isbn = {0-7695-0589-2},
year = {2000},
pages = {283-289},
doi = {http://doi.ieeecomputersociety.org/10.1109/HPC.2000.846563},
publisher = {IEEE Computer Society},
address = {Los Alamitos, CA, USA},
}


  	
@article{1742-6596-219-6-062041,
  author={Po-Hsiang Chiu and Maxim Potekhin},
  title={Pilot factory – a Condor-based system for scalable Pilot Job generation in the Panda WMS framework},
  journal={Journal of Physics: Conference Series},
  volume={219},
  number={6},
  pages={062041},
  url={http://stacks.iop.org/1742-6596/219/i=6/a=062041},
  year={2010},
  abstract={The Panda Workload Management System is designed around the concept of the Pilot Job – a "smart wrapper" for the payload executable that can probe the environment on the remote worker node before pulling down the payload from the server and executing it. Such design allows for improved logging and monitoring capabilities as well as flexibility in Workload Management. In the Grid environment (such as the Open Science Grid), Panda Pilot Jobs are submitted to remote sites via mechanisms that ultimately rely on Condor-G. As our experience has shown, in cases where a large number of Panda jobs are simultaneously routed to a particular remote site, the increased load on the head node of the cluster, which is caused by the Pilot Job submission, may lead to overall lack of scalability. We have developed a Condor-inspired solution to this problem, which is using the schedd-based glidein, whose mission is to redirect pilots to the native batch system. Once a glidein schedd is installed and running, it can be utilized exactly the same way as local schedds and therefore, from the user's perspective, Pilots thus submitted are quite similar to jobs submitted to the local Condor pool.}
}

@misc{dpa_surveypaper, note = {S. Jha et al., {\em Programming Abstractions
                  for Large-scale Distributed Application s}, 
                  Submitted to ACM Computing Surveys; draft at \url{http://www.cct.lsu.edu/~sjha/publications/dpa_surveypaper.pdf}}}

@misc{egi,
author="{EGI}",
key={egi},
howpublished={\url{http://www.egi.eu/}},
year={2011}
}

@Article{bfast2009,
title="{BFAST : An alignment tool for large scale genome resequencing}",
author={Homer, N. and Merriman, B. and Nelson, S. F.} ,
journal={PLoS One},
year={2009},
volume={4},
number={11},
pages={e7767},
keywords={},
doi={},
ISSN={}, }

@misc{saga_rm,
author={Andre Merzky},
title="{SAGA Resource Management API (DRAFT)}",
booktitle={OGF Draft},
howpublished={\url{https://svn.cct.lsu.edu/repos/saga-ogf/trunk/documents/saga-package-resource/}},
year=2011
}

@misc{saga_advert,
author={Andre Merzky},
title="{SAGA API Extension: Advert API}",
howpublished={OGF Document Series 177,  \url{http://www.gridforum.org/documents/GFD.177.pdf}},
year=2011
}

@misc{redis,
author="{Redis}",
key={Redis},
howpublished={\url{http://redis.io/}},
year=2011
}

@misc{zmq,
author="{ZeroMQ}",
key={zmq},
howpublished={\url{http://www.zeromq.org/}},
year=2011
}

@misc{fg,
title="{FutureGrid: An Experimental, High-Performance Grid Test-bed}",
key={FutureGrid},
howpublished={\url{https://portal.futuregrid.org/}},
year=2012
}

@misc{xsede,
title="{XSEDE: Extreme Science and Engineering Discovery Environment}",
key={XSEDE},
howpublished={\url{https://www.xsede.org/}},
year=2012
}


@article{Gelernter:1985:GCL:2363.2433,
 author = {Gelernter, David},
 title = {Generative communication in Linda},
 journal = {ACM Trans. Program. Lang. Syst.},
 volume = {7},
 issue = {1},
 month = {January},
 year = {1985},
 issn = {0164-0925},
 pages = {80--112},
 numpages = {33},
 url = {http://doi.acm.org/10.1145/2363.2433},
 doi = {http://doi.acm.org/10.1145/2363.2433},
 acmid = {2433},
 publisher = {ACM},
 address = {New York, NY, USA},
}


@misc{loni, 
author="{LONI}",
key={loni},
howpublished={\url{http://www.loni.org}},
year={2011}
}


@article{Moscicki20092303,
title = "Ganga: A tool for computational-task management and easy access to Grid resources",
journal = "Computer Physics Communications",
volume = "180",
number = "11",
pages = "2303 - 2316",
year = "2009",
note = "",
issn = "0010-4655",
doi = "10.1016/j.cpc.2009.06.016",
url = "http://www.sciencedirect.com/science/article/pii/S0010465509001970",
author = "J.T. Moscicki {\it et al}",
keywords = "Grid computing",
keywords = "Data mining",
keywords = "Task management",
keywords = "User interface",
keywords = "Interoperability",
keywords = "System integration",
keywords = "Application configuration",
abstract = "In this paper, we present the computational task-management tool Ganga, which allows for the specification, submission, bookkeeping and post-processing of computational tasks on a wide set of distributed resources. Ganga has been developed to solve a problem increasingly common in scientific projects, which is that researchers must regularly switch between different processing systems, each with its own command set, to complete their computational tasks. Ganga provides a homogeneous environment for processing data on heterogeneous resources. We give examples from High Energy Physics, demonstrating how an analysis can be developed on a local system and then transparently moved to a Grid system for processing of all available data. Ganga has an API that can be used via an interactive interface, in scripts, or through a GUI. Specific knowledge about types of tasks or computational resources is provided at run-time through a plugin system, making new developments easy to integrate. We give an overview of the Ganga architecture, give examples of current use, and demonstrate how Ganga can be used in many different areas of science.
Program summary
Program title: Ganga

Catalogue identifier: AEEN_v1_0

Program summary URL: http://cpc.cs.qub.ac.uk/summaries/AEEN_v1_0.html

Program obtainable from: CPC Program Library, Queen's University, Belfast, N. Ireland

Licensing provisions: GPL

No. of lines in distributed program, including test data, etc.: 224 590

No. of bytes in distributed program, including test data, etc.: 14 365 315

Distribution format: tar.gz

Programming language: Python

Computer: personal computers, laptops

Operating system: Linux/Unix

RAM: 1 MB

Classification: 6.2, 6.5

Nature of problem: Management of computational tasks for scientific applications on heterogenous distributed systems, including local, batch farms, opportunistic clusters and Grids.

Solution method: High-level job management interface, including command line, scripting and GUI components.

Restrictions: Access to the distributed resources depends on the installed, 3rd party software such as batch system client or Grid user interface."
}

@article{Moscicki20092303-long,
title = "Ganga: A tool for computational-task management and easy access to Grid resources",
journal = "Computer Physics Communications",
volume = "180",
number = "11",
pages = "2303 - 2316",
year = "2009",
note = "",
issn = "0010-4655",
doi = "10.1016/j.cpc.2009.06.016",
url = "http://www.sciencedirect.com/science/article/pii/S0010465509001970",
author = "J.T. Moscicki and F. Brochu and J. Ebke and U. Egede and J. Elmsheuser and K. Harrison and R.W.L. Jones and H.C. Lee and D. Liko and A. Maier and A. Muraru and G.N. Patrick and K. Pajchel and W. Reece and B.H. Samset and M.W. Slater and A. Soroko and C.L. Tan and D.C. van der Ster and M. Williams",
keywords = "Grid computing",
keywords = "Data mining",
keywords = "Task management",
keywords = "User interface",
keywords = "Interoperability",
keywords = "System integration",
keywords = "Application configuration",
abstract = "In this paper, we present the computational task-management tool Ganga, which allows for the specification, submission, bookkeeping and post-processing of computational tasks on a wide set of distributed resources. Ganga has been developed to solve a problem increasingly common in scientific projects, which is that researchers must regularly switch between different processing systems, each with its own command set, to complete their computational tasks. Ganga provides a homogeneous environment for processing data on heterogeneous resources. We give examples from High Energy Physics, demonstrating how an analysis can be developed on a local system and then transparently moved to a Grid system for processing of all available data. Ganga has an API that can be used via an interactive interface, in scripts, or through a GUI. Specific knowledge about types of tasks or computational resources is provided at run-time through a plugin system, making new developments easy to integrate. We give an overview of the Ganga architecture, give examples of current use, and demonstrate how Ganga can be used in many different areas of science.
Program summary
Program title: Ganga

Catalogue identifier: AEEN_v1_0

Program summary URL: http://cpc.cs.qub.ac.uk/summaries/AEEN_v1_0.html

Program obtainable from: CPC Program Library, Queen's University, Belfast, N. Ireland

Licensing provisions: GPL

No. of lines in distributed program, including test data, etc.: 224 590

No. of bytes in distributed program, including test data, etc.: 14 365 315

Distribution format: tar.gz

Programming language: Python

Computer: personal computers, laptops

Operating system: Linux/Unix

RAM: 1 MB

Classification: 6.2, 6.5

Nature of problem: Management of computational tasks for scientific applications on heterogenous distributed systems, including local, batch farms, opportunistic clusters and Grids.

Solution method: High-level job management interface, including command line, scripting and GUI components.

Restrictions: Access to the distributed resources depends on the installed, 3rd party software such as batch system client or Grid user interface."
}

@misc{leaky_abstractions,
  title  = {{The Law of Leaky Abstractions}},
  author = {{Joel Spolsky}},
  note   = {\url{http://www.joelonsoftware.com/articles/LeakyAbstractions.html}},
}
