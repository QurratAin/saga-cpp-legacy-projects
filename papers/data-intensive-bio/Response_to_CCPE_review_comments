The original submission of paper received two reviews, and we have
carried out the suggested revisions, going over every aspect of the
paper. We think the suggestions have indeed improved the
manuscript. Our response  follows along with excerpts from
the original reviews.


In order to run effectively scientific applications on distributed systems, 
scientific workflow management systems such as Pegasus have been introduced.  
In particular, Pegasus generates a optimized workflow and sumbit it to other execution platforms 
DAGman or Condor.  Currenlty, DARE acts like an execution platform that supports 
NGS application specific execution patterns on distributed heterogeneous resources, and thus
it is desirable to have a workflow management system in front of DARE and we plan to employ 
a lightweight workflow system.


Reviewer: 1
Comments to the Author
This paper gives a thorough discussion of computation requirements for NGS data covering both computing and disk issues and looking at multiple tools. They demonstrate success with a distributed execution environment DARE-NGS building on earlier work with SAGA and Bigjob supporting Pilot-jobs.

This is a good paper which is thorough in its examination of problem characteristics. I suggest publication with one improvement. I think it could do a better job with "related work" where other approaches such as Pegasus could be applicable. They correctly emphasize that their work crosses clouds and classic HPC/grid systems and note some previous work used MapReduce. The latter has been implemented on distributed systems and so I assume previous cloud approach could mimic DARE-NGS on heterogeneous platforms. Challenges here could be commented on.

Our response :  We added our undestanding on Pegasus and differences beteen a workflow management system such as Pegasus and our DARE approach.


Reviewer: 2
Comments to the Author
This paper proposes DARE, a SAGA-BigJob framework exploring interoperability among heterogeneous distributed computing environments for pleasingly parallel applications. It is motivated by NGS analysis and other similar data intensive applications, which can possibly utilize HPC, Grid and Cloud infrastructure through a unified framework to achieve task-level concurrency.

The authors conduct performance measurements using multi-threading and data partition optimizations.  In particular, comparison of task completion time Tc is used for different parallel configurations such as read file size, number of tasks and threads per task, cores or instances.

The proposed framework would enable NGS-like applications to run automatically on different infrastructures.

It would be helpful if the authors could clarify how to configure a new application using this framework. For instance, it doesnâ€™t seem clear what the principles or formulae to use in designing a new deployment. How exactly is Tc used?

How is this framework different from a workflow system such as Pegasus that has composite runtime frameworks?


Our response : 
