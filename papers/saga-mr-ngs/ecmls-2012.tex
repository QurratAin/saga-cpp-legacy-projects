% THIS IS SIGPROC-SP.TEX - VERSION 3.1
% WORKS WITH V3.2SP OF ACM_PROC_ARTICLE-SP.CLS
% APRIL 2009
%
% It is an example file showing how to use the 'acm_proc_article-sp.cls' V3.2SP
% LaTeX2e document class file for Conference Proceedings submissions.
% ----------------------------------------------------------------------------------------------------------------
% This .tex file (and associated .cls V3.2SP) *DOES NOT* produce:
%       1) The Permission Statement
%       2) The Conference (location) Info information
%       3) The Copyright Line with ACM data
%       4) Page numbering
% ---------------------------------------------------------------------------------------------------------------
% It is an example which *does* use the .bib file (from which the .bbl file
% is produced).
% REMEMBER HOWEVER: After having produced the .bbl file,
% and prior to final submission,
% you need to 'insert'  your .bbl file into your source .tex file so as to provide
% ONE 'self-contained' source file.
%
% Questions regarding SIGS should be sent to
% Adrienne Griscti ---> griscti@acm.org
%
% Questions/suggestions regarding the guidelines, .tex and .cls files, etc. to
% Gerald Murray ---> murray@hq.acm.org
%
% For tracking purposes - this is V3.1SP - APRIL 2009

%\documentclass{acm_proc_article-sp}
\documentclass{sig-alternate}
\usepackage[numbers, sort, compress]{natbib}
\usepackage{graphics}
\usepackage{graphicx}
\usepackage{epstopdf}
\usepackage{color}
\usepackage{hyperref}
\usepackage{pdfsync}
\usepackage{mdwlist}

\begin{document}

\conferenceinfo{ECMLS'12,} {}
\CopyrightYear{2012}
\crdata{978-1-4503-0702-4/11/06}
\clubpenalty=10000
\widowpenalty = 10000


%\title{A Sample {\ttlit ACM} SIG Proceedings Paper in LaTeX
%Format\titlenote{(Does NOT produce the permission block, copyright information nor page numbering). For use with ACM\_PROC\_ARTICLE-SP.CLS. Supported by ACM.}}

\newif\ifdraft
\drafttrue                                                                                                   

\ifdraft
% \newcommand{\reviewer}[1]{ {\textcolor{blue}    { ***Reviewer:     #1 }}}
 \newcommand{\jkimnote}[1]{{\textcolor{green}   { ***Joohyun:   #1 }}}
 \newcommand{\jhanote}[1]{  {\textcolor{red}     { ***SJ: #1 }}}
  \newcommand{\pmnote}[1]{  {\textcolor{red}     { ***Pradeep: #1 }}}
 \newcommand{\todo}[1]{  {\textcolor{red}     { ***TODO: #1 }}}
 \newcommand{\fix}[1]{  {\textcolor{red}     { ***FIX: #1 }}}
 \newcommand{\reviewer}[1]{}
\else
 \newcommand{\reviewer}[1]{}
 \newcommand{\jkimnote}[1]{}
 \newcommand{\pmnote}[1]{}
 \newcommand{\jhanote}[1]{}
 \newcommand{\todo}[1]{  {\textcolor{red}     { ***TODO: #1 }}}
 \newcommand{\fix}[1]{}                                                                                     
\fi

\title{Next-Generation Sequencing Reads Alignment Using Pilot-based SAGA-MapReduce}

\numberofauthors{3} %  in this sample file, there are a *total*
% of EIGHT authors. SIX appear on the 'first-page' (for formatting
% reasons) and the remaining two appear in the \additionalauthors section.
%
\author{
% You can go ahead and credit any number of authors here,
% e.g. one 'row of three' or two rows (consisting of one row of three
% and a second row of one, two or three).
%
% The command \alignauthor (no curly braces needed) should
% precede each author name, affiliation/snail-mail address and
% e-mail address. Additionally, tag each line of
% affiliation/address with \affaddr, and tag the
% e-mail address with \email.
%
\alignauthor Pradeep Kumar Mantha\\
       \affaddr{Center for Computation and Technology}\\
       \affaddr{Louisiana State University}\\
       \affaddr{216 Johnston}\\
       \affaddr{Baton Rouge, LA}
       \email{pradeepm66@gmail.com}
\alignauthor Andre Luckow\\
       \affaddr{Center for Computation and Technology}\\
       \affaddr{Louisiana State University}\\
       \affaddr{216 Johnston}\\
       \affaddr{Baton Rouge, LA}
\alignauthor Nayong Kim\\
       \affaddr{Center for Computation and Technology}\\
       \affaddr{Louisiana State University}\\
       \affaddr{216 Johnston}\\
       \affaddr{Baton Rouge, LA}
\and
\alignauthor Joohyun Kim\titlenote{Author for correspondence}\\
       \affaddr{Center for Computation and Technology}\\
       \affaddr{Louisiana State University}\\
       \affaddr{216 Johnston}\\
       \affaddr{Baton Rouge, LA} \\
       \email{jhkim@cct.lsu.edu}
\alignauthor Shantenu Jha\titlenote{Author for correspondence}\\
      \affaddr{Center for Computation and Technology}\\
     \affaddr{Louisiana State University}\\
      \affaddr{214 Johnston}\\
      \affaddr{Baton Rouge, LA}
     \email{sjha@cct.lsu.edu}
}
% There's nothing stopping you putting the seventh, eighth, etc.
% author on the opening page (as the 'third row') but we ask,
% for aesthetic reasons that you place these 'additional authors'
% in the \additional authors block, viz.
%\additionalauthors{Additional authors: John Smith (The Th{\o}rv{\"a}ld Group,
%email: {\texttt{jsmith@affiliation.org}}) and Julius P.~Kumquat
%(The Kumquat Consortium, email: {\texttt{jpkumquat@consortium.net}}).}
\date{25 Feb. 2012}
% Just remember to make sure that the TOTAL number of authors
% is the number that will appear on the first page PLUS the
% number that will appear in the \additionalauthors section.

\maketitle
\begin{abstract} 



 
\end{abstract}

We present the use of MapReduce programming model for Next-Generatiion Sequencing (NGS) data analysis.  Our approach is based on Pilot-based SAGA-MapReduce (P-SAGA-MR) framework which extends previously introduced SAGA-MapReduce with a Pilot task and data management implementation.  With the new P-SAGA-MR, a variety of applications for NGS data and downstream analysis are transformed to become scalable tools by analyzing and processing large distributed data sets located in distributed multiple infrastructures effectively.   As an example, we demonstrate the capacity of P-SAGA-MR for an application carrying out NGS reads alignment and duplicate removal, implemented to the map phase and the reduce phase task, respectively.  We compared our implementation with other MapReduce-based NGS data analysis tools such as Seqal of the SEAL package and Crossbow that make use of Hadoop-based environment but currently implemented with two different mappers, BWA and Bowtie, respectively.  Based on obtained results presenting benchmark experiments using two different mappers and comparison to the two tools, we discuss how P-SAGA-MR stands out, in particular with respect to the scalability with multiple cluster integration and the extensibility with supporting multiple tools and the potential of P-SAGA-MR for a broad range of NGS data analytics. 


\category{D.1.3}{Software}{Concurrent Programming}{ Distributed
  programming/parallel programming} \category{J.3}{Computer
  Applications}{Bioinformatics, Mapping}


% A category with the (minimum) three required fields
%\category{H.4}{Information Systems Applications}{Miscellaneous} %Acategory including the fourth, optional field follows...
%\category{D.2.8}{Software Engineering}{Metrics}[complexity measures,performance measures]

\terms{Design, Experimentation, Performance}

 \keywords{Genome Sequence Alignment, BWA, Human Genome, RNA-Seq Data,
  MapReduce, Distributed Computing, Simple API for Grid
  Applications (SAGA), Pilot Job and Data}

%\keywords{ACM proceedings, \LaTeX, text tagging} % NOT required for Proceedings 
%\keywords{RNA conformation energy landscape, Runtime Environment, SAM-I riboswitch,
% S gene of Bovine Corona Viral Genome} % NOT required for Proceedings

\section{INTRODUCTION} 
Recent advances in high-throughput DNA sequencing technologies such as Next-Generation Sequencing (NGS) platforms have  imposed unprecedented challenges in areas of bioinformatics, computational biology, and biocomputing in general\cite{metzker2010,1000genome,wang2009-natrevgen,alex2009,mcpherson2009}.  With astronomically explosive volumes of raw data and processed data, along with required computational tasks that often need scalable infrastructure, these challenges are to some extent novel because of the need of an integrative solution leveraging algorithmic advances, computational implementations, and infrastructure developments altogether. Indeed, still at this moment it is common to find many biologists who have sequencing data sets in his/her hand for their biological/biomedical queries but are puzzled surrounded with so-many-tools implemented with specific algorithms and computational requirements including the installation, maintenance, and update of the software tools. 

Among many directions for responding to such challenges, the use of parallelism is an essential strategy and in fact the programming model of MapReduce has been widely touted as an efficient solution for big data problems\cite{mapreduce-2004-dean}.  Several tools using MapReduce were already introduced in NGS data analysis such as read alignment onto a reference genome\cite{cloudburst, gatk,langmead2009,seal2011,langmead2010, taylor2010}.

In this work, we present the development of a Next-Generation Sequencing reads alignment tool using Pilot-based SAGA-MapReduce (P-SAGA-MR or PMR) which is a recent re-implementation of SAGA-MapReduce with a newly developed Pilot-based approach\cite{Sehgal2011590,pmr2012}.  Indeed, P-SAGA-MR provides a viable solution for computational challenges with NGS data analytics, in particular, arising from the required scalability for dealing with ever-growing data volume, variety, and demand for time-to-solution.  Our implementation of the MapReduce programming model supports the development of dynamic applications which represent applications executed in distributed resources via effective and dynamic task and data management, which is contrasted to other approaches using Hadoop-based MapReduce implementations\cite{cloudburst,langmead2009,seal2011,langmead2010}.  With a specific example, in this work we demonstrate how PMR has the capacity for executing a task of NGS data analysis effectively with recognizing aspects associated with algorithms, implementations, and infrastructure.

The target task is the combination of reads alignment and duplicate removal, with which we examine the characteristics and the performance of the developed tool specifically in distributed computing environments.  The discussions including the potential of this approach for a broad range of NGS data analytics are presented.  Also, we compare our implementation with other approaches that implemented conventional MapReduce with Hadoop.

The paper is organized as follows. In the following section, the data sets we used for this work and the introducing of the P-SAGA-MR are presented.   Later, results for parallel performance measurements and comparison of our results with SEQAL which represents applications that use the open source Hadoop-based MapReduce\cite{hadoop-url, taylor2010} and aiming the same read alignment-duplicate removal task\cite{seal_2011_mapred,seal2011} are presented.  Finally, we will give concluding remarks focusing on challenges associated with scalable calculations of NGS data analytics which could be effectively resolved by the utilization of P-SAGA-MR that seamlessly supports parallel/concurrent computation and data processing  tasks with scalable multiple HPC infrastructures.

\begin{center}
\begin{table*}[ht]
{\small
\hfill{}
\begin{tabular}{|l|l|c|c|c|c|c|c|}
\hline
  & \textbf{P-SAGA-MR}\cite{pmr2012} & \textbf{SEQAL}\cite{seal2011} & \textbf{Crossbow}\cite{langmead2009} & \textbf{CloudBurst}\cite{cloudburst} & \textbf{GATK}\cite{gatk} \\ \hline
%\cline{3-9}
 \hline 
Key Parallelism   & Pilot-based   &  Hadoop-based/  &  Hadoop cluster  & Hadoop-based & MR-based Structured \\ 
Stretegy  & Distributed MR & MR  & or Amazon EMR & MR & Programming  \\
& & (Pydoop) &  & & Framework  \\ \hline
  
Hadoop & No & Yes & Yes\footnote[1] & Yes & No \\ 
Requirement  & & & &  &\\ \hline  
  
    
Multiple  Cluster & Yes  & Limited   & Limited  & Limited  & Limited \\
Support &  & by Hadoop &  by Hadoop & by Hadoop  & by JVM   \\ \hline

Distributed Job and  & Advert Service (SAGA) & Hadoop/HDFS & Hadoop/HDFS & Hadoop/HDFS & Java \\ 
Data Coordination & &  & & & Framework\\ \hline
%Strength & 1. Scalable with Multiple Systems  &  &  &  & \\ 
%
%&  2. Pilot Job/Data Support & &  & & \\ 
%&3. Extensibility  &  &  &  & \\
%& 4. Short Development Cycle & & & & \\\hline
%Weakness &  & 1. HDFS Limitations & 1. HDFS Limitations & 1. HDFS Limitations  &\\ \hline

Primary Aligner &  BWA  &  BWA & Bowtie & RMAP &  BWA \\ \hline
Multiple Aligner  & Straightforward & Not Straight- & Possible & Not Straight-  & Straight-  \\ 
Support &  & forward &   & forward  & forward \\\hline
Primary Tasks & Alignment/Duplicate  & Alignment/ & Alignment/ & Alignment &Various\\
  &  Removal & Duplicate & SNP Discovery & & NGS Data  \\  
           &  &  Removal & &  & \& Downstream  \\
           &  & & &  & Analysis \\ \hline  
Extensibility to   &  High  & Medium &  Low & Low & High      \\
Other Analysis  &      &  &  &  &   \\ \hline

\hline
\end{tabular}}
\hfill{}
\caption{Feature comparison of P-SAGA-MR with other tools for Next-Generation Sequencing (NGS) data analysis with MapReduce framework.  $^{1}${Crossbow can run without hadoop when scalability is not needed.} }
 \label{table:mr-comparison}
\end{table*}
\end{center}

\section{Materials and Methods}
\subsection{NGS Data Sets and Analysis}
The short reads alignment, along with assembly, is the first step in every pipeline projects aiming biological discovery with sequencing data from NGS platforms.  Since the de-novo assembly remains still challenging at this moment primarily due to the short length of sequencing reads from NGS machines, alignment or mapping is taken as the first task in most of cases.  After alignment, duplicate read removal might be required because the preparation step artifacts stemming from high-throughtput read amplification might introduce many duplicates that are not relevant to true biological conditions.  These two steps could be parallelized by using MapReduce such that the read alignment step is conducted as a Map phase and duplicate removal as a Reduce phase.  Note that a certain kind of variation for designing MapReduce-based analysis for NGS data is also of interest considering the duplicate removal task might be skipped or replaced with other analysis tasks such as SNP finding, transcript quantification or peak calling that are required for other advanced NGS protocols.  The development for such topics will be announced in the future works.

For this work, we used RNA-Seq data from our collaborator lab which is from human lymphoma cell lines.  A brief summary on the data set is given in Table~\ref{table:data}

\subsection{Experimental Set-up for NGS Read Alignment and Duplicate Removal}
\subsubsection{Pilot-based SAGA-MapReduce}
For this work, we used two Futuregrid systems, SIERRA and HOTEL.  More details on the specification of these machines can be found from the web page of Futuregrid\cite{futuregrid_url}.  


\subsubsection{Comparative Experiment with Seqal}
Seqal is chosen for the comparison with our approach with P-SAGA-MR since it aims the analysis of read alignment and duplicate removal.  Also, Seqal is implemented with BWA for alignment, implying that the comparison is informative to differentiate Hadoop-based MR implementation and the Pilot-based implementation.

Hadoop version 0.20.2 and seqal version  seal-0.2.3 were used for SEQAL-based read alignment.

First of all, PJ based mapreduce involves advert coordination- whereas HDFS filesytem involves TCP/IP layer for communication between data nodes; and job nodes use RPC to communicate between each other.
Note that it is not easy for Hadoop/Normal MR to be scaled out to multiple clusters(unless and until clusters have some common global filesystem, which is rare and involves latency issues).  On the contrary, PMR supports  multiple clusters and no need of having common filesystem by design.

Hadoop SEQAL experiment setup is as follows.  The input file format is prq format.  SEAL, a software tool containing SEQAL as a part, has a file conversion capacity between qseq/fastq and prq format.  The replication factor for Hadoop configuration is set  to 1.

To make the comparision more meaningful, we set the number of nodes as 4, and the maximum map and reduce tasks is set to be 2.  We found that if the number of tasks is set to be more than 2, the issue with memory size occurred.  \pmnote{refer to reference paper}  Thus, total 8 workers were used.
The chunk size used is 128MB, which is default block size and corresponding to nearly 292,763 reads.
The reduce phase starts after all map phase tasks are completed. 

We found problems faced with using SEQAL; the tmp directory on each node is used to store data  by hadoop, but tmp is limited and tasks failed due to memory problem.  So a parallel file system is needed in case of multiple nodes, or tmp data directory should point to different disks.

PMR setup for using two separated systems is as follows.  Initially the half of the data is placed on sierra. whereas the remaining half is on hotel. The number of workers is 8 and each individual node of the four nodes (two nodes per each cluster) has 2 workers.  For a single system set up, everything is similar except all workers are now running in the system.  Input is in fastq format. An In-house script is used for the chunking step. The user can define the chunker script and provide as an input to the pMR framwork.  
 
   \pmnote{chunksize = number of lines of fastq file ( number of sequences (292763 * 4 ) since in fastq each sequence is of 4 lines..
tts = max( map on sierra, map on hotel)+max( time tansfer from sierra to hotel, time transfer from hotel to sierra)+max(reduce on sierra, reduce on hotel)..
Graph : x axis- (2,4,8 input sizes) with chunk size 292763 sequences, number of workers=8, reduces=8.
experiments repeated thrice.. }
 
For the experiment using distributed resources, all input and required data are stored initially on a single cluster to process.  Again, Hadoop-based implementation, SEQAL cannot run on multiple clusters and thus all experiments are conducted in a single Hadoop-installed system.

We calculated the time-to-solution (tts) as the combination of the time for transferring data to A cluster from B cluster (when A and B are used) and SEQAL execution time. 
 


\section{Results}

\subsection{Pilot Model-driven SAGA-MapReduce for NGS data analysis: Implementation}
In Fig.~\ref{fig:arch-pj-saga-mr}, the overall architecture of PJ-based SAGA-MapReduce for reads alignment and duplicate removal tasks is shown.  In brief, the target tasks are carried out with this order. 1.SAGA-MapReduce launches Map tasks on N clusters using Pilot-Job 2. After the Map stage, SAGA-MapReduce exchanges Intermediate data between clusters using Pilot-Data  3. SAGA-MapReduce launches Reduce tasks on N clusters using Pilot-Job.


\begin{figure}
 \centering
%\includegraphics[scale=0.45]{figures/align-dup.pdf} 
\includegraphics[scale=0.45]{figures/mapreduce-pilotdata.pdf} 
\caption{\small Pilot-SAGA MapReduce architecture}
  \label{fig:arch-pj-saga-mr} 
\end{figure}


\subsection{Pilot Model-driven SAGA-MapReduce for NGS data analysis : Reads Alignment and Duplicate Removal}

There are unique features that differentiate our approach from others, which could be beneficial for developing cyberinfrastructure for NGS data analytics and downstream analysis.  
\begin{enumerate}

\item MapReduce via Parallel/Concurrency framework vs. MapReduce as a API embedded in an Application or a pipeline  
\item No need of Hadoop infrastructure
\item Scalability by utilizing multiple compute resources
\item Distributed data across distributed resources
\end{enumerate}
 
 In Fig.~\ref{fig:scale-pj-saga-mr}, we present the overall scaling results for the task of mapping and duplicate removal with P-SAGA-MR.  Generally, our observation is that the most of time-to-solution for the tasks are consumed in the map phase, the alignment of reads onto a reference genome.  



\begin{figure}
 \centering
\includegraphics[scale=0.45]{figures/pj-smr-tts.png} 
\caption{\small Varying the read size with 16 nodes, chunk size of 62500 reads and 8 reduces}
  \label{fig:scale-pj-saga-mr} 
\end{figure}

\begin{figure}
 \centering
\includegraphics[scale=0.42]{figures/pj-smr-scale.png}
\caption{\small PJ-based SAGA-MapReduce}
  \label{fig:scale-pj-saga-mr} 
\end{figure}


\subsection{Comparison to Hadoop-based SEQAL}
\subsubsection{Closely Related Works}
There exist a few works specifically targeting NGS data analytics using the MR framework and four other tools are presented in Table~\ref{table:mr-comparison}

Interestingly, multi-domain support MR framework is recently introduced for AutodDock application which is, in contrast to our applications that are loosely-coupled, pleasingly parallel.\cite{ecmls11-mr-autodock}

\begin{figure}
 \centering
\includegraphics[scale=0.55]{figures/seqalvslocalpmr.png}

\caption{\small Hadoop based SEQAL vs local-PMR vs distributed-PMR}
  \label{fig:comp_with_seqal_1} 
\end{figure}

\subsubsection{Performance Comparison}
In Fig.~\ref{fig:comp_with_seqal_1} and Fig.~\ref{fig:comp_with_seqal_2}, we compared directly the time-to-solution between SEQAL and two scenarios with P-SAGA-MR, one with a single cluster and the other with two clusters.  In Fig.~\ref{fig:comp_with_seqal_2}, we dissect the contributions of each step for the total runtime.




\begin{figure}
 \centering
\includegraphics[scale=0.55]{figures/8GB_phasewisetimes.png}

\caption{\small  Duplicate Read Removal on 8GB input data}
  \label{fig:comp_with_seqal_2} 
\end{figure}



As the number of input sequences increased the time to solution also increased linearly for both SEQAL and local-PMR. 
The time to solution decreased by an average of 43.39% with 95% confidence interval of 3.03%. The Map phase of Local-PMR is on an average of 64% of Map phase of SEQAL application, and is reduced by an average of 35.7%
The reduce phase is very less compared to seqal applicaiton because there is not sort involved in reduce phase.
\pmnote{( why is that?? i dont see any reason to have a sort before reduce starts)) we do sort intermediate data before shuffled.}
The reduce phase is average of 8.85% of reduce phase of seqal  ( it involves sort )

\pmnote{how to explain performance of PMR ??}..One of the performance bottlneck for PMR is coordination system used... we used redis as coordination system... which is proved best ,when compared to other coordination systems{Pstar reference}. I think we can compare the results.. but cant say why SEQAL performed better.. since, it needs understanding of how SEQAL actually works.


\section{Concluding Remarks}


% \begin{table}
% \small
% \begin{tabular}{|c|c|c|c|c|c|} 
% \hline 
%Case & Read File & Threads   &  \# of & BigJob Size   &   $T_C$   \\
%   & Size& per Task & Tasks  & Cores(Nodes)  & \\
%   \hline
%g1 & 0.209 GB & 2 &   40 &  80(10) & 3966 s \\
%g2 & 0.435 GB & 2 &  20 & 40(5) & 8031 s\\ \hline
%g3  & 0.209 GB& 2 & 40  & 12(3) & 25807 s \\
%g4 & 0.435 GB& 2 & 20  & 12(3) & 23872 s  \\ \hline
%\hline
%g5 & 0.209 GB& 2& 40 & 80(20) & 1111 s \\
%g6&0.435 GB&2& 20 & 40(10)&2096 s\\
%\hline
%\end{tabular}
%\caption{Performance comparison for different parallel configurations
%  using SAGA-BigJob on a HPC-Grid (LONI). One BigJob is submitted with
%  the number of sub-jobs, where each sub-job is a BFAST task.  The
%  total (read) data size is the read-file size multiplied by the
%  number of tasks (which is equal to the number of read-files); which
%  is a constant for g1-g6.  Cases g1, g2 and g3,g4 and g5,g6 are
%  conducted on QB, Painter and Eric respectively. The cases g1, g2,
%  g3, g4 are use 40 index files of a Human Chromosome 21.  Note that
%  g5 and g6 are the results with 10 index files; g6 is specifically
%  carried out to provide a direct comparison to c5 (on a cloud
%  resource as in the following Table~\ref{table:cloud-VM}) }
%  
%  \label{table:bigjob-loni} 
%\end{table}



\section*{Acknowledgement}
This document was developed with support from the National Science
Foundation (NSF) under Grant No.  0910812 to Indiana University for
``FutureGrid: An Experimental, High-Performance Grid Test-bed.''  We
also acknowledge the SEAL developer, Luca Pireddu for useful performance related
discussions, and Erik Flemington for allowing us to use his RNA-seq data sets. Computing resources were made possible via NSF TRAC award TG-MCB090174 and LONI resources.  The project described was partially
supported by Grant Number P20RR016456 from the NIH National Center For
Research Resources.

\bibliographystyle{abbrv} 
\bibliography{compbio,saga}


\end{document}

Any opinions, ndings, and conclusions or recommendations expressed in
this material are those of the author(s) and do not necessarily
reflect the views.
