\documentclass{article}

\usepackage{graphicx}
\usepackage{epsfig}
\usepackage{subfigure}
\usepackage[hypertex]{hyperref}
\usepackage{subfigure}  
\usepackage{color}
\usepackage{srcltx}
\usepackage{url}
\usepackage[small,it]{caption}


\parskip   = 0.5em
\parindent = 0.0em

\textwidth      = 6.5315 in
\textheight     = 9.0315 in
\oddsidemargin  = 0.0 in
\evensidemargin = 0.0 in
\topmargin      = 0.0 in
\headheight     = 0.0 in
\headsep        = 0.0 in
\textfloatsep   = 0.1in

\newenvironment{shortlist}{
  \vspace*{-0.5em}
  \begin{itemize}
  \setlength{\itemsep}{-0.3em}
}{
  \end{itemize}
  \vspace*{-0.5em}
}

\newcommand{\I}[1]{\textit{#1}}
\newcommand{\B}[1]{\textbf{#1}}
\newcommand{\BI}[1]{\textbf{\textit{#1}}}
\newcommand{\T}[1]{\texttt{#1}}
\newcommand{\NL}{\newline}

\newif\ifdraft
%\drafttrue
\ifdraft
 \newcommand{\jhanote}[1]{  {\textcolor{red}    { ***Shantenu: #1 }}}
 \newcommand{\katznote}[1]{ {\textcolor{cyan}   { ***Dan:      #1 }}}
 \newcommand{\amnote}[1]{   {\textcolor{magenta}{ ***Andre:    #1 }}}
 \newcommand{\hknote}[1]{   {\textcolor{blue}   { ***Hartmut:  #1 }}}
\else
 \newcommand{\jhanote}[1]{}
 \newcommand{\katznote}[1]{}
 \newcommand{\amnote}[1]{}
 \newcommand{\hknote}[1]{}
\fi


\usepackage{ifpdf}
\ifpdf
 \DeclareGraphicsExtensions{.pdf, .jpg}
\else
 \DeclareGraphicsExtensions{.eps, .ps}
\fi

% CFP:
%
%
% October 22 and 23, 2008
% 
% Dramatic growth in data and equally rapid decline in the cost of
% highly integrated clusters has spurred the emergence of the data
% center as the platform of choice for a growing class of
% data-intensive applications. To encourage conversations between
% those developing applications, algorithms, software, and hardware
% for such "cloud" platforms, we are convening the first workshop on
% Cloud Computing and its Applications (CCA'08).
% 
% This workshop will include a mixture of invited and contributed
% talks on cloud computing, data intensive scalable computing, and
% related topics.
% 
% Topics of interest include:
% 
%   - compute and storage cloud architectures and implementations
% * - map-reduce and its generalizations
% * - programming models and tools
%   - novel data-intensive computing applications
%   - data intensive scalable computing
%   - distributed data intensive computing
%   - content distribution systems for large data
%   - data management within and across data centers
% 
% If you would like to give a contributed talk, please submit a five
% page extended abstract by August 15, 2008. These submissions will
% also be used to select papers for a poster session. Extended
% abstracts should be submitted to:
% https://cmt.research.microsoft.com/CCA2008.


\begin{document}

\title{\large Programming Abstractions for Clouds}

\author{Shantenu Jha$^{12}$,
        Andre Merzky$^{1}$,
        Geoffrey Fox$^{34}$\\[1em]
        %
        $^1$ \small
          Center for Computation and Technology, 
          Louisiana State University\\[-0.3em]
        $^2$ \small
          Department of Computer Science, 
          Louisiana State University\\[-0.3em]
        $^3$ \small
          Community Grids Lab, 
          Indiana University\\[-0.3em]
        $^4$ \small
          Department of Computer Science, 
          Indiana University
       }

\maketitle

\begin{abstract}

  \noindent

  Clouds seem like 'Grids Done Right', including scalability,
  transparency, and ease of management. Virtual Machines are the
  dominant application environments for compute Clouds, however, that
  does not make application programming any less relevant than
  ``non-virtualized'' environments.  The limited set of successful
  Cloud applications show that distributed programming patterns of the
  type of
%  MapReduce, AllPairs, and BigTable are required by a large set of
  MapReduce and All-Pairs are
  required % by a large set of applications,
  to make Cloud infrastructure a viable compute environment for a
  large class of problems.  The existence of multiple implementations
  of these programming paradigms also makes clear, that application
  portability is, even for Clouds an emerging problem which needs
  addressing beyond the level of system virtualization. %\\[-0.5em]
  This paper discusses these and other challenges around cloud
  applications programming and development, and through a discussion
  of several applications, demonstrates potential solutions. We
  discuss how using the right abstractions -- programming interfaces,
  frameworks that support commonly occuring programming and execution
  patterns -- enable efficient, extensible and importantly {\it
    system-independent} implementations of common programming patterns
  such as MapReduce, ie same application is usable seamlessly on both
  traditional Grids and Clouds systems. We further discuss that
  lessons learned from programming applications for Grid environment
  also apply, to some extent, to Cloud environments.

\end{abstract}

% \tableofcontents

% \newpage
% 
% -- intro
% 
%   - dominant compute intensive cloud applications are, at the moment,
%     pleasingly distributed or very loosely coupled.  
%   - dominant data intensive cloud applications use novel programming
%     paradigms, e.g. MapReduce, BigTable, etc.
%   - what about other application classes?
% 
% -- Clouds
% 
%   - Clouds seem to be designed to support the first two categories, by
%     their affinity
%   - explain affinity etc etc etc
%   - discuss how affinity allows high level programming abstractions,
%     such as map reduce (would be tough to implement on a not-data
%     affine grid, as performant/redundant GFS would be missing)
% 
% -- programming models and affinity
% 
%   - discuss what programming models are required for other apps
%     classes in table
%   - pick one or two, and details, and derive required affinities
%     - loosely coupled heterogeneous:
%       - long living applications
%       - fault tolerant
%       - compute intensive, CPU colocation within components
%     - tightly coupled, homogeneous
%       - if small tasks:
%         - need to avoid queueing delay (slide in, pools, ...)
%       - if large tasks
%         - need fault tolerance
%       - all need co-location, fast channels, reservation?
% 
%   - separation of concerns
%   - focus on MapReduce (implemented), RepEx (discussing)
% 
% -- conclusions 
% 
%   - Clouds are young, and one should anticipate Clouds with other
%     affinities, and target application classes
%   - for academia, the reverse procedure may prove useful: define the
%     application classes, derive programming models, derive affinities,
%     design Clouds supporting those.  implement on Grids for a good
%     measure ;)


\section{Introduction}

Going by interest garnered, Clouds seem to have emerged as a clear
winner of the (perceived) battle of distributed infrastructures for a
susbet of applications, and for the time being at least.  They allow
loosely-coupled, data-intensive applications to be run with an ease,
and with absolutely competetive scalability and throughput.  Not
suprisingly, dominant cloud applications utilize novel and hitherto,
Cloud specific computing paradigms, such as MapReduce, BigTable, or
Hadoop.  These paradigms are supported by the inherent system
capabilities of todays Clouds, which we call
\I{affinities}~\cite{cloud-saga-paper}.  Section~\ref{sec:affine}
discusses these in some more detail.

%We wonder, however, how 

For Clouds to be relevant to the wider scientific computing community
and in general, beyond internet-backend computing, it is important to
understand how application classes will fare when migrated to Clouds ,
or Cloud-like distributed systems?  At the moment it seems unclear if
the system properties and affinities as offered by todays Clouds
support, or even allow, for other application types to perform equally
well.  We will discuss several application classes, which seem to be
most relevant for the academic computing community, in
Section~\ref{sec:apps}.  Instead of just waiting for the 'right'
affinities to emerge with new Cloud incarnations, we rather attempt to
predict what these affinities are, by abstracting the relevant
programming patterns for these application classes, and deriving the
respective system properties required to support these programming
patterns (see Section~\ref{sec:apps}).
 

We outline two specific applications, which to the best of our
knowledge have not been used on Clouds: the first a replica-exchange
based applications, which belongs to loosely-coupled ensemble of
tightly-coupled, homogenous distributed applications. The second
example is MapReduce based application, as an example of
loosely-coupled data driven applications. We specifically discuss
dominant programming pattern, and describe exemplary Grid based
implementations.  We will then discuss, how these implementation
change (i.e. simplify) for a Cloud system with the appropriate system
affinities.  The Simple API for Grid Applications (SAGA) can be used
to programmatically develop a very wide-range of distributed
applications.  In this paper we describe how SAGA has been used to
develop two different applications from the following classes of
distributed applications (i) applications based upon the loosely
coupled of homogenous sub-tasks and, (ii) applications based upon
loosely coupled simulations of heterogenous sub-tasks. The specific
applications developed are Replica-Exchange simulations using
Molecular Dynamics and Kalman-Filter based application for reservoir
simulation.  We briefly discuss the specific applications developed
and the typical science problems tackled using these applications.  We
will describe the application characteristics of the two case-studies,
with a focus on the distributed logic of these simulations, and not
the core simulation logic of the applications.  The paper analyses and
contrasts the application characteristics of the examples, and shows
how they are supported using SAGA, often in conjunction with other
programming frameworks such as Cactus.  The primary aim of this paper
is to demonstrate how SAGA can be an effective tool for
programmatically representing and implemeting the logic of
coordination and orchestrating multiple, distributed tasks, while
remaining agnostic to the actual mechanism, ie. details of the
distributed environment. We will highlight the importance of
programming abstractions and how frameworks that provide common
programming patterns can be used to simplify the construction of
distributed applications. We will conclude our discussion with a
proposed procedure for defining scientific-computing oriented Cloud
properties.


\section{Cloud Usage Modes and System Affinities}
\label{sec:affine}
 
% \amnote{section needs shortening, to about 1 page}
 
In Ref~\cite{cloud-saga-paper} it was shown how Grid system interfaces
(in particular for general purpose Grids) tend to be complete
(i.e. they try to expose a complete set of available system
capabilities), whereas Cloud interfaces tend to be minimalistic
(i.e. they expose only a limited set of capabilities, just enough to
'do the job').
%~\cite{cloud-saga-paper}.
 
 \subsection{Usage Modes}

  It is important to understand the reason for this difference.  In
  our experience, general purpose Grids are mostly designed bottom-up:
  existing, often heterogenous resources are federated as VOs, and
  their combined capabilities, plus additional capabilities of higher
  level Grid services, are offered to the end-user.  This is not
  applicable for Clouds: the design of Clouds seems to be, mostly, top
  down. Clouds are designed to serve a limited, specific set of use
  cases and usage modes, and the Cloud system interface is designed to
  provide \I{that} functionality, and no other.  Furthermore, the
  Cloud system itself, and in particular its high level services, may
  be designed to implement specific target use cases, while not
  supporting others (e.g., a Cloud could be homogenous by design).
  These differences do not imply that Clouds are trivial to implement.
  In practise the opposite is most likely true (due to issues of
  scale, amongst other things). Clouds may very well build upon
  general purpose Grids, or narrow Grids, and at least face the same
  challenges; but their system interfaces do not expose those internal
  capabilities.

  Specific users and user communities tend to create different
  applications but with shared characteristics.  For example, the
  particle data community tends to focus on very loosely coupled, data
  intensive parameter sweeps involving Monte Carlo simulations and
  statistical analyzes.  Systems used by these communities are thus
  designed to support these application classes before others.
  
  The \I{Usage Mode} tries to catch the dominant
  properties of the main application classes, insofar they are
  relevant to the design of the system, and to the operational
  properties of the system.  For example, the usage mode \I{'massively
  distributed, loosely coupled'} implies that the system's design
  prioritizes on compute resources (e.g. cycle scavanging, large
  clusters), and to a lesser degree on communication (no need for fast
  links between application instances), or on reservation and co
  scheduling.

  In contrast, the usage mode \I{'massively distributed,
    tighly-coupled'} would imply a system's design to focus on compute
  resources, but importantly also on fast communication between near
  nodes, and on (physical) co-location of processes.


 \subsection{Affinities}

  Currently Clouds seem to be designed to mostly support exactly one
  usage mode, e.g.  data storage, \I{or} high throughput computing,
  \I{or} databases, etc.  This does not preclude Clouds targeting more
  than one domain or usage mode, however.  The overarching design
  guideline to support the main target usage mode, of Cloud systems,
  we defined as its \BI{affinity}.  In other words, affinity is the
  term we use to indicate the type of computational characteristics
  that a Cloud supports.  That property can very often be expressed as
  the need to use different aspects or elements of a system
  \I{together} (hence the term 'Affinity', in the sense of
  'closeness').  

  For example, the usage mode \I{distributed, tightly coupled}
  implies that an application requires the use of multiple compute
  resources, which need to be 'near' to each other, together with fast
  communication links between these compute resources.  The system
  needs to have a \I{compute-communication affinity}, and a
  \I{compute-compute affinity}.

  Affinities as used in this paper are, however, not always mappable
  to 'closeness'.  For example, we say that a system that supports
  'persistent storage, data replication, data intensive' usage mode,
  may have 'bulk storage affinity' -- in the sense that it needs to be
  designed to have bulk storage properties (availability guarantees,
  long term consistency guarantees etc).  This example also shows that
  affinities are, in some sense, related to Quality of Service (QoS)
  properties exposed by the system, and thus to Service Level
  Agreements (SLAs) about these qualities of service.


 \subsection{Affinities and Programming Abstractions}

  Affinity is thus a high level characterization of the kind of
  application that could be beneficially executed on a particular
  Cloud implementation, without revealing the specifics of the
  underlying architecture. In some ways, this is the ``ideal
  abstraction'' for the end-user who would like to use infrastructure
  as a black-box.  Some classic examples of affinity are:
  tightly-coupled/MPI affinity, high-throughput affinity (capacity),
  fast-turnaround affinity (capability), or bulk storage affinity.
  Our observation is that Clouds have at least one affinity, a
  corollary to which is that Cloud system interfaces are, designed to
  serve at least one specific set of users or usage modes

  % One can argue that narrow Grids also expose affinity, e.g. that a
  % Data Grid has data affinity.  That may well be true, and we think
  % that the term affinity may be useful for the discussion of narrow
  % Grids as well, but the main difference between Clouds and Grids
  % remain that the interfaces of narrow Grids are still designed so as
  % to expose the complete set of capabilities related to the affinity
  % of narrow Grids, whereas Cloud system interfaces expose the minimal
  % set of capabilities related to its affinities.  For the application
  % developer, but more likely the application deployer, information
  % about the affinity of Clouds should be complemented by SLA
  % information, e.g. providing replicated data in case of loss,
  % co-scheduling at the application level, or low latency
  % communication.  Traditionally SLAs are, implicitly or explicitly,
  % provided by the ``service provider'' based upon infrastructure,
  % policy, usage modes, or negotiation.  For Clouds, SLAs are an
  % implicit part of the system interface: the Cloud's affinities imply
  % a certain QoS to be met, for every use of the system.

  An affinity being the 'ideal system abstraction' has another
  important consequence, as it allows to express suitable programming
  abstractions easily, and natively.  For example, it is certainly
  possible to implement MapReduce on a general purpose Grid, with no
  affinity supporting data replication, or data-compute-colocation.
  The implementation of that abstraction, i.e. the Map Reduce
  application framework, must then however implement these
  capabilities itself, \I{on top} of the system it uses.  OTOH, if an
  data/compute affine cloud provides these capabilities natively, as
  is the case for, for example, googles cloud with its google file
  system~\cite{gfs}, then the MapReduce framework can focus on the
  core logic of the programming abstraction, i.e. on the algorithmic
  abstractions and frameworks, and is thus much easier to implement.
  Note that for the application using the MapReduce framework, there
  is no difference~\cite{gsoc-saga}.

  Clearly, we are arguing for a separation of concerns: we argue that
  application frameworks should not have to deal with exposing,
  expressing, or implementing capabilities which are required \I{by}
  them, but are not part of their algorithmic core.  Those should be
  provided at the system level, which makes the application frameworks
  \I{easily} implementable on any system providing these capabilities,
  i.e. on any system, which has the appropriate affinity.


\section{Distributed Applications Usage Modes}
\label{sec:apps}

Table~\ref{tab:classes} shows an overview of a number of application
classes~\cite{dpa_paper} which are widely used in scientific
computing, and outside.  Often applications in the same class, have
similar programming models or use programming patterns; for example,
\I{'pleasingly distributed'} applications, such as the numberous
\I{'XYZ@Home'} type applications, all share the Master-Worker model,
in one incarnation or the other.  As compute affine Clouds (aka
compute Clouds) support that programming paradigm, these applications
can immediately utilize compute cloude resources with great success.
For other application classes, such as \I{'tightly coupled,
  heterogeneous'} applications, this is not so obvious, as a compute
cloud without compute-communication affinity can not easily run a
communication intensive application efficiently.
 
 \begin{table}[h]
  \begin{center}
   \footnotesize
   \begin{tabular}{|p{.25\textwidth}|p{.33\textwidth}|p{.33\textwidth}|}
     \hline
 
     \B{Application Class}                              &
     \B{Data    Driven}                                 &
     \B{Compute Driven}                                 \\\hline
 
     \B{Pleasingly\NL Distributed}                      &
        SETI$@$home                                     &
        Monte Carlo Simulations of\newline
        Viral Propagation                               \\\hline
 
     \B{Loosely Coupled,\NL Homogenous}                 &
        Image Analysis                                  &
        Replica Exchange Molecular\newline
        Dynamics of Proteins                            \\\hline
 
     \B{Tightly Coupled,\NL Homogenous}                 &
        Semantic Video Analysis                         &
        Heme Lattice-Boltzmann\NL Fluid dynamics        \\\hline
 
     \B{Loosely Coupled,\NL Heterogeneous}              &
        Multi-Domain\NL Climate Predictions             &
        Kalman-Filter Fluid Dynamics                    \\\hline
 
     \B{Dynamic Event\NL Driven}                        &
        Disaster support                                &
        Visualization                                   \\\hline
 
     \B{First Principle,\NL Distributed}                &
        %GridSAT                                         &
       --                                                &  
        MapReduce-Based Motif\NL Distributed search     \\\hline
 
   \end{tabular}
   \caption{\footnotesize \B{Examples of primary categories 
            of distributed applications\cite{dpa_paper}.}}
   \label{tab:classes}
  \end{center}
  \vspace*{-2em}
 \end{table}

 We want to demonstrate using two examples, how the implementation of the
 respective programming patterns used by these application classes can
 be supported by the Cloud affinities\footnote{Both applications have
 been implemented using SAGA~\cite{saga-core}, but we do not, in this
 paper, intent to focus on SAGA as a solution to the discussed problem
 space, but merily use it as means to an end.}.

 \subsection{Example 1: MapReduce}

  MapReduce~\cite{mapreduce-paper} is a programming framework which supports
  applications which operate on very large data sets on clusters of
  computers.  MapReduce relies on a number of capabilities of the
  underlying system, most related to file operations, but also related
  to process/data colocation.  The Google file system, and other
  global file systems, provide these capabilities, such as atomic file
  renames.  Implementations of MapReduce on these file systems can
  focus on implementing the the dataflow pipeline, which is the
  algorithmic core of the MapReduce framework.

  We have recently implemented MapReduce in SAGA, targeting
  general purpose Grid systems, where the system capabilities required
  by MapReduce are usually not natively supported.  Some semantics,
  such as again the atomic file rename, is provided by the SAGA API
  layer, others, such as data/compute colocation are not.  Our
  implementation is thus required to interleave the core logic with
  explicit instructions on where processes are to be scheduled when
  operating on specific parts of the data set~\cite{gsoc-saga}.

  The advantage of this approach is obviously that our implementation
  is no longer bound to run on a system providing the appropriate
  semantics originally required by MapReduce, but is portable to
  other, more generic systems as well.  The drawback of the approach
  is obvious as well: our implementation is relatively more complex,
  as it needs to add semantic system capabilities at some level or the
  other, and it is inherently slower, as it is for these capabilities
  very difficult or near impossible to obtain system level performance
  on application level.  But many of these are due to the early-stages
  of the implementation of SAGA, and not a fundamental limitation of
  the design or concept.

  \B{Summary:} A data affine, and compute/data affine environment with
  the capabilities listed above provides a clear separation of
  concenrns for MapReduce implementations.


 \subsection{Example 2: Replica Exchange}

 Replica Exchange~\cite{repex} is a simulation method which improves
 the properties of Monte Carlo simulations: according to certain
 specific measure (here of temperature), two MC simulation instances
 exchange their configuration.  That procedure improves the mixing
 properties of set of MC
 simulations.%\footnote{\T{http://en.wikipedia.org/wiki/Replica\_exchange}}.

In our specific application case~\cite{saga-migol-paper}, the
implemented replica-exchange framework relied on the following
system capabilities: 

  \begin{shortlist}
   \item efficient execution of many jobs
   \item fault tolerant job execution
   \item efficient exchange of small data items (MC temperature)
  \end{shortlist}

  Again, our implementation targets general purpose Grids.
  Typical for Grids, as discussed in Section~\ref{sec:affine},
  no production Grid system available to us provides that
  complete set of capabilities, but all provide a set of lower
  level capabilities, which can be used to implement the
  required ones.

  We deployed an application level fault tolerance service,
  Migol~\cite{migol}, and interleaved checkpoint/restart
  instructions with the original application code, using the
  SAGA CPR package.  Our implementation can thus operate on
  general purpose Grids, as it does not have strong requirements
  on system capabilities, but again the application development
  process is unnecesarily complicated, and definitely not
  focused on the core method implementation.

\section{Discussion}
\label{sec:discussion}

We have argued above that affinities guide, as well as support, the
implementation of high level programming abstractions.
Clouds\footnote{\url{http://cloudcomputing.qrimp.com}} currently
however, offer a very finite list of affinities: They are either
compute centric (eg EC2)
%~\cite{EC2}, or 
data centric (eg S3)
%~\cite{S3}, 
although some Clouds also offer data-compute colocation.  
%But that is about all you can find -- 
There are no Clouds which are communication affine, and would thus
invite users of tightly-coupled applications, or offer event-driven
application execution, or pipeline execution modes, etc.  If Clouds
are to make a broader impact on Scientific Computing, this deficit
will need to be addressed. 
% The for that is, simple: the commercial cloud providers see, at the
% moment, no market for other specialized Clouds.

\section{Conclusions}
\label{sec:conclusion}

  Trying to migrate applications to a cloud environment which
  does not offer the appropriate usage modes and affinities is
  very like a painful and tedious endeavour, and will likely
  show similar pain-points to the development of Grid
  applications.  Also, performance and scalability may not be
  what the user expects.

  On the other hand, a Cloud environment which does offer the
  suitable usage modes and affinities can significantly ease
  the work of the application developer, and likely yield the
  expected turnaround.

  In many ways, that can be compared to the situation of application
  development for Grids environments: where the higher level grid
  services and abstraction layers are missing in Grid environments,
  application development and deployment is painful, with often
  limited returns.  Clouds can inherently offer these higher
  abstraction layers -- but not always the ones required.

  For scientific computing, the road to successfull Cloud deployment
  seems clear: depending on the target application classes, one needs
  to derive the required fundamental affinities the system needs to
  expose -- which may, or may not, differ significantly from those
  offered by commercial Cloud providers.

\section{Acknowledgements}
\label{sec:acks}

This work is based upon the insight gained from many SAGA projects,
especially the SAGA-MapReduce and SAGA-Replica Exchange implementation
projects. We would like to thank Chris and Michael Miceli, Andre
Luckow, Joohyun Kim, and the wider SAGA team at CCT.

\bibliographystyle{plain}
\bibliography{cca08}

\end{document}

